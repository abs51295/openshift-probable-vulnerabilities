{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0702 04:07:46.107047 139846337992512 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import text_normalizer as tn\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf_hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  2 04:10:12 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   54C    P0    28W /  70W |    213MiB / 15079MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     31703      C   /home/redanalyze/anaconda3/bin/python        203MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152151 entries, 0 to 152150\n",
      "Data columns (total 2 columns):\n",
      "description    152151 non-null object\n",
      "label          152151 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./data/GH_complete_labeled_issues_prs - preprocessed.csv', encoding='utf-8', \n",
    "                      na_filter=False)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Counter({0: 128908, 1: 22572, 2: 671})\n",
      "After: Counter({0: 128908, 1: 23243})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "texts = dataset['description'].tolist()\n",
    "labels = dataset['label'].tolist()\n",
    "\n",
    "print('Before:', Counter(labels))\n",
    "labels = [1 if item != 0 else 0 for item in labels]\n",
    "print('After:', Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114113, 38038)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_text, test_text, train_labels, test_labels = train_test_split(texts, labels, \n",
    "                                                                    test_size=0.25, random_state=SEED)\n",
    "len(train_text), len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKMAAAEyCAYAAAAm+BNQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHWpJREFUeJzt3X2spNV9H/Dvr7sGgxPe4tgiLNLiZpWGRG1MVpjEVRSZCBaIsq7kSERR2bpUK7l2m6StUtxIdd7+wFUau0gOETXEYKXGLnFrFNulCLuKKsWYJXZsMHHY2AQ2EONoMXGDZAdy+sec60yWe2e5L3vmzp3PR7q685w5M/c85z7P85v7vc88U621AAAAAMAIf2/eAwAAAABgeQijAAAAABhGGAUAAADAMMIoAAAAAIYRRgEAAAAwjDAKAAAAgGGEUQAAAAAMI4wCAAAAYBhhFAAAAADD7J73ALbaK1/5yrZ37955DwNg23nwwQf/orX2nfMex7ypEwCrUycm1AmA1W1lndhxYdTevXtz5MiReQ8DYNupqj+d9xi2A3UCYHXqxIQ6AbC6rawT3qYHAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhhFEAAAAADCOMAgAAAGAYYRQAAAAAwwijAAAAABjmpGFUVd1WVU9X1UNTbedV1b1V9Wj/fm5vr6q6qaqOVtXnquqSqccc6v0frapDU+0/WFWf74+5qapq1s8AYHtRJwCYRZ0A4EQv5cyo9yU5cELbDUnua63tS3JfX06Sq5Ls61+Hk9ycTApBknckeV2SS5O8Y6oY3Nz7rjzuwEl+BgDby/uiTgCwtvdFnQBgyknDqNba7yU5fkLzwSS399u3J3njVPsdbeJTSc6pqvOTXJnk3tba8dbaM0nuTXKg33dWa+33W2styR0nPNdqPwOAbUSdAGAWdQKAE+3e4ONe3Vp7Kklaa09V1at6+wVJnpjqd6y3zWo/tkr7rJ/xIlV1OJP/hmTXWd+ZvTd8dIOrtdweu/GaeQ8B2DnUiVU4zgJ8y46sE47zAC/NVl/AvFZpaxtoX5fW2i2ttf2ttf27zjx7vQ8HYBx1AoBZ1AmAJbDRMOor/ZTY9O9P9/ZjSS6c6rcnyZMnad+zSvusnwHA9qdOADCLOgGwxDYaRt2dZOUTLA4l+chU+3X9UzAuS/JsPzX2niRXVNW5/UKDVyS5p9/39aq6rH/qxXUnPNdqPwOA7U+dAGAWdQJgiZ30mlFV9YEkP5rklVV1LJNPsbgxyYeq6vokjyf5yd79Y0muTnI0yXNJ3pwkrbXjVfUrSR7o/X65tbZyEcO3ZPIJG2ck+Xj/yoyfAcA2ok4AMIs6AcCJavKhEzvH6efva+cfeve8h7GQXHARdraqerC1tn/e45i3edYJx1lgO1MnJjZTJxzngZ1sK+vEVl/AHAAAAADWJIwCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhhFGAQAAADCMMAoAAACAYYRRAAAAAAwjjAIAAABgGGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhhFEAAAAADCOMAgAAAGAYYRQAAAAAwwijAAAAABhGGAUAAADAMMIoAAAAAIYRRgEAAAAwjDAKAAAAgGGEUQAAAAAMI4wCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhhFGAQAAADCMMAoAAACAYYRRAAAAAAwjjAIAAABgGGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhhFEAAAAADCOMAgAAAGAYYRQAAAAAw2wqjKqqn6uqh6vqoar6QFW9vKouqqr7q+rRqvpgVZ3W+57el4/2+/dOPc/be/sXq+rKqfYDve1oVd2wmbECMJ46AcAs6gTActpwGFVVFyT510n2t9a+P8muJNcmeWeSd7XW9iV5Jsn1/SHXJ3mmtfbdSd7V+6WqLu6P+74kB5L8RlXtqqpdSd6T5KokFyf5qd4XgAWgTgAwizoBsLw2+za93UnOqKrdSc5M8lSSNyS5q99/e5I39tsH+3L6/ZdXVfX2O1tr32itfTnJ0SSX9q+jrbUvtda+meTO3heAxaFOADCLOgGwhDYcRrXW/izJryV5PJOi8WySB5N8rbX2fO92LMkF/fYFSZ7oj32+9/+O6fYTHrNW+4tU1eGqOlJVR1547tmNrhIAW0idAGAWdQJgeW3mbXrnZvKfhYuSfFeSV2RyCuyJ2spD1rhvve0vbmztltba/tba/l1nnn2yoQMwgDoBwCzqBMDy2szb9H4syZdba19trf11kg8n+eEk5/TTbJNkT5In++1jSS5Mkn7/2UmOT7ef8Ji12gFYDOoEALOoEwBLajNh1ONJLquqM/t7tS9P8oUkn0zypt7nUJKP9Nt39+X0+z/RWmu9/dr+6RgXJdmX5NNJHkiyr3+axmmZXJTw7k2MF4Cx1AkAZlEnAJbU7pN3WV1r7f6quivJHyR5PslnktyS5KNJ7qyqX+1tt/aH3Jrk/VV1NJP/YFzbn+fhqvpQJoXn+SRvba29kCRV9bYk92TyyRq3tdYe3uh4ARhLnQBgFnUCYHnV5J8JO8fp5+9r5x9697yHsZAeu/GaeQ8BOIWq6sHW2v55j2Pe5lknHGeB7UydmNhMnXCcB3ayrawTm3mbHgAAAACsizAKAAAAgGGEUQAAAAAMI4wCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhhFGAQAAADCMMAoAAACAYYRRAAAAAAwjjAIAAABgGGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhhFEAAAAADCOMAgAAAGAYYRQAAAAAwwijAAAAABhGGAUAAADAMMIoAAAAAIYRRgEAAAAwjDAKAAAAgGGEUQAAAAAMI4wCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhhFGAQAAADCMMAoAAACAYYRRAAAAAAwjjAIAAABgGGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhNhVGVdU5VXVXVf1RVT1SVT9UVedV1b1V9Wj/fm7vW1V1U1UdrarPVdUlU89zqPd/tKoOTbX/YFV9vj/mpqqqzYwXgLHUCQBmUScAltNmz4z6L0n+V2vtHyT5R0keSXJDkvtaa/uS3NeXk+SqJPv61+EkNydJVZ2X5B1JXpfk0iTvWCk4vc/hqccd2OR4ARhLnQBgFnUCYAltOIyqqrOS/EiSW5OktfbN1trXkhxMcnvvdnuSN/bbB5Pc0SY+leScqjo/yZVJ7m2tHW+tPZPk3iQH+n1ntdZ+v7XWktwx9VwAbHPqBACzqBMAy2szZ0a9JslXk/xWVX2mqt5bVa9I8urW2lNJ0r+/qve/IMkTU48/1ttmtR9bpR2AxaBOADCLOgGwpDYTRu1OckmSm1trr03yV/nbU2hXs9r7s9sG2l/8xFWHq+pIVR154blnZ48agFHUCQBmUScAltRmwqhjSY611u7vy3dlUky+0k+JTf/+9FT/C6cevyfJkydp37NK+4u01m5pre1vre3fdebZm1glALaQOgHALOoEwJLacBjVWvvzJE9U1ff0psuTfCHJ3UlWPsHiUJKP9Nt3J7mufwrGZUme7afd3pPkiqo6t19o8Iok9/T7vl5Vl/VPvbhu6rkA2ObUCQBmUScAltfuTT7+XyX57ao6LcmXkrw5k4DrQ1V1fZLHk/xk7/uxJFcnOZrkud43rbXjVfUrSR7o/X65tXa8335LkvclOSPJx/sXAItDnQBgFnUCYAltKoxqrX02yf5V7rp8lb4tyVvXeJ7bkty2SvuRJN+/mTECMD/qBACzqBMAy2kz14wCAAAAgHURRgEAAAAwjDAKAAAAgGGEUQAAAAAMI4wCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhhFGAQAAADCMMAoAAACAYYRRAAAAAAwjjAIAAABgGGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhhFEAAAAADCOMAgAAAGAYYRQAAAAAwwijAAAAABhGGAUAAADAMMIoAAAAAIYRRgEAAAAwjDAKAAAAgGGEUQAAAAAMI4wCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhhFGAQAAADCMMAoAAACAYYRRAAAAAAwjjAIAAABgGGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhNh1GVdWuqvpMVf1uX76oqu6vqker6oNVdVpvP70vH+337516jrf39i9W1ZVT7Qd629GqumGzYwVgPHUCgFnUCYDlsxVnRv1Mkkemlt+Z5F2ttX1JnklyfW+/PskzrbXvTvKu3i9VdXGSa5N8X5IDSX6jF6RdSd6T5KokFyf5qd4XgMWiTgAwizoBsGQ2FUZV1Z4k1yR5b1+uJG9IclfvcnuSN/bbB/ty+v2X9/4Hk9zZWvtGa+3LSY4mubR/HW2tfam19s0kd/a+ACwIdQKAWdQJgOW02TOj3p3k55P8TV/+jiRfa60935ePJbmg374gyRNJ0u9/tvf/VvsJj1mr/UWq6nBVHamqIy889+wmVwmALaROADCLOgGwhDYcRlXVjyd5urX24HTzKl3bSe5bb/uLG1u7pbW2v7W2f9eZZ88YNQCjqBMAzKJOACyv3Zt47OuT/ERVXZ3k5UnOyuQ/G+dU1e7+34o9SZ7s/Y8luTDJsaraneTsJMen2ldMP2atdgC2P3UCgFnUCYAlteEzo1prb2+t7Wmt7c3kgoGfaK39dJJPJnlT73YoyUf67bv7cvr9n2ittd5+bf90jIuS7Evy6SQPJNnXP03jtP4z7t7oeAEYS50AYBZ1AmB5bebMqLX8+yR3VtWvJvlMklt7+61J3l9VRzP5D8a1SdJae7iqPpTkC0meT/LW1toLSVJVb0tyT5JdSW5rrT18CsYLwFjqBACzqBMAO1xN/pmwc5x+/r52/qF3z3sYC+mxG6+Z9xCAU6iqHmyt7Z/3OOZtnnXCcRbYztSJic3UCcd5YCfbyjqx2U/TAwAAAICXTBgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhhFEAAAAADCOMAgAAAGAYYRQAAAAAwwijAAAAABhGGAUAAADAMMIoAAAAAIYRRgEAAAAwjDAKAAAAgGGEUQAAAAAMI4wCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhhFGAQAAADCMMAoAAACAYYRRAAAAAAwjjAIAAABgGGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhhFEAAAAADCOMAgAAAGAYYRQAAAAAwwijAAAAABhGGAUAAADAMMIoAAAAAIYRRgEAAAAwjDAKAAAAgGGEUQAAAAAMI4wCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhtlwGFVVF1bVJ6vqkap6uKp+prefV1X3VtWj/fu5vb2q6qaqOlpVn6uqS6ae61Dv/2hVHZpq/8Gq+nx/zE1VVZtZWQDGUScAmEWdAFhemzkz6vkk/7a19r1JLkvy1qq6OMkNSe5rre1Lcl9fTpKrkuzrX4eT3JxMik2SdyR5XZJLk7xjpeD0PoenHndgE+MFYCx1AoBZ1AmAJbXhMKq19lRr7Q/67a8neSTJBUkOJrm9d7s9yRv77YNJ7mgTn0pyTlWdn+TKJPe21o631p5Jcm+SA/2+s1prv99aa0numHouALY5dQKAWdQJgOW1JdeMqqq9SV6b5P4kr26tPZVMCkySV/VuFyR5Yuphx3rbrPZjq7Sv9vMPV9WRqjrywnPPbnZ1ANhi6gQAs6gTAMtl02FUVX1bkt9J8rOttb+c1XWVtraB9hc3tnZLa21/a23/rjPPPtmQARhInQBgFnUCYPlsKoyqqpdlUjh+u7X24d78lX5KbPr3p3v7sSQXTj18T5InT9K+Z5V2ABaEOgHALOoEwHLazKfpVZJbkzzSWvv1qbvuTrLyCRaHknxkqv26/ikYlyV5tp92e0+SK6rq3H6hwSuS3NPv+3pVXdZ/1nVTzwXANqdOADCLOgGwvHZv4rGvT/JPk3y+qj7b2/5DkhuTfKiqrk/yeJKf7Pd9LMnVSY4meS7Jm5OktXa8qn4lyQO93y+31o73229J8r4kZyT5eP8CYDGoEwDMok4ALKkNh1Gttf+b1d+HnSSXr9K/JXnrGs91W5LbVmk/kuT7NzpGAOZHnQBgFnUCYHltyafpAQAAAMBLIYwCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhhFGAQAAADCMMAoAAACAYYRRAAAAAAwjjAIAAABgGGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBhhFEAAAAADCOMAgAAAGAYYRQAAAAAwwijAAAAABhGGAUAAADAMMIoAAAAAIYRRgEAAAAwzO55D4DtY+8NH533EBbSYzdeM+8hAAti3sdZxyuAU2uzx3nHaWBZODMKAAAAgGGEUQAAAAAMI4wCAAAAYBhhFAAAAADDCKMAAAAAGEYYBQAAAMAwwigAAAAAhhFGAQAAADCMMAoAAACAYYRRAAAAAAwjjAIAAABgGGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMMzueQ8AFt3eGz467yEsrMduvGbeQ4ClMs/jlf0d4OQ2e5x2rAUWhTOjAAAAABhm24dRVXWgqr5YVUer6oZ5jweA7UWdAGAWdQJg+9nWYVRV7UryniRXJbk4yU9V1cXzHRUA24U6AcAs6gTA9rTdrxl1aZKjrbUvJUlV3ZnkYJIvzHVUwJZwva2Nc02Ib1EnFsS893f7DCytpaoTrjkFLIrtHkZdkOSJqeVjSV43p7EAbBvz/sN+G1EneEnsM/OxzH/Y2ua2DXViHRZ5u53n8Wbe87bMx1oW13YPo2qVtvaiTlWHkxzui9/403f++EOndFTb3yuT/MW8B7ENmIcJ82AOVnzPvAdwCqgTG2OfmDAPE6dsHuqdp+JZTwnbwoQ6MaFOLOA+cYqONwsxDwOOtQsxD6eYOZjYsjqx3cOoY0kunFrek+TJEzu11m5JckuSVNWR1tr+McPbnszBhHmYMA/mYEVVHZn3GE4BdWIDzMGEeZgwD+ZghTqhTqwwBxPmYcI8mIMVW1kntvUFzJM8kGRfVV1UVacluTbJ3XMeEwDbhzoBwCzqBMA2tK3PjGqtPV9Vb0tyT5JdSW5rrT0852EBsE2oEwDMok4AbE/bOoxKktbax5J8bB0PueVUjWWBmIMJ8zBhHszBih05D+rEhpiDCfMwYR7MwYodOQ/qxIaYgwnzMGEezMGKLZuHau1F1+8DAAAAgFNiu18zCgAAAIAdRBgFAAAAwDA7JoyqqgNV9cWqOlpVN8x7PKdSVV1YVZ+sqkeq6uGq+pnefl5V3VtVj/bv5/b2qqqb+tx8rqoume8abJ2q2lVVn6mq3+3LF1XV/X0OPtg/NSVVdXpfPtrv3zvPcW+lqjqnqu6qqj/q28QPLem28HN9f3ioqj5QVS9fhu2hqm6rqqer6qGptnX//qvqUO//aFUdmse6nGrLVCeSpKoeq6rPV9VnVz6GdxmODfaJNefgF6vqz/r28Nmqunrqvrf3OfhiVV051b6w+0xt4WulBd8W1pqHpdoeXqqdvo6Oj44NK2ryOvnTVfWHfR5+qbdfVOt87bzWMWNR1Bb8PbkD5mBLXjOue59orS38VyafjPEnSV6T5LQkf5jk4nmP6xSu7/lJLum3vz3JHye5OMl/SnJDb78hyTv77auTfDxJJbksyf3zXoctnIt/k+S/JfndvvyhJNf227+Z5C399r9M8pv99rVJPjjvsW/hHNye5F/026clOWfZtoUkFyT5cpIzpraDf7YM20OSH0lySZKHptrW9ftPcl6SL/Xv5/bb58573bZ4npaqTvR1fizJK09o2/HHBvvEmnPwi0n+3Sp9L+77w+lJLur7ya5F32eyRa+VdsC2sNY8LNX28BLnahnW0fHRsWFlHirJt/XbL0tyf1+/db12XuuYMe/1W+dcbOrvyR0yB49lk68ZN7JP7JQzoy5NcrS19qXW2jeT3Jnk4JzHdMq01p5qrf1Bv/31JI9k8sf4wUyCifTvb+y3Dya5o018Ksk5VXX+4GFvuarak+SaJO/ty5XkDUnu6l1OnIOVubkryeW9/0KrqrMyeWFxa5K01r7ZWvtalmxb6HYnOaOqdic5M8lTWYLtobX2e0mOn9C83t//lUnuba0db609k+TeJAdO/eiHWqo6McOOPzbYJ9acg7UcTHJna+0brbUvJzmayf6y0PvMFr5WWvRtYa15WMuO3B5eoh2/jo6Pjg0r+vr8v774sv7Vsv7XzmsdMxbCFv09udBzMMMp3yd2Shh1QZInppaPZXah3TH66YGvzSTNfnVr7alkcqBN8qrebafOz7uT/HySv+nL35Hka6215/vy9Hp+aw76/c/2/ovuNUm+muS3+uml762qV2TJtoXW2p8l+bUkj2cSQj2b5MEs3/awYr2//x25XZxgGdbxRC3J/66qB6vqcG9bqmPDFPvExNv6KfW3rZxunyWYg02+Vtqp85As6fYwwzKs42rsE0t6bOhvT/tskqczCQ7+JOt/7bzo87AVf08u+hwkW/Oacd3zsFPCqNXOaGjDRzFYVX1bkt9J8rOttb+c1XWVtoWen6r68SRPt9YenG5epWt7Cfctst2ZnG59c2vttUn+KpPTKNeyI+ehv4g+mMmpsd+V5BVJrlql607fHk5mrfVehvlYhnU80etba5dksi+8tap+ZEbfZZyfZLn2iZuT/P0kP5BJaP+fe/uOnoMteK20U+dhKbeHk1iGdVyPHb0tODYkrbUXWms/kGRPJmfyfO9q3fr3HTcPW/j35MLOwZSteM247nnYKWHUsSQXTi3vSfLknMYyRFW9LJMD6G+31j7cm7+y8raK/v3p3r4T5+f1SX6iqh7L5DTqN2SSbJ/T36aV/N31/NYc9PvPzkt/C8N2dizJsdbayn8578oknFqmbSFJfizJl1trX22t/XWSDyf54Szf9rBivb//nbpdTFuGdfw7WmtP9u9PJ/kfmbzQXLZjw4ql3ydaa1/pf3j8TZL/mr99C8GOnYMteq20I+dhGbeHl2AZ1nE19omJpZuHFW1yiY//k8n1f9b72nmR52Gr/p5c5DlIsmWvGdc9DzsljHogyb5+5fvTMrmg2N1zHtMp09+bemuSR1prvz51191JVq5afyjJR6bar+tXvr8sybMrp9wtqtba21tre1prezP5fX+itfbTST6Z5E2924lzsDI3b+r9Fy2xfpHW2p8neaKqvqc3XZ7kC1mibaF7PMllVXVm3z9W5mGptocp6/3935Pkiqo6t59ldkVv20mWrU68oqq+feV2Jr/Th7J8x4YVS79PnHANsH+SyfaQTObg2pp8StBFSfYl+XQWfJ/ZwtdKC70trDUPy7Y9vETLsI6rsU9MLNs8fGdVndNvn5HJP3YfyfpfO691zNj2tvDvyYWdg2RLXzOuf59o2+Dq7VvxlclV3f84k/e6/sK8x3OK1/UfZ3LK2+eSfLZ/XZ3Je1bvS/Jo/35e719J3tPn5vNJ9s97HbZ4Pn40f/vpB6/JZOc/muS/Jzm9t7+8Lx/t979m3uPewvX/gSRH+vbwPzP59IKl2xaS/FKSP+oHz/dn8okWO357SPKBTN5i8deZ/Efi+o38/pP88z4fR5O8ed7rdYrmapnqxGsy+WSXP0zy8Mr6LsOxwT6x5hy8v6/j5zJ5IXn+VP9f6HPwxSRXTbUv7D6TLXyttODbwlrzsFTbwzrma0evo+OjY8PU2P9hks/0eXgoyX/s7et+7bzWMWORvrLJvycXeQ6yha8Z17tPVH8QAAAAAJxyO+VtegAAAAAsAGEUAAAAAMMIowAAAAAYRhgFAAAAwDDCKAAAAACGEUYBAAAAMIwwCgAAAIBh/j92BE6fvYIM6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_doc_lens = [len(doc.split(' ')) for doc in train_text]\n",
    "f, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "ax[0].hist(train_doc_lens, bins=100)\n",
    "ax[0].set_xlim([0, 1000])\n",
    "\n",
    "ax[1].hist(train_doc_lens, bins=100)\n",
    "ax[1].set_xlim([0, 2500])\n",
    "\n",
    "ax[2].hist(train_doc_lens, bins=100)\n",
    "ax[2].set_xlim([0, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "       When running eval/predict on the TPU, we need to pad the number of examples\n",
    "       to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "       size. The alternative is to drop the last batch, which is bad because it means\n",
    "       the entire output data won't be generated.\n",
    "       We use this class instead of `None` because treating `None` as padding\n",
    "       batches could cause silent errors.\n",
    "  \"\"\"\n",
    "    \n",
    "    \n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module(bert_path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  tf_hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=text, text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Params for bert model and tokenization\n",
    "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "MAX_SEQ_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0702 04:41:11.638050 139846337992512 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path=BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_lengths = np.array([len(doc.split(' ')) for doc in train_text])\n",
    "test_text_lengths = np.array([len(doc.split(' ')) for doc in test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112291, 112291, 37408, 37408)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_idx = np.argwhere(train_text_lengths >= 5).ravel()\n",
    "test_text_idx = np.argwhere(test_text_lengths >= 5).ravel()\n",
    "\n",
    "train_text = [train_text[i] for i in train_text_idx]\n",
    "train_labels = [train_labels[i] for i in train_text_idx]\n",
    "test_text = [test_text[i] for i in test_text_idx]\n",
    "test_labels = [test_labels[i] for i in test_text_idx]\n",
    "\n",
    "len(train_text), len(train_labels), len(test_text), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_text, train_labels)\n",
    "test_examples = convert_text_to_examples(test_text, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1d280b7009405fa7feffc019628bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=112291, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0242b266ac5c46799f435b5f659ae61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=37408, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(train_input_ids, train_input_masks, \n",
    " train_segment_ids, train_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
    "                                                                  examples=train_examples, \n",
    "                                                                  max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "(test_input_ids, test_input_masks, \n",
    " test_segment_ids, test_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
    "                                                                examples=test_examples, \n",
    "                                                                max_seq_length=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112291, 512), (37408, 512))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids.shape, test_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_hub.module.Module at 0x7f2ff78bc128>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = tf_hub.Module(BERT_PATH, trainable=True, name=f\"bert_module\")\n",
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.layers.Layer):\n",
    "    \n",
    "    def __init__(self, bert_path, n_fine_tune_encoders=10, **kwargs,):\n",
    "        \n",
    "        self.n_fine_tune_encoders = n_fine_tune_encoders\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.bert_path = bert_path\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.bert = tf_hub.Module(self.bert_path,\n",
    "                                  trainable=self.trainable, \n",
    "                                  name=f\"{self.name}_module\")\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        trainable_vars = [var for var in trainable_vars \n",
    "                                  if not \"/cls/\" in var.name]\n",
    "        trainable_layers = [\"embeddings\", \"pooler/dense\"]\n",
    "\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_encoders+1):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(10 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [var for var in trainable_vars\n",
    "                                  if any([l in var.name \n",
    "                                              for l in trainable_layers])]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:# and 'encoder/layer' not in var.name:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        print('Trainable layers:', len(self._trainable_weights))\n",
    "        print('Non Trainable layers:', len(self._non_trainable_weights))\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(input_ids=input_ids, \n",
    "                           input_mask=input_mask, \n",
    "                           segment_ids=segment_ids)\n",
    "        \n",
    "        pooled = self.bert(inputs=bert_inputs, \n",
    "                           signature=\"tokens\", \n",
    "                           as_dict=True)[\"pooled_output\"]\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(bert_path, max_seq_length, n_fine_tune_encoders=10): \n",
    "    \n",
    "    inp_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    inp_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    inp_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [inp_id, inp_mask, inp_segment]\n",
    "    \n",
    "    bert_output = BertLayer(bert_path=bert_path, \n",
    "                            n_fine_tune_encoders=n_fine_tune_encoders)(bert_inputs)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=tf.keras.optimizers.Adam(lr=2e-5), \n",
    "                  metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0702 05:46:25.326409 139846337992512 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers: 199\n",
      "Non Trainable layers: 5\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0702 05:46:27.496462 139846337992512 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_path=BERT_PATH, max_seq_length=MAX_SEQ_LENGTH, n_fine_tune_encoders=10)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_1 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      bert_layer_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 109,679,361\n",
      "Non-trainable params: 622,650\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 101061 samples, validate on 11230 samples\n",
      "Epoch 1/3\n",
      "101061/101061 [==============================] - 14260s 141ms/step - loss: 0.1429 - acc: 0.9509 - val_loss: 0.0990 - val_acc: 0.9660\n",
      "Epoch 2/3\n",
      "101061/101061 [==============================] - 14258s 141ms/step - loss: 0.0882 - acc: 0.9692 - val_loss: 0.0857 - val_acc: 0.9705\n",
      "Epoch 3/3\n",
      "  5880/101061 [>.............................] - ETA: 3:34:54 - loss: 0.0649 - acc: 0.9716"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-c5e26489be2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=3,\n",
    "    batch_size=15,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37408/37408 [==============================] - 1986s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(x=[test_input_ids, \n",
    "                                    test_input_masks, \n",
    "                                    test_segment_ids],\n",
    "                                 batch_size=200,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = [1 if prob > 0.5 else 0 for prob in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     31617\n",
      "           1       0.89      0.89      0.89      5791\n",
      "\n",
      "    accuracy                           0.97     37408\n",
      "   macro avg       0.93      0.93      0.93     37408\n",
      "weighted avg       0.97      0.97      0.97     37408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEKCAYAAADzQPVvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucXdP5x/HPNzcSScQlbnGJREJpCSKipSU0QilKSX5FkIoSrXtFqWu0Li2lpRKEpNW4q1SRpghVtwQhIi6RuIQUuUeCZGae3x97hyMmM2cms+fMOef79tqv7L3O2metI5PnrHn22msrIjAzs9LWrNAdMDOz7DnYm5mVAQd7M7My4GBvZlYGHOzNzMqAg72ZWRlwsDczKwMO9mZmZcDB3sysDLQodAdWZfmcGb61176m9SZ7FLoL1gRVLHtfq/sedYk5LdfvstrtNTaP7M3MykCTHdmbmTWqqspC9yBTDvZmZgCVFYXuQaacxjEzAyKq8t5qImlNSc9JeknSVEkXpeVbSnpW0puS7pDUKi1fIz2enr7eOee9zknLX5e0b055v7RsuqSh+Xw+B3szM4Cqqvy3mn0O9ImIHYAeQD9JvYHLgasjohswHxiU1h8EzI+IrYCr03pI2hboD2wH9AOul9RcUnPgOmA/YFtgQFq3Rg72ZmYAUZX/VtPbJD5JD1umWwB9gLvT8lHAwen+Qekx6et7S1JafntEfB4RM4HpQK90mx4RMyJiGXB7WrdGDvZmZpBcoM1zkzRY0qScbXDuW6Uj8MnAR8B44C1gQUSsuDAwC+iU7ncC3gNIX18IrJdbvtI5qyqvkS/QmplBrSP2r1SNGAGMqOH1SqCHpA7AfcA3qquW/lndnP2ooby6QXqt9wg42JuZAZHBbJyIWCBpAtAb6CCpRTp63xT4IK02C9gMmCWpBbA2MC+nfIXcc1ZVvkpO45iZQYNdoJXUMR3RI6k1sA8wDXgMOCytNhC4P90fmx6Tvv5oJA8HHwv0T2frbAl0A54DJgLd0tk9rUgu4o6t7eN5ZG9mBnVK49RiY2BUOmumGXBnRDwg6VXgdknDgBeBm9P6NwN/kTSdZETfHyAipkq6E3gVqACGpOkhJJ0MjAOaAyMjYmptnVLyBdL0eG0cq47XxrHqNMTaOJ+/9njeMWeNbb5XdGvjeGRvZgYNObJvkhzszcyg5JdLcLA3M4N87owtag72ZmZAeu2zZDnYm5mBc/ZmZmXBaRwzszLgkb2ZWRmoXF7oHmTKwd7MDJzGMTMrC07jmJmVAY/szczKgIO9mVnpC1+gNTMrA87Zm5mVAadxzMzKgEf2ZmZlwCN7M7My4JG9mVkZqPDDS8zMSp9H9mZmZcA5ezOzMuCRvZlZGfDI3sysDHhkb2ZWBjwbx8ysDEQUugeZcrA3MwPn7M3MyoKDvZlZGfAFWjOzMlBZWegeZMrB3swMnMYxMysLDvZmZmXAOXszs9IXVaU9z75ZoTtgZtYkVFXlv9VA0maSHpM0TdJUSaes9PqZkkLS+umxJF0rabqklyXtlFN3oKQ3021gTvnOkqak51wrSbV9PAd7MzNIZuPku9WsAjgjIr4B9AaGSNoWki8C4PvAuzn19wO6pdtg4M9p3XWBC4BdgV7ABZLWSc/5c1p3xXn9auuUg72ZGTTYyD4iZkfEC+n+YmAa0Cl9+Wrgl0BuzuggYHQkngE6SNoY2BcYHxHzImI+MB7ol77WPiKejogARgMH1/bxnLNvJJ9/voyBQ85i2fLlVFZU8v29dufknx7FrA/+x1kXXMbCRYv5RvetuOz8M2nZsiUf/O9Dfv2bq5m3YCFrt2/HZeefxUYbdARg+z1+QLcunQHYeMOO/OmKCwE4d9jvmTR5Cm3XWguAS889nW26dy3Ex7UGsPba7Rkx/Hdst93WRATHH38Gzzz7PENOOpaTTjqWiooKHnroEYaecyn77L0Hl176K1q1asmyZcsZOnQYj034b6E/QnGpw2wcSYNJRtYrjIiIEdXU6wzsCDwr6YfA+xHx0kpZl07AeznHs9KymspnVVNeIwf7RtKqVUtGXnsZbdq0ZnlFBUefeCZ79O7J6Dvu46gjDmb/ffbkoiv+yD0PjKP/IQfwuz/dxA/77c1B+3+fZ5+fzB9uuJXLzj8LgDXWaMU9o66rtp0zhgyi7157NOZHs4xcfdXFjBv3GEf0H0zLli1p06Y1e37v2/zwwH3Zcad9WLZsGR07rgfAnLnzOPiQY5g9+0O2225rHnzgNrbYsmeBP0GRqcNCaGlg/1pwzyWpLXAPcCpJaudcoG91Vatroh7lNXIap5FIok2b1gBUVFRQUVGBJJ59/iX67pkE54P234dHn3gagLdmvsuuPXsA0GunHXjsP08XpuNWEO3atWWP3Xdl5C1jAFi+fDkLFy7ihBOO5oorr2PZsmUAfPzxXAAmT57K7NkfAjB16uusueaatGrVqjCdL1YNlMYBkNSSJNDfFhH3Al2BLYGXJL0NbAq8IGkjkpH5Zjmnbwp8UEv5ptWU1yjzYC+ptaSts26nGFRWVnLowCF894AB7LbLjmzWaWPatV2LFi2aA7Bhx/X5KP3Hu3W3LoxPfw3/9+NPsWTppyxYuAiAZcuWcfhxv+D/jj+VR5546ittXDt8FIccfSKXXzP8i4BgxadLly2YM2cuN990NROfG8fwG66kTZvWdOvWhd1378VTT/6DR/99Nz133uFr5/7oRz9g8uRX/PdfV1WR/1aDdGbMzcC0iLgKICKmRMQGEdE5IjqTBOydIuJ/wFjg6HRWTm9gYUTMBsYBfSWtk16Y7QuMS19bLKl32tbRwP21fbxMg72kA4HJwMPpcQ9JY7Nssylr3rw594y6jkfu+wtTXn2DGW+/97U6K3J5Zw75KZNenMJhxwxh0uQpbNhxPZo3T74Uxt8zmjtHXsvlF57N5dcM591ZyZf6qT87ln+MuZE7brqGhYsWc/Nf72q8D2cNqkXz5uy447cYPnw0u/TalyVLlnL2L0+mRYvmdOiwNt/e/UDOHjqMMX+74Svnbbttd3576a84ccjZBep5EWu42TjfAY4C+kianG7711D/QWAGMB24ETgJICLmAZcAE9Pt4rQM4ETgpvSct4CHautU1jn7C0mmDE0AiIjJ6QWLauVe9Lj+98P46dEDMu5eYbRv15Zddtqel6a+xuJPllBRUUmLFs358OM5dFx/XQA26Lge1/z21wAsXfop/57wJO3arvXFawCbddqYXXbcntfefIvNN93ki3NbtWrFwT/oy61j7inAp7OGMOv92cyaNZvnJr4IwL33/pNfnnUy78+azd//nvy7njhpMlVVVay//rrMmTOPTp025u67bubY405hxox3Ctn9ohQNtFxCRDxJ9Xn13Dqdc/YDGLKKeiOBkdWUTwK+WZd+ZZ3GqYiIhflWjogREdEzInqWWqCfN38BixZ/AsBnn3/OMxNfpEvnzei10/b8a8J/ALj/wX/TZ4/dAJi/YCFV6Q/fjX+5g0N+kFzXWbho8Re/ns9fsJAXp7xK186bA/DxnORLPyJ49Imn6NZli8b7gNagPvzwY2bN+oDu6WyqPn12Z9q0N7h/7Dj22us7AHTr1oVWrVoxZ8481l67PWPvH8255/2Wp56eVMiuF68GSuM0VVmP7F+R9H9Ac0ndgF8AT9VyTkn6eO58zh32OyqrqoiqYN8+e7Dnd3ala+fNOeuCy/jjiNF8o3tXfnRAEtQnvvgyf7jhViSx8w7f5LwzTgJgxjvvcfEVf0TNRFQFg448nK5bJkH97IuuYP6ChUQEW3frwgVn/bxgn9dW3ymn/ZrRo/5Iq1YtmTnzXQb99HSWLFnKTTf+nskvPsKyZcs5btCpAAw56Vi26tqZc391Kuf+Kinbb/8BX1zAtTyU+No4igyfuyipDV+dbjQOGBYRn9V27vI5M4rz69My1XoTTyu1r6tY9n6tywXUZsnFP8k75qx1/m2r3V5jy3pkv3VEnEsS8M3Mmq6K0n54SdY5+6skvSbpEknbZdyWmVn9RVX+WxHKNNhHxF7AnsDHwIh0lbbzsmzTzKxeSvwCbeY3VUXE/yLiWuBnJHPuz8+6TTOzuoqqqry3YpRpzl7SN4AjgMOAucDtwBlZtmlmVi9FOmLPV9YXaG8BxgB9I6LWtRvMzArGwb7+IqJ3lu9vZtZgal8GoahlEuwl3RkRh0uawleX3hTJ3cHbZ9GumVl9lfozaLMa2a945uIBGb2/mVnDKvFgn8lsnHQJToCTIuKd3I10RTczsyalAdezb4qynnr5/WrK9su4TTOzuivxefZZ5exPJBnBd5H0cs5L7QA/GNPMmp4iDeL5yipn/zeSxfR/CwzNKV+cs/i+mVmTEZXFmZ7JVybBPl3DfiEwAEDSBsCaQFtJbSPi3SzaNTOrN4/s6y99LOFVwCbAR8AWwDTAi6KZWZNS6lMvs75AOwzoDbwREVsCe+OcvZk1RSV+gTbrYL88IuYCzSQ1i4jHgB4Zt2lmVndVddiKUNZr4yyQ1BZ4ArhN0kdARcZtmpnVWVQUaRTPU9Yj+4OAT4HTgIeBt4ADM27TzKzuPLKvv4hYknM4Ksu2zMxWR6lfoM16Ns5ivroQGiRTMicBZ0TEjCzbNzPLW5GO2POVdc7+KuADkpusBPQHNgJeB0aSPLLQzKzgSn1kn3XOvl9EDI+IxRGxKCJGAPtHxB3AOhm3bWaWvxLP2Wcd7KskHS6pWbodnvNaaX+NmllRiYr8t2KUdbD/CXAUyd2zH6b7R0pqDZyccdtmZnmLqvy3YpT1bJwZrHqq5ZNZtm1mVidFGsTzlenIXlJ3SY9IeiU93l7SeVm2aWZWH6U+ss86jXMjcA6wHCAiXiaZkWNm1qSUerDPeuplm4h4TlJuWZFe3jCzUhaVqr1SEcs62M+R1JV05o2kw4DZNZ9iZtb4inXEnq+sg/0QYASwjaT3gZkkM3TMzJqUqCrtkX3WOfv3gVuAS4HbgfHAwIzbNDOrs4bM2UsaKemjFZNT0rIekp6RNFnSJEm90nJJulbSdEkvS9op55yBkt5Mt4E55TtLmpKec61WypVXJ+tgfz/J1MvlJMsmfAIsqfEMM7MCiFDeWx5uBfqtVHYFcFFE9ADOT48B9gO6pdtg4M8AktYFLgB2BXoBF0hasfLAn9O6K85bua2vyTqNs2lE1NoJM7NCa8icfUQ8IanzysVA+3R/bZIBMCRLwY+OiACekdRB0sYka4eNj4h5AJLGA/0kTQDaR8TTaflo4GDgoZr6VGuwl7QW8GlEVEnqDmwDPBQRy2s7F3hK0rciYkoedc3MCqaqDrNxJA0mGVmvMCJd+6smpwLjJP2OJKvy7bS8E/BeTr1ZaVlN5bOqKa9RPiP7J4A90l8fHiFZnvgI8rvQujtwjKSZwOckK19GRGyfx7lmZo2mLhdo08BeW3Bf2YnAaRFxT7pO2M3APiRx8WtN1KO8RvkEe0XEUkmDgD9GxBWSXszjPEhyUWZmTV4jzMYZCJyS7t8F3JTuzwI2y6m3KUmKZxZfXQZ+U2BCWr5pNfVrlM8FWknajWQk/8+0LK9cf0S8U92Wz7lmZo0pIv+tnj4Avpfu9wHeTPfHAkens3J6AwsjYjYwDugraZ00s9IXGJe+tlhS73QWztEkk2FqlE/QPpVkyYP7ImKqpC7AY3X4gGZmTV5DjuwljSEZla8vaRbJrJrjgWsktQA+48uc/4PA/sB0YClwLEBEzJN0CTAxrXfxiou1JCmhW4HWJBdma7w4C0mKZrU/WBaWz5nRNDtmBdV6kz0K3QVrgiqWvb/akfqtb+6bd8zp+sq4orsDa5Uje0n/oIakf0T8MJMemZkVQGUZr43zu0brhZlZgeV5s1TRWmWwj4jHG7MjZmaFVOpr4+RzU1U34LfAtsCaK8ojokuG/TIza1RN9PJlg8ln6uUtJOswVAB7AaOBv2TZKTOzxhZVynsrRvkE+9YR8QjJzJ13IuJCkjmiZmYlo7KqWd5bMcpnnv1nkpoBb0o6mWTZ4g2y7ZaZWeNyGie5qaoN8AtgZ+AovCa9mZWYqlDeWzGqdWQfESvu3vqE9M4uM7NSU7ZTL1eQ9BjV3FwVEc7bm1nJKPU0Tj45+zNz9tcEDiWZmZMp3xZv1dmlY/dCd8FKVLGmZ/KVTxrn+ZWK/ivJN1yZWUkp1lk2+conjbNuzmEzkou0G2XWIzOzAijxLE5eaZzn+fLpKBXATGBQlp0yM2tsZZ/GAb4REZ/lFkhaI6P+mJkVRKnPxsknSfVUNWVPN3RHzMwKqaoOWzGqaT37jUieWN5a0o58+ZDb9iQ3WZmZlYyo9jnepaOmNM6+wDEkD7P9PV8G+0XAr7LtlplZ46oo8TROTevZjwJGSTo0Iu5pxD6ZmTW6Uh/Z55Oz31lShxUH6ZPOh2XYJzOzRlfqOft8gv1+EbFgxUFEzCd5ErqZWckIlPdWjPKZetlc0hoR8TmApNaAp16aWUkp1hF7vvIJ9n8FHpF0S3p8LDAquy6ZmTW+yiIdsecrn7VxrpD0MrAPyYych4Etsu6YmVljKtKnDeYtn5E9wP9Ifss5nGS5BM/OMbOSUlWuI3tJ3YH+wABgLnAHyXNo92qkvpmZNZpyXgjtNeA/wIERMR1A0mmN0iszs0ZW6hdoa5p6eShJ+uYxSTdK2htK/PccMytbVVLeWzFaZbCPiPsi4ghgG2ACcBqwoaQ/S+rbSP0zM2sUlXXYilGtN1VFxJKIuC0iDiBZJ2cyMDTznpmZNaIq5b8Vozo9hysi5kXEcD9s3MxKTRXKeytG+U69NDMraeU8G8fMrGwUa3omXw72ZmaU99RLM7OyUan8t9pIGinpI0mv5JRdKek1SS9Lum+lpePPkTRd0uuS9s0p75eWTZc0NKd8S0nPSnpT0h2SWtXWJwd7MzMafD37W4F+K5WNB74ZEdsDbwDnAEjalmS1gu3Sc66X1FxSc+A6YD9gW2BAWhfgcuDqiOgGzAcG1dYhB3szMxo22EfEE8C8lcr+FREV6eEzJFPZAQ4Cbo+IzyNiJjAd6JVu0yNiRkQsA24HDpIkoA9wd3r+KODg2vrkYG9mBoTy3yQNljQpZxtcx+aOAx5K9zsB7+W8NistW1X5esCCnC+OFeU18gVaMzPqdoE2IkYAI+rTjqRzgQrgthVF1TVB9YPxqKF+jRzszcxonGUQJA0EDgD2jogVAXoWsFlOtU2BD9L96srnAB0ktUhH97n1V8lpHDMzsl8uQVI/4GzghxGxNOelsUB/SWtI2hLoBjwHTAS6pTNvWpFcxB2bfkk8BhyWnj8QuL+29h3szcxo2Au0ksYATwNbS5olaRDwJ6AdMF7SZEk3AETEVOBO4FWSJwEOiYjKdNR+MjAOmAbcmdaF5EvjdEnTSXL4N9fWJ6dxzMxo2JuqImJANcWrDMgRcSlwaTXlDwIPVlM+g2S2Tt4c7M3M8No4ZmZlwWvjmJmVgWJ9KEm+HOzNzICqEk/kONibmVH6q1462JuZ4Qu0ZmZlwSN7M7MyUKHSHts72JuZ4TSOmVlZcBrHzKwMeOqlmVkZKO1Q72BvZgY4jWNmVhYqS3xs72BvZoZH9mZmZSE8sjczK30e2Vvm1l67PSOG/47tttuaiOD4489gv/36cOCBfamqCj7+aA7H/fQ0Zs/+kO99dzfuvWckM99+D4C///1Bhl36hwJ/Amso9z4zhqWfLKWyqorKikqO2/9n9Dngeww6/Rg6d9ucQT84kddefgOAjTbdkNsnjOKdGcnPwtQXXuWKoVcD0KJlC84Ydgo7fXsHoiq44fKbmfDgEwX7XMXAUy8tc1dfdTHjxj3GEf0H07JlS9q0ac3UV1/ngguvBODkIcdx3rmnMeTkoQA8+eRzHHTIwEJ22TI05MensXD+oi+O33ptJuccfz5nX3b61+rOeucDBvY9/mvlx/ziSObPnc8RexyNJNp3aJdpn0tBaYd6B/uCa9euLXvsvivHDToVgOXLl7Nw4fKv1FlrrTYkD5S3cvTO9HfrfM4B/fej/3eTAUFEfOXLw6pXUeLhvlmWb67EkZLOT483l1Snh+SWui5dtmDOnLncfNPVTHxuHMNvuJI2bVoDcMnFZzPzrYkMGHAIF1505Rfn9O69M89PGs8DY//Cttt2L1TXLQMRwTVjruSWh4Zz0E8OqLX+JptvxKhxI7j+7j+wQ69vAdC2/VoADP7lcdz68HAuHX4B66y/Tqb9LgVRh/+KUabBHrge2A1Y8aT1xcB1q6osabCkSZImVVUtybhrTUOL5s3ZccdvMXz4aHbptS9Llizl7F+eDMCvz7+cLbvuwpgx9zHkpGMBeOHFKXTZqhc79/w+111/C/fcNbKQ3bcGdsLBP+eYfidw+pFnc+gxB9Nj1+1XWXfuR/M4uFd/Bu47mGsuup6LrjuPNm3b0Lx5czbcZANenvgKx/Q7gSnPv8rPz/9ZI36K4lRVh60YZR3sd42IIcBnABExH2i1qsoRMSIiekZEz2bN1sq4a03DrPdnM2vWbJ6b+CIA9977T3bs8a2v1Blz+30ccsj+ACxe/AlLliwF4KGHH6Vlyxast55HbaVizodzAZg/dwGPP/Qftu2xzSrrLl+2nEVpeub1KW/w/tsfsHmXTVk4fxGfLv2Uxx/6DwCPPjCBrb/p3wBr45H96lkuqTnptQ9JHSneL8ZMfPjhx8ya9QHdu3cFoE+f3Zk27Q222mrLL+oceEBfXn/9LQA23LDjF+W79OxBs2bNmDt3fuN22jKxZus1abNW6y/2d/1eT2a8PnOV9TusuzbNmiX/hDfZfGM227ITH7w7G4Anxz/NTt/uAUDP3Xfi7TffzrbzJaDUR/ZZX6C9FrgP2EDSpcBhwHkZt1l0Tjnt14we9UdatWrJzJnvMuinpzNi+JV0796Vqqoq3n33fU4akszEOfRHP+CEE46moqKSzz79jJ8ceVKBe28NZd2O63DZzZcA0Lx5c/7193/zzISJfK/f7pw+7Bd0WHdtfj/6t7wx9S1O+8kv6dF7B44/81gqKyupqqzkinOuZtGCxQBcf+kIzr/2HE69cAgL5i1k2GmXF/KjFYXKEp8EoaxneUjaBtgbEPBIREzL57wWrTqV9v95q5ddOjodYV/39PuPaXXf4/+2OCTvmPO3d+5b7fYaW6Yje0nXAHdExCovypqZNQXFmovPV9Y5+xeA8yRNl3SlpJ4Zt2dmVi+lnrPPNNhHxKiI2B/oBbwBXC7pzSzbNDOrjyoi760YNdYdtFsB2wCdgVcbqU0zs7yVehon65z95cCPgLeAO4FLImJBlm2amdVHqc/GyXpkPxPYLSLmZNyOmdlqKdb0TL4yCfaStomI14DngM0lbZ77ekS8kEW7Zmb1VawXXvOV1cj+dGAw8PtqXgugT0btmpnVi3P29RARg9Pd/SLis9zXJK2ZRZtmZqujIdM4kjoANwHfJBngHge8DtxBMlHlbeDwiJgvScA1wP7AUuCYFdkPSQP5ctWBYRExqr59ynqe/VN5lpmZFVRE5L3l4Rrg4YjYBtgBmAYMJVlFoBvwSHoMsB/QLd0GA38GkLQucAGwK8n09Qsk1XvVw6xy9hsBnYDWknYkWSoBoD3QJos2zcxWR2UDjewltQe+CxwDEBHLgGWSDgL2TKuNAiYAZwMHAaMj+RZ5RlIHSRundcdHxLz0fccD/YAx9elXVjn7fUk+6KbAVTnli4FfZdSmmVm91SWNI2kwySh8hRERMSLd7wJ8DNwiaQfgeeAUYMOImA0QEbMlbZDW7wS8l/Nes9KyVZXXS1Y5+1HAKEmHRsQ9WbRhZtaQ6rIoZBrYR6zi5RbATsDPI+LZdI2woauoC19mPr7SRA3l9ZJVGufIiPgr0FnS156SHBFXVXOamVnBNOAF2lnArIh4Nj2+myTYfyhp43RUvzHwUU79zXLO3xT4IC3fc6XyCfXtVFYXaFc8Zqot0K6azcysSWmoJ1VFxP+A9yRtnRbtTbJMzFhgYFo2ELg/3R8LHJ0+s7s3sDBN94wD+kpaJ70w2zctq5es0jjD0z8vyuL9zcwaWgMvl/Bz4DZJrYAZwLEkg+s7JQ0C3gV+nNZ9kGTa5XSSqZfHAkTEPEmXABPTehevuFhbH1mvjXMFMAz4FHiYZArSqWmKx8ysyWjIefYRMRmobkn3vaupG8CQVbzPSGBkQ/Qp63n2fSNiEXAASf6pO3BWxm2amdWZlzhePS3TP/cHxqS/lmTcpJlZ3WX9iNZCyzrY/0PSayRpnJMkdQQ+q+UcM7NGV6wj9nxl/aSqocBuQM+IWA4sIblbzMysSWmo2ThNVdYXaFsCRwHfTdM3jwM3ZNmmmVl9VEZpL3KcdRrnzyR5++vT46PSsp9m3K6ZWZ04Z796domIHXKOH5X0UsZtmpnVmXP2q6dSUtcVB5K6AJUZt2lmVmfO2a+es4DHJM1IjzuT3h1mZtaUVJV4Gifrkf1/geEkj3esSvefzrhNM7M688h+9YwGFgGXpMcDgL/w5ZoQZmZNgmfjrJ6tV7pA+5gv0JpZU+Q0zup5MV2yEwBJu5KkdszMmhSncVbPriTrNL+bHm8OTJM0hWSxt+0zbt/MLC+lPrLPOtj3y/j9zcwaRLGO2POVabCPiHeyfH8zs4ZSGaV9C1DWI3szs6Lg5RLMzMpAqS+X4GBvZoZH9mZmZcGzcczMyoBn45iZlQEvl2BmVgacszczKwPO2ZuZlQGP7M3MyoDn2ZuZlQGP7M3MyoBn45iZlQFfoDUzKwNO45iZlQHfQWtmVgY8sjczKwOlnrNXqX+blQJJgyNiRKH7YU2Lfy6sLpoVugOWl8GF7oA1Sf65sLw52JuZlQEHezOzMuBgXxycl7Xq+OfC8uYLtGZmZcAjezOzMuBgX2QkdZB0Us7xJpLuLmSfrHFJ+pmko9P9YyRtkvPaTZK2LVzvrKlyGqfISOoMPBAR3yxwV6wJkDQBODMiJhW6L9a0eWTfwCR1ljRN0o2Spkr6l6TWkrpKeljS85L+I2mbtH5XSc9ImijpYkmfpOVtJT0i6QVJUyQdlDZxGdBV0mRJV6btvZKe86yk7XL6MkHSzpLNzs2zAAAFVUlEQVTWkjQybePFnPeyRpb+fb0maZSklyXdLamNpL3Tv5sp6d/VGmn9yyS9mtb9XVp2oaQzJR0G9ARuS38eWqd/5z0lnSjpipx2j5H0x3T/SEnPpecMl9S8EP8vrJFFhLcG3IDOQAXQIz2+EzgSeATolpbtCjya7j8ADEj3fwZ8ku63ANqn++sD0wGl7//KSu29ku6fBlyU7m8MvJHu/wY4Mt3vALwBrFXo/1fluKV/XwF8Jz0eCZwHvAd0T8tGA6cC6wKv8+Vv4B3SPy8kGc0DTAB65rz/BJIvgI7A9Jzyh4DdgW8A/wBapuXXA0cX+v+Lt+w3j+yzMTMiJqf7z5P8A/82cJekycBwkmAMsBtwV7r/t5z3EPAbSS8D/wY6ARvW0u6dwI/T/cNz3rcvMDRtewKwJrB5nT+VNZT3IuK/6f5fgb1JfmbeSMtGAd8FFgGfATdJ+hGwNN8GIuJjYIak3pLWA7YG/pu2tTMwMf152Bvo0gCfyZo4L4SWjc9z9itJgvSCiOhRh/f4CcnobOeIWC7pbZIgvUoR8b6kuZK2B44ATkhfEnBoRLxeh/YtO3ldKIuICkm9SAJyf+BkoE8d2rmD5Ev/NeC+iAhJAkZFxDl17LMVOY/sG8ciYKakHwMosUP62jPAoel+/5xz1gY+SgP9XsAWaflioF0Nbd0O/BJYOyKmpGXjgJ+n/9CRtOPqfiBbLZtL2i3dH0Dym1tnSVulZUcBj0tqS/L3+CBJWqe6wUJNPw/3AgenbdyRlj0CHCZpAwBJ60raYhXnWwlxsG88PwEGSXoJmAqsuEh6KnC6pOdIUjsL0/LbgJ6SJqXnvgYQEXOB/0p6RdKV1bRzN8mXxp05ZZcALYGX04u5lzToJ7O6mgYMTFN06wJXA8eSpPmmAFXADSRB/IG03uMk12RWditww4oLtLkvRMR84FVgi4h4Li17leQawb/S9x3PlylFK2GeellgktoAn6a/YvcnuVjr2TIlylNnrVCcsy+8nYE/pSmWBcBxBe6PmZUgj+zNzMqAc/ZmZmXAwd7MrAw42JuZlQEHe2twkirTqYCvSLornXFU3/faU9ID6f4PJQ2toe5XVgStQxsXSjqzvn00KwYO9paFTyOiRzq9cBnJmj9fSG8qq/PPXkSMjYjLaqjSAahzsDcrBw72lrX/AFvpy9VArwdeADaT1FfS0+nKnneld4wiqV+6MuSTwI9WvFG6cuOf0v0NJd0n6aV0+zYrrQia1jsrXe3zZUkX5bzXuZJel/RvknVjzEqag71lRlILYD9gxbINWwOjI2JHYAnJnZz7RMROwCSSO4nXBG4EDgT2ADZaxdtfCzweETsAO5HclTwUeCv9reIsSX2BbkAvkqUGdpb0XUk7k9xlvCPJl8kuDfzRzZoc31RlWWidrqgIycj+ZmAT4J2IeCYt7w1sS7L0A0Ar4GlgG5IVIN8EkPRXYHA1bfQBjgaIiEpgoaR1VqrTN91eTI/bkgT/diQLgy1N2xi7Wp/WrAg42FsWPl15hc80oC/JLQLGR8SAler1IM9VIfMg4LcRMXylNk5twDbMioLTOFYozwDfWbHSo5KnNXUnWfBtS0ld03oDVnH+I8CJ6bnNJbXn6ytAjgOOy7kW0Cld7fEJ4JD0yU7tSFJGZiXNwd4KIn24xjHAmHT1xWeAbSLiM5K0zT/TC7TvrOItTgH2SleJfB7YbuUVQSPiXyQPhHk6rXc30C4iXiBZ8ncycA9JqsmspHltHDOzMuCRvZlZGXCwNzMrAw72ZmZlwMHezKwMONibmZUBB3szszLgYG9mVgYc7M3MysD/A61bpxZfNKFuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "with tf.Session() as session:\n",
    "    cm = tf.confusion_matrix(test_labels, test_pred_labels).eval()\n",
    "\n",
    "LABELS = ['negative', 'positive']\n",
    "sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS, fmt='g')\n",
    "xl = plt.xlabel(\"Predicted\")\n",
    "yl = plt.ylabel(\"Actuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('bert_security_model_weights_seq512b15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bert_security_model_seq512b15.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is not complete I still need to run some experiments but didn't get time considering it takes 4 hours per epoch :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
