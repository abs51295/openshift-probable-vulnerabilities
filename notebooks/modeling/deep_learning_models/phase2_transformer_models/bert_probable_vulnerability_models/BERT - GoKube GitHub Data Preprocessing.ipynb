{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re\n",
    "from concurrent import futures\n",
    "import threading\n",
    "import pandas as pd\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"lxml\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text, re.I)\n",
    "    return stripped_text\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = '((https?:\\/\\/)(\\s)*(www\\.)?|(www\\.))(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*'\n",
    "    text = re.sub(url_pattern, ' ', text, re.I)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_checklists(text):\n",
    "    checklist_pattern = r'\\[[xX\\.\\s]\\]'\n",
    "    text = re.sub(checklist_pattern, ' ', text, re.I | re.DOTALL)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-Z0-9/\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def pre_process_document(document):\n",
    "    # strip HTML\n",
    "    document = strip_html_tags(document)\n",
    "\n",
    "    # remove URLS\n",
    "    document = remove_urls(document)\n",
    "\n",
    "    # remove checklists\n",
    "    document = remove_checklists(document)\n",
    "\n",
    "    # expand contractions\n",
    "    #document = expand_contractions(document)\n",
    "\n",
    "    # lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # remove extra newlines (often might be present in really noisy text)\n",
    "    document = document.translate(document.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "\n",
    "    # remove accented characters\n",
    "    document = remove_accented_chars(document)\n",
    "\n",
    "    # remove special characters and\\or digits\n",
    "    # insert spaces between special characters to isolate them\n",
    "    #special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "    #document = special_char_pattern.sub(\" \\\\1 \", document)\n",
    "    #document = remove_special_characters(document, remove_digits=False)\n",
    "\n",
    "    # remove only numbers\n",
    "    #document = re.sub(r'\\b\\d+\\b', '', document)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    document = document.strip()\n",
    "\n",
    "    return document\n",
    "\n",
    "\n",
    "def parallel_preprocessing(idx, doc, total_docs):\n",
    "    if idx % 5000 == 0 or idx == (total_docs - 1):\n",
    "        print('{}: working on doc num: {}'.format(threading.current_thread().name,\n",
    "                                                  idx)\n",
    "    )\n",
    "    return pre_process_document(doc)\n",
    "\n",
    "\n",
    "def pre_process_documents_parallel(documents):\n",
    "    total_docs = len(documents)\n",
    "    docs_input = [[idx, doc, total_docs] for idx, doc in enumerate(documents)]\n",
    "    \n",
    "    ex = futures.ThreadPoolExecutor(max_workers=None)\n",
    "    print('preprocessing: starting')\n",
    "    norm_descriptions_map = ex.map(parallel_preprocessing, \n",
    "                                   [record[0] for record in docs_input],\n",
    "                                   [record[1] for record in docs_input],\n",
    "                                   [record[2] for record in docs_input])\n",
    "    norm_descriptions = list(norm_descriptions_map)\n",
    "    return norm_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152151 entries, 0 to 152150\n",
      "Data columns (total 2 columns):\n",
      "description    152151 non-null object\n",
      "label          152151 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/GH_complete_labeled_issues_prs.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['description'].values\n",
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing: starting\n",
      "ThreadPoolExecutor-0_0: working on doc num: 0\n",
      "ThreadPoolExecutor-0_4: working on doc num: 5000\n",
      "ThreadPoolExecutor-0_11: working on doc num: 10000\n",
      "ThreadPoolExecutor-0_18: working on doc num: 15000\n",
      "ThreadPoolExecutor-0_3: working on doc num: 20000\n",
      "ThreadPoolExecutor-0_8: working on doc num: 25000\n",
      "ThreadPoolExecutor-0_13: working on doc num: 30000\n",
      "ThreadPoolExecutor-0_16: working on doc num: 35000\n",
      "ThreadPoolExecutor-0_10: working on doc num: 40000\n",
      "ThreadPoolExecutor-0_16: working on doc num: 45000\n",
      "ThreadPoolExecutor-0_11: working on doc num: 50000\n",
      "ThreadPoolExecutor-0_19: working on doc num: 55000\n",
      "ThreadPoolExecutor-0_3: working on doc num: 60000\n",
      "ThreadPoolExecutor-0_9: working on doc num: 65000\n",
      "ThreadPoolExecutor-0_15: working on doc num: 70000\n",
      "ThreadPoolExecutor-0_12: working on doc num: 75000\n",
      "ThreadPoolExecutor-0_16: working on doc num: 80000\n",
      "ThreadPoolExecutor-0_4: working on doc num: 85000\n",
      "ThreadPoolExecutor-0_16: working on doc num: 90000\n",
      "ThreadPoolExecutor-0_15: working on doc num: 95000\n",
      "ThreadPoolExecutor-0_13: working on doc num: 100000\n",
      "ThreadPoolExecutor-0_12: working on doc num: 105000\n",
      "ThreadPoolExecutor-0_0: working on doc num: 110000\n",
      "ThreadPoolExecutor-0_1: working on doc num: 115000\n",
      "ThreadPoolExecutor-0_2: working on doc num: 120000\n",
      "ThreadPoolExecutor-0_10: working on doc num: 125000\n",
      "ThreadPoolExecutor-0_11: working on doc num: 130000\n",
      "ThreadPoolExecutor-0_1: working on doc num: 135000\n",
      "ThreadPoolExecutor-0_11: working on doc num: 140000\n",
      "ThreadPoolExecutor-0_4: working on doc num: 145000\n",
      "ThreadPoolExecutor-0_9: working on doc num: 150000\n",
      "ThreadPoolExecutor-0_3: working on doc num: 152150\n",
      "152151\n",
      "CPU times: user 2min 14s, sys: 28.9 s, total: 2min 43s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "norm_docs = pre_process_documents_parallel(documents=docs)\n",
    "print(len(norm_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152151 entries, 0 to 152150\n",
      "Data columns (total 2 columns):\n",
      "description    152151 non-null object\n",
      "label          152151 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrame({'description': norm_docs, \n",
    "                       'label': labels})\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openshift-node is logging private rsa keys to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>issue with auth not logging when it fails ther...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>webhook secrets are vulnerable to timing attac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sql: support placeholders for identifiers exam...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>syscall: guard against windows dll preloading ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  label\n",
       "0  openshift-node is logging private rsa keys to ...      2\n",
       "1  issue with auth not logging when it fails ther...      2\n",
       "2  webhook secrets are vulnerable to timing attac...      2\n",
       "3  sql: support placeholders for identifiers exam...      2\n",
       "4  syscall: guard against windows dll preloading ...      2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    128908\n",
       "1     22572\n",
       "2       671\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description     \n",
       "label          0\n",
       "Name: 1915, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[1915]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('./data/GH_complete_labeled_issues_prs - preprocessed.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
