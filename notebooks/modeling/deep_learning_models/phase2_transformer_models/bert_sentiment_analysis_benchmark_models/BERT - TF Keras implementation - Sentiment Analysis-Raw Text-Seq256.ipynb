{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 835MB\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze   1MB Jun 25 06:02 'BERT - TF Keras implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze   1MB Jun 21 13:11 'BERT Inference - TF Implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze   1MB Jun 21 13:11 'BERT Training - TF Implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze   1MB Jun 21 11:18  checkpoint\r\n",
      "drwxr-xr-x 2 redanalyze redanalyze   1MB Jun 21 10:02  eval\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze 623MB Jun 21 11:18  events.out.tfevents.1561110216.better-eve-instance\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze 193MB Jun 21 11:01  graph.pbtxt\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  20MB Jun 21 03:12  imdb_movie_reviews.csv.bz2\r\n",
      "drwxrwxr-x 3 redanalyze redanalyze   1MB Jun 21 12:55  tf_models\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l --block-size=MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0625 06:05:47.681380 139978309543744 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf_hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 25 06:05:49 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   67C    P0    31W /  70W |    213MiB / 15079MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     28636      C   /home/redanalyze/anaconda3/bin/python        203MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      "review       50000 non-null object\n",
      "sentiment    50000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./imdb_movie_reviews.csv.bz2', compression='bz2')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'] = [1 if sentiment == 'positive' else 0 \n",
    "                            for sentiment in dataset['sentiment'].values]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 2), (5000, 2), (15000, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = dataset.iloc[:30000]\n",
    "val_df = dataset.iloc[30000:35000]\n",
    "test_df = dataset.iloc[35000:]\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_df['review'].tolist()\n",
    "train_labels = train_df['sentiment'].tolist()\n",
    "\n",
    "val_text = val_df['review'].tolist()\n",
    "val_labels = val_df['sentiment'].tolist()\n",
    "\n",
    "test_text = test_df['review'].tolist()\n",
    "test_labels = test_df['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "       When running eval/predict on the TPU, we need to pad the number of examples\n",
    "       to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "       size. The alternative is to drop the last batch, which is bad because it means\n",
    "       the entire output data won't be generated.\n",
    "       We use this class instead of `None` because treating `None` as padding\n",
    "       batches could cause silent errors.\n",
    "  \"\"\"\n",
    "    \n",
    "    \n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module(bert_path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  tf_hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=text, text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Params for bert model and tokenization\n",
    "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "MAX_SEQ_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 06:05:56.444095 139978309543744 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path=BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_text, train_labels)\n",
    "val_examples = convert_text_to_examples(val_text, val_labels)\n",
    "test_examples = convert_text_to_examples(test_text, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77e58b7d0584d9eb79b4577d58dc11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=30000, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d2cc82bb7f4421aa4ee26eaacfffa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=5000, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6f867abd4f427599afd279e3cb19a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=15000, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(train_input_ids, train_input_masks, \n",
    " train_segment_ids, train_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
    "                                                                  examples=train_examples, \n",
    "                                                                  max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "(val_input_ids, val_input_masks, \n",
    " val_segment_ids, val_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
    "                                                              examples=val_examples, \n",
    "                                                              max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "(test_input_ids, test_input_masks, \n",
    " test_segment_ids, test_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
    "                                                                examples=test_examples, \n",
    "                                                                max_seq_length=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 256), (5000, 256), (15000, 256))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids.shape, val_input_ids.shape, test_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_hub.module.Module at 0x7f4e3b77fe10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = tf_hub.Module(BERT_PATH, trainable=True, name=f\"bert_module\")\n",
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'bert_module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/embeddings/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/embeddings/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>\n",
      "bert_module/bert/embeddings/position_embeddings:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>\n",
      "bert_module/bert/embeddings/token_type_embeddings:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>\n",
      "bert_module/bert/embeddings/word_embeddings:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/pooler/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/pooler/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>\n",
      "bert_module/cls/predictions/output_bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/cls/predictions/transform/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/cls/predictions/transform/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/cls/predictions/transform/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/cls/predictions/transform/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n"
     ]
    }
   ],
   "source": [
    "for var in bm.variables:\n",
    "    print(var)\n",
    "    print(var.name)\n",
    "    print('\\t\\t|')\n",
    "    print('\\t\\tV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bm.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder/layer_10\n",
      "encoder/layer_9\n",
      "encoder/layer_8\n",
      "encoder/layer_7\n",
      "encoder/layer_6\n",
      "encoder/layer_5\n"
     ]
    }
   ],
   "source": [
    "for i in range(5+1):\n",
    "    print(f\"encoder/layer_{str(10 - i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.layers.Layer):\n",
    "    \n",
    "    def __init__(self, bert_path, n_fine_tune_encoders=10, **kwargs,):\n",
    "        \n",
    "        self.n_fine_tune_encoders = n_fine_tune_encoders\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.bert_path = bert_path\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.bert = tf_hub.Module(self.bert_path,\n",
    "                                  trainable=self.trainable, \n",
    "                                  name=f\"{self.name}_module\")\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        trainable_vars = [var for var in trainable_vars \n",
    "                                  if not \"/cls/\" in var.name]\n",
    "        trainable_layers = [\"embeddings\", \"pooler/dense\"]\n",
    "\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_encoders+1):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(10 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [var for var in trainable_vars\n",
    "                                  if any([l in var.name \n",
    "                                              for l in trainable_layers])]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(input_ids=input_ids, \n",
    "                           input_mask=input_mask, \n",
    "                           segment_ids=segment_ids)\n",
    "        \n",
    "        pooled = self.bert(inputs=bert_inputs, \n",
    "                           signature=\"tokens\", \n",
    "                           as_dict=True)[\"pooled_output\"]\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(bert_path, max_seq_length, n_fine_tune_encoders=10): \n",
    "    \n",
    "    inp_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    inp_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    inp_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [inp_id, inp_mask, inp_segment]\n",
    "    \n",
    "    bert_output = BertLayer(bert_path=bert_path, \n",
    "                            n_fine_tune_encoders=n_fine_tune_encoders)(bert_inputs)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=tf.keras.optimizers.Adam(lr=2e-5), \n",
    "                  metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 06:09:24.016709 139978309543744 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 06:09:25.877933 139978309543744 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_path=BERT_PATH, max_seq_length=MAX_SEQ_LENGTH, n_fine_tune_encoders=10)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_1 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      bert_layer_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 109,679,361\n",
      "Non-trainable params: 622,650\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 2066s 69ms/step - loss: 0.2437 - acc: 0.8995 - val_loss: 0.2249 - val_acc: 0.9072\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 2046s 68ms/step - loss: 0.0972 - acc: 0.9673 - val_loss: 0.2283 - val_acc: 0.9190\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 2048s 68ms/step - loss: 0.0329 - acc: 0.9906 - val_loss: 0.3316 - val_acc: 0.8984\n",
      "Epoch 4/5\n",
      " 2550/30000 [=>............................] - ETA: 29:27 - loss: 0.0245 - acc: 0.9929"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-058334c3ce92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs=5,\n",
    "    batch_size=30,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 343s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(x=[test_input_ids, \n",
    "                                    test_input_masks, \n",
    "                                    test_segment_ids],\n",
    "                                 batch_size=15,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = [1 if prob > 0.5 else 0 for prob in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      7490\n",
      "           1       0.92      0.93      0.92      7510\n",
      "\n",
      "    accuracy                           0.92     15000\n",
      "   macro avg       0.92      0.92      0.92     15000\n",
      "weighted avg       0.92      0.92      0.92     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "with tf.Session() as session:\n",
    "    cm = tf.confusion_matrix(test_labels, test_pred_labels).eval()\n",
    "\n",
    "LABELS = ['negative', 'positive']\n",
    "sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS, fmt='g')\n",
    "xl = plt.xlabel(\"Predicted\")\n",
    "yl = plt.ylabel(\"Actuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('bert_sentiment_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bert_sentiment_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2596MB\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 25 08:10 'BERT - TF Keras implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 21 13:11 'BERT Inference - TF Implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 21 13:11 'BERT Training - TF Implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze 1320MB Jun 25 08:12  bert_sentiment_model.h5\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  442MB Jun 25 08:12  bert_sentiment_model_weights.h5\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 21 11:18  checkpoint\r\n",
      "drwxr-xr-x 2 redanalyze redanalyze    1MB Jun 21 10:02  eval\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  623MB Jun 21 11:18  events.out.tfevents.1561110216.better-eve-instance\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  193MB Jun 21 11:01  graph.pbtxt\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze   20MB Jun 21 03:12  imdb_movie_reviews.csv.bz2\r\n",
      "drwxrwxr-x 3 redanalyze redanalyze    1MB Jun 21 12:55  tf_models\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l --block-size=MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 08:16:19.465353 139978309543744 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 08:16:21.107729 139978309543744 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_2 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          196864      bert_layer_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            257         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 109,679,361\n",
      "Non-trainable params: 622,650\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = build_model(bert_path=BERT_PATH, max_seq_length=MAX_SEQ_LENGTH, n_fine_tune_encoders=10)\n",
    "initialize_vars(sess)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 366s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(x=[test_input_ids, \n",
    "                                    test_input_masks, \n",
    "                                    test_segment_ids],\n",
    "                                 batch_size=500,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.ravel()\n",
    "test_pred_labels = [1 if prob > 0.5 else 0 for prob in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.96      0.66      7490\n",
      "           1       0.52      0.04      0.07      7510\n",
      "\n",
      "    accuracy                           0.50     15000\n",
      "   macro avg       0.51      0.50      0.37     15000\n",
      "weighted avg       0.51      0.50      0.36     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEKCAYAAADticXcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XecVdW5//HPV4pSNDY6KhYIqFdRVKy5orlEiS2RWG6sMT+siYgldkzU1BtLkosKimI0CJJrvTaCYgdEwY6KIFcQFTtgmfb8/tgbOMIwcwZmzzlsvm9f+zV7r7PPXus4wzNrnrX22ooIzMwsH9YpdQPMzKzxOKibmeWIg7qZWY44qJuZ5YiDuplZjjiom5nliIO6mVmOOKibmeWIg7qZWY40L3UDVqbyo1m+1dVW0KrzPqVugpWhqop5Wt1rNCTmtNh0q9WuLyvuqZuZ5UjZ9tTNzJpUTXWpW9AoHNTNzACqq0rdgkbhoG5mBkTUlLoJjcJB3cwMoMZB3cwsP9xTNzPLEQ+UmpnliHvqZmb5EZ79YmaWIx4oNTPLEadfzMxyxAOlZmY54p66mVmOeKDUzCxHPFBqZpYfEc6pm5nlh3PqZmY54vSLmVmOuKduZpYj1ZWlbkGjcFA3MwOnX8zMcsXpFzOzHHFP3cwsRxzUzczyIzxQamaWI86pm5nliNMvZmY54p66mVmOuKduZpYj7qmbmeVIlR+SYWaWH+6pm5nliHPqZmY5kpOe+jqlboCZWVmoqSl+q4ekDSWNkzRD0uuS9pC0saTxkt5Kv26UnitJf5E0U9JLknYuuM7x6flvSTq+mI/hoG5mBklPvditftcCD0VET2BH4HXgfGBCRHQHJqTHAAcC3dNtEHAdgKSNgaFAX2A3YOiSXwR1cVA3M4Nk9kuxWx0kbQB8D7gJICIqIuIz4FBgVHraKOCwdP9Q4NZITAI2lNQJ+AEwPiI+iYhPgfHAAfV9DAd1MzOAiOK3um0FLABuljRN0o2S2gAdImJ+UlXMB9qn53cB3i14/9y0bGXldXJQNzODBuXUJQ2SNLVgG1RwpebAzsB1EbETsJhlqZbaqJayqKO8Tp79YmYGDZrSGBHDgeEreXkuMDciJqfH40iC+geSOkXE/DS98mHB+ZsVvL8r8F5avu9y5RPra5t76mZm0GgDpRHxPvCupO+mRfsDrwH3AktmsBwP3JPu3wscl86C2R34PE3PPAz0l7RROkDaPy2rk3vqZmYA1dWNebVfALdLagnMAk4k6USPlXQS8H/AT9JzHwAGADOBL9NziYhPJF0OPJee95uI+KS+ih3UzcygUe8ojYjpwC61vLR/LecGcPpKrjMSGNmQuh3UzczAywSYmeVKTpYJcFA3MwOipt7ZgmsEB3UzM3D6xcwsVxp39kvJOKibmYF76rbqZs+ZyzmX/m7p8dz35nPGz4/lgwUf8/jTk2neojmbdenEFRcOYYP12/LMlBe45vqbqaysokWL5px9+kn07dMbgJOHXMyCjz+huqqanXfcnovPPo1mzZqV6qNZI+natTO3jLyWDh3bUVNTw4033s5f/3YTAKefdiKnnXYiVVVVPPjgBM6/4EqOPvpHnD3k1KXv3+HferFr3wN48cVXS/UR1jw5CeqK+henKYnKj2aVZ8MaWXV1NfsddiyjR1zN7Dlz6dunN82bN+OqYck/4CGnncTrb85kk402on27TXhr1jucfNbFPHrPbQAsWryYtm3aEBGcddGV9N9vbwZ8f98SfqJsteq8T6mb0CQ6dmxPp47tmTb9Fdq2bcOUyQ9x+MCf0aF9Oy44/5ccfOhxVFRU0K7dJixY8PG33rv99j35n3Ej6dFzzxK1vulVVcyrbZ2UBvnympOLjjmtB9+w2vVlxT31Eps0dTqbdelE544d6Nyxw9LyHbbryfjHngKgV49tlpZvs+UWfFNRQUVFBS1btqRtmzYAVFVXU1lViWpdA8jWNO+//yHvv58sDbJo0WJmzHiLLp07ctJJP+WPf/pvKioqAFYI6ABHHXkYY8bes0K51SMnPfXM136R1KpgDQRbzoMTHmfA9/99hfK7/vcR9t5j1xXKx098il49tqZly5ZLywaddRH/ftDRtGndmv799s60vdb0ttiiK7133J7JU6bRvftW7L33bjzz1H08+q9x7NJnxxXO/8nAg7ljzN0laOkariaK38pYpkFd0sHAdOCh9Li3pHuzrHNNUllZycSnJtN/v2+nFG4YNZpmzZpxUP9+3yqfOWsOVw0byaXn/uJb5cOvvpLH7rmdiopKJj//YubttqbTpk1rxo4ZwZBzhrJw4SKaN2/Ghht+hz33PphfnX8Fo/9x/bfO323Xnfjyq6949dU3StTiNVh1dfFbGcu6p34ZyWOYPoOl6yF0W9nJhWsU33jr6IybVnpPTppKrx5bs+nGy55Qdc8D43ni6Sn8Yeh5SMtSKe9/uIAzL7yc315yDpt37bzCtdZdtyX99u7LY09OapK2W/aaN2/OnWNGMHr0Xdx994MAzJs7f+n+c1OnU1NTw6abbrz0PUcecShjxjj1siqipqborZxlnVOviojPC4NTXQrXKF4bBkofGD+RAf+x79LjpyZN5abb7+SWv/2RVuutt7T8i4WLOO3coQw++QR23mG7peVffvkVi7/8inabbkxVVTVPPDuVPjtuh+XDiOF/5vUZM7nm2mXLdt9z78P067cXjz/xLN27b0XLli356KNk4T5JHH74QfTb/8elavKarczTKsXKOqi/Iuk/gWaSugO/BJ7JuM41wldff82zz01j6Hm/XFp25VXDqKis5P8NvghIBkuHnvcLRv/zPt6d+x7X3zKa629J/oIZfs2VRARn/OoyKiorqamuoW+fHTnisB+W5PNY49prz1059piBvPTya0x97hEALrnk99x8yx3cOOLPTJ82gYqKSn520uCl7/nePrszb958Zs/+v1I1e82Wk7VfMp3SKKk1cBHJ4u6QLPB+RUR8Xd9714aeujXc2jKl0RqmMaY0Lv7NT4uOOW0uvb1sp5ll3VP/bkRcRBLYzczKV1V5D4AWK+uB0qskzZB0uSQne82sfDXS4+xKLdOgHhH9SB6cugAYLullSRdnWaeZ2SrxPPXiRMT7EfEX4BSSOeuXZl2nmVlDeUpjEST1Ao4EBgIfA3cAZ2dZp5nZKinzHnixsh4ovRkYDfSPiPcyrsvMbNU5qNcvInbP8vpmZo2mzG//L1YmQV3S2Ig4QtLLQOGvPwERETtkUa+Z2aryM0rrdmb69aCMrm9m1rhyEtQzmf0SEfPT3dMiYk7hBpyWRZ1mZqulpqb4rYxlPaXxP2opOzDjOs3MGi4n89SzyqmfStIj30rSSwUvrQ88nUWdZmarpcyDdbGyyqn/A3gQ+B1wfkH5woj4JKM6zcxWWVSXd1qlWJkE9Yj4HPgcOBpAUntgPaCtpLYR4bVBzay8uKdev/RxdlcBnYEPgS2A1wEv7mVmZSUvUxqzHii9AtgdeDMitgT2xzl1MytHORkozTqoV0bEx8A6ktaJiMeA3hnXaWbWcDUN2MpY1mu/fCapLfAEcLukD4GqjOs0M2uwqCrzaF2krHvqhwJfAWcBDwFvAwdnXKeZWcO5p16/iFhccDgqy7rMzFZHXgZKs579spBvL+gFyVTHqcDZETEry/rNzIpW5j3wYmWdU78KeI/kZiQBRwEdgTeAkSSPujMzK7m89NSzzqkfEBE3RMTCiPgiIoYDAyJiDLBRxnWbmRUvJzn1rIN6jaQjJK2TbkcUvJaPX4tmlgtRVfxWDEnNJE2TdH96fIuk2ZKmp1vvtFyS/iJppqSXJO1ccI3jJb2VbscXU2/W6ZefAtcCw0iC+CTgGEmtgDMyrtvMrGjR+D3wM0nuoN+goOzciBi33HkHAt3TrS9wHdBX0sbAUGAXkvj5vKR7I+LTuirNevbLLFY+hfGpLOs2M2uQRgzqkroCPwSuBIbUc/qhwK0REcAkSRtK6kQy5jh+ySKIksYDB5A893mlMk2/SOohaYKkV9LjHSRdnGWdZmarImqK3yQNkjS1YBu03OWuAc5jxV8VV6YplqslrZuWdQHeLThnblq2svI6ZZ1THwFcAFQCRMRLJDNgzMzKSkOCekQMj4hdCrbhS64j6SDgw4h4frkqLgB6ArsCGwO/WvKW2ppTR3mdsg7qrSNiynJlXibAzMpOVKvorR57AYdIege4A9hP0m0RMT8S3wA3A7ul588FNit4f1eSqeArK69T1kH9I0lbk/52kTQQmF/3W8zMml5Deup1XifigojoGhHdSDITj0bEMWmeHEkCDgNeSd9yL3BcOgtmd+Dz9DnPDwP9JW0kaSOgf1pWp6xnv5wODAd6SpoHzCaZEWNmVlaipt4e+Oq6XVI7krTKdOCUtPwBYAAwE/gSOBEgIj6RdDnwXHreb4p5cpySAddspAMBA4FuJDmkL4CIiN/U997Kj2Z5HrutoFXnfUrdBCtDVRXzVjsiv7dnv6JjTudnHsv8N8Cqyrqnfg/wGfACReSCzMxKJaJs43SDZB3Uu0bEARnXYWa22jK4+agk6h0oldRG0jrpfg9Jh0hqUeT1n5H0b6vVQjOzJlBTraK3clZMT/0JYJ909HUCybK5R1LcgOfewAmSZgPfkAwQRETssIrtNTPLRBMMlDaJYoK6IuJLSScBf42IP0qaVuT1D1yNtpmZNZm1KqhL2oOkZ35SA95HRMxZ1YaZmTWlDCcCNqligvNgkttb74qIVyVtBTyWbbPMzJrWWtNTj4jHgccLjmcBv8yyUWZmTS33Uxol3Ucdi8dExCGZtMjMrASqy3xWS7Hq6qn/V5O1wsysxHLfU0/TLmZma4W1JqcuqTvwO2BbYL0l5RGxVYbtMjNrUnmZ/VLM0rs3kzwzrwroB9wK/D3LRpmZNbWoUdFbOSsmqLeKiAkkNyHNiYjLgP2ybZaZWdOqrlmn6K2cFTNP/et07Ze3JJ0BzAPaZ9ssM7OmtTalXwYDrUnmpvcBjgWOz7JRZmZNrSZU9FbOirn5aMlTNxaRPpHDzCxvcj+lcQlJj1HLTUgR4by6meVGXtIvxeTUzynYXw84nGQmjJlZbpR7WqVYxaRfnl+u6GlJvjHJzHKl3Ge1FKuY9MvGBYfrkAyWdsysRWZmJZCT7EtR6ZfnST6vSNIus1m2rrqZWS6sNekXoFdEfF1YIGndjNpjZlYSeZn9UkwS6Zlayp5t7IaYmZVSTQO2clbXeuodgS5AK0k7kaRfADYguRnJzCw3gnz01OtKv/wAOAHoCvyZZUH9C+DCbJtlZta0qnKSfqlrPfVRwChJh0fEP5uwTWZmTS4vPfVicup9JG245EDSRpKuyLBNZmZNLi859WKC+oER8dmSg4j4FBiQXZPMzJpeoKK3clbMlMZmktaNiG8AJLUCPKXRzHKl3HvgxSomqN8GTJB0c3p8IjAquyaZmTW96jLvgRermLVf/ijpJeD7JDNgHgK2yLphZmZNqcyfUle0YnrqAO+T/HVyBMkyAZ4NY2a5UpP3nrqkHsBRwNHAx8AYkueU9muitpmZNZm1YUGvGcCTwMERMRNA0llN0iozsyaWl4HSuqY0Hk6SdnlM0ghJ+0NO/j4xM1tOjVT0Vs5WGtQj4q6IOBLoCUwEzgI6SLpOUv8map+ZWZOobsBWzuq9+SgiFkfE7RFxEMk6MNOB8zNvmZlZE6pR8Vs5a9DzmyLik4i4wQ+dNrO8qUFFb3WRtJ6kKZJelPSqpF+n5VtKmizpLUljJLVMy9dNj2emr3cruNYFafkbkn5QzOfIx0P5zMxWUzRgq8c3wH4RsSPQGzhA0u7AH4CrI6I78CnLniB3EvBpRGwDXJ2eh6RtSWYgbgccAAyT1Ky+yh3UzcxovPRLJBalhy3SLYD9gHFp+SjgsHT/UJbdpT8O2F+S0vI7IuKbiJgNzAR2q+9zOKibmdGwVRolDZI0tWAbVHgtSc0kTQc+BMYDbwOfRURVespckocQkX59FyB9/XNgk8LyWt6zUsXeUWpmlmvVDRgAjYjhwPA6Xq8GeqfLlt8F9KrttPRrbTVHHeV1ck/dzIxs1lNPly2fCOwObChpSUe6K/Beuj8X2Awgff07wCeF5bW8Z6Uc1M3MaLygLqndkgcLpUuVfx94HXgMGJiedjxwT7p/b3pM+vqjERFp+VHp7Jgtge7AlPo+h9MvZmZAIz6itBPJo0CbkXScx0bE/ZJeA+5Inxw3DbgpPf8m4O+SZpL00I8CiIhXJY0FXgOqgNPTtE6dHNTNzGi8tV8i4iVgp1rKZ1HL7JWI+Br4yUqudSVwZUPqd1A3M6P8b/8vloO6mRnlf/t/sRzUzczIz9K7DupmZjiom5nlytrw5CMzs7WGc+pmZjni2S9mZjlSk5MEjIO6mRkeKDUzy5V89NMd1M3MAPfUzcxypUr56Ks7qJuZ4fSLmVmuOP1iZpYjntJoZpYj+QjpDupmZoDTL2ZmuVKdk766g7qZGe6pm5nlSrinbmaWH+6p2yqbPWcu51z6u6XHc9+bzxk/P5YPFnzM409PpnmL5mzWpRNXXDiEDdZvyzNTXuCa62+msrKKFi2ac/bpJ9G3T28AXp3xFhdfeRVff/MN++yxKxcMPgUpJwtDr8W6du3MLSOvpUPHdtTU1HDjjbfz17/dxA47bMuwv/2eNm1bM2fOXI497gwWLlwEwK/OO4MTTziK6poazjrrEh4Z/3iJP8WaJS9TGhVRnh+k8qNZ5dmwRlZdXc1+hx3L6BFXM3vOXPr26U3z5s24athNAAw57SRef3Mmm2y0Ee3bbcJbs97h5LMu5tF7bgPgqJ+fyfmDT2HH7Xpy6jmX8tOBh7DPHruW8iNlqlXnfUrdhCbRsWN7OnVsz7Tpr9C2bRumTH6Iwwf+jJE3XcOvfnU5Tzw5iROOP5Itt9ycoZf9iV69unPb34exx54/pHPnDjz84B302m4famry0v+sW1XFvNXuyZza7YiiY85174wt257TOqVuwNpu0tTpbNalE507dmCvvn1o3rwZADts15MPPvwIgF49tqF9u00A2GbLLfimooKKigoWfPQJixd/Se/teyGJQw7Yn0effLZkn8Uaz/vvf8i06a8AsGjRYmbMeIsunTvy3R5b88STkwD414Qn+dGPBgBwyME/YOzYe6ioqOCdd97l7bffYbdddypZ+9dEVUTRWznLNKgrcYykS9PjzSXtlmWda5oHJzzOgO//+wrld/3vI+xdS497/MSn6NVja1q2bMkHCz6iQ/tNl77Wod2mfLDg40zba01viy260nvH7Zk8ZRqvvvoGBx/cH4CBhx/EZl07A9C5c0fenfve0vfMnTefzl06lqS9a6powH/lLOue+jBgD+Do9Hgh8N8rO1nSIElTJU298dbRGTet9CorK5n41GT67/ftlMINo0bTrFkzDurf71vlM2fN4aphI7n03F8AtY/WO52eL23atGbsmBEMOWcoCxcu4ueDhnDaKScwedKDrL9+GyoqKgFqHUcp19RquappwFbOsh4o7RsRO0uaBhARn0pqubKTI2I4MBzWjpz6k5Om0qvH1my68UZLy+55YDxPPD2FG//yu2/9Q33/wwWceeHl/PaSc9g87Z11bNduaYoG4IMFH9F+002a7gNYppo3b86dY0YwevRd3H33gwC88cbbHPjD/wSge/etGHDg/gDMmzd/aa8doGuXTsx/74Omb/QarNx74MXKuqdeKakZ6bIKktpR/r/omswD4ycy4D/2XXr81KSp3HT7nfz1D0Nptd56S8u/WLiI084dyuCTT2DnHbZbWt5u041p3boVL77yOhHBvQ9NoN/euzflR7AMjRj+Z16fMZNrrh2+tKxdOrYiiQsvOJMbhv8dgPvuf4QjjjiUli1b0q3bZmyzzZZMeW5aSdq9pnJPvTh/Ae4C2ku6EhgIXJxxnWuEr77+mmefm8bQ8365tOzKq4ZRUVnJ/xt8EZAMlg497xeM/ud9vDv3Pa6/ZTTX35KkpYZfcyWbbLQhl5xzxrIpjbvvmuuZL2uTvfbclWOPGchLL7/G1OceAeCSS37PNttsyamnngDA3Xc/wC2jxgDw2mtvMm7cfbz84mNUVVfzyzMvWmtmvjSW6pykqzKf0iipJ7A/IGBCRLxezPvWhvSLNdzaMqXRGqYxpjT+5xY/Kjrm/GPOXWU7epVpT13StcCYiFjp4KiZWTlwTr04LwAXS5op6U+Sdsm4PjOzVZKXnHqmQT0iRkXEAGA34E3gD5LeyrJOM7NVUUMUvZWzplr7ZRugJ9ANeK2J6jQzK1pe0i9Z59T/APwYeBsYC1weEZ9lWaeZ2arIy+yXrHvqs4E9IuKjes80Myuhck+rFCuToC6pZ0TMAKYAm0vavPD1iHghi3rNzFZVuQ+AFiurnvoQYBDw51peC2C/jOo1M1slecmpZzL7JSIGpbsHRkS/wg0YkEWdZmarozFnv0gaKelDSa8UlF0maZ6k6ek2oOC1C9Kp329I+kFB+QFp2UxJ5xfzObKep/5MkWVmZiUVEUVvRbgFOKCW8qsjone6PQAgaVvgKGC79D3DJDVL1836b+BAYFvg6PTcOmWVU+8IdAFaSdqJZIkAgA2A1lnUaWa2OqobMf0SEU9I6lbk6YcCd0TEN8BsSTNJ7u0BmBkRswAk3ZGeW+e08Kxy6j8ATgC6AlcVlC8ELsyoTjOzVdaQ2S+SBpGMGy4xPF06vD5nSDoOmAqcHRGfknSAJxWcMzctA3h3ufK+9VWQSVCPiFHAKEmHR8Q/s6jDzKwxNWRxw8JnPzTAdcDlJJNFLieZSPIzlmUyvlUFtafH621kVumXYyLiNqCbpCErtCriqlreZmZWMlnPU4+IpU8tkTQCuD89nAtsVnBqV2DJswlXVr5SWQ2Utkm/tgXWr2UzMysrWT+jVFKngsMfAUtmxtwLHCVpXUlbAt1J7vF5Duguacv0iXFHpefWKav0yw3p119ncX0zs8bWmMsESBoN7AtsKmkuMBTYV1JvkhTKO8DJABHxqqSxJAOgVcDpEVGdXucM4GGgGTAyIl6tt+4sH5Ih6Y/AFcBXwEPAjsDgNDVTJz8kw2rjh2RYbRrjIRl7ddmv6Jjz9LxHy/YhGVnPU+8fEV8AB5HkjXoA52Zcp5lZg3np3eK0SL8OAEZHxCdS2f6CM7O1WNaP9mwqWQf1+yTNIEm/nCapHfB1xnWamTVYuffAi5X1k4/OB/YAdomISmAxyR1RZmZlJevZL00l64dktACOBb6Xpl0eB67Psk4zs1VRHflYfDfr9Mt1JHn1YenxsWnZzzOu18ysQZxTL86uEbFjwfGjkl7MuE4zswZzTr041ZK2XnIgaSugOuM6zcwazDn14pwLPCZpVnrcDTgx4zrNzBqsJifpl6x76k8DN5A8/q8m3X824zrNzBrMPfXi3Ap8QbLMJMDRwN+Bn2Rcr5lZg3j2S3G+u9xA6WMeKDWzcuT0S3GmSdp9yYGkviQpGTOzsuL0S3H6AsdJ+r/0eHPgdUkvAxERO2Rcv5lZUfLSU886qNf2NG0zs7JT7j3wYmUa1CNiTpbXNzNrLNWRj1tosu6pm5mtEbxMgJlZjuRlmQAHdTMz3FM3M8sVz34xM8sRz34xM8sRLxNgZpYjzqmbmeWIc+pmZjninrqZWY54nrqZWY64p25mliOe/WJmliMeKDUzyxGnX8zMcsR3lJqZ5Yh76mZmOZKXnLry8tspzyQNiojhpW6HlRf/XFht1il1A6wog0rdACtL/rmwFTiom5nliIO6mVmOOKivGZw3tdr458JW4IFSM7MccU/dzCxHHNTXMJI2lHRawXFnSeNK2SZrWpJOkXRcun+CpM4Fr90oadvStc5KzemXNYykbsD9EbF9iZtiZUDSROCciJha6rZYeXBPvZFJ6ibpdUkjJL0q6RFJrSRtLekhSc9LelJSz/T8rSVNkvScpN9IWpSWt5U0QdILkl6WdGhaxe+BrSVNl/SntL5X0vdMlrRdQVsmSuojqY2kkWkd0wquZU0s/X7NkDRK0kuSxklqLWn/9Hvzcvq9Wjc9//eSXkvP/a+07DJJ50gaCOwC3J7+PLRKv+e7SDpV0h8L6j1B0l/T/WMkTUnfc4OkZqX4f2EZiQhvjbgB3YAqoHd6PBY4BpgAdE/L+gKPpvv3A0en+6cAi9L95sAG6f6mwExA6fVfWa6+V9L9s4Bfp/udgDfT/d8Cx6T7GwJvAm1K/f9qbdzS71cAe6XHI4GLgXeBHmnZrcBgYGPgDZb9Rb1h+vUykt45wERgl4LrTyQJ9O2AmQXlDwJ7A72A+4AWafkw4LhS/3/x1nibe+rZmB0R09P950n+Ie8J3ClpOnADSdAF2AO4M93/R8E1BPxW0kvAv4AuQId66h0L/CTdP6Lguv2B89O6JwLrAZs3+FNZY3k3Ip5O928D9if5mXkzLRsFfA/4AvgauFHSj4Evi60gIhYAsyTtLmkT4LvA02ldfYDn0p+H/YGtGuEzWZnwgl7Z+KZgv5okGH8WEb0bcI2fkvS2+kREpaR3SILxSkXEPEkfS9oBOBI4OX1JwOER8UYD6rfsFDWQFRFVknYjCbxHAWcA+zWgnjEkv9xnAHdFREgSMCoiLmhgm20N4Z560/gCmC3pJwBK7Ji+Ngk4PN0/quA93wE+TAN6P2CLtHwhsH4ddd0BnAd8JyJeTsseBn6R/oNG0k6r+4FstWwuaY90/2iSv8S6SdomLTsWeFxSW5Lv4wMk6ZjaOgV1/Tz8D3BYWseYtGwCMFBSewBJG0vaYiXvtzWQg3rT+SlwkqQXgVeBJYOVg4EhkqaQpGQ+T8tvB3aRNDV97wyAiPgYeFrSK5L+VEs940h+OYwtKLscaAG8lA6qXt6on8wa6nXg+DS1tjFwNXAiSXruZaAGuJ4kWN+fnvc4yZjJ8m4Brl8yUFr4QkR8CrwGbBERU9Ky10hy+I+k1x3PslSg5YCnNJaYpNbAV+mfxkeRDJp6dkpOeUqqZc059dLrA/wtTY18BvysxO0xszWYe+pmZjninLqZWY44qJuZ5YiDuplZjjioW6OTVJ1OsXt7fs85AAACNUlEQVRF0p3pDJ9Vvda+ku5P9w+RdH4d535rBcsG1HGZpHNWtY1m5cRB3bLwVUT0TqftVZCsabNUevNVg3/2IuLeiPh9HadsCDQ4qJvliYO6Ze1JYBstW71yGPACsJmk/pKeTVeivDO9gxJJB6QrGT4F/HjJhdKVBv+W7neQdJekF9NtT5ZbwTI979x0dcqXJP264FoXSXpD0r9I1kUxywUHdcuMpObAgcCS5Qq+C9waETsBi0nubPx+ROwMTCW5s3Y9YARwMLAP0HEll/8L8HhE7AjsTHKX7vnA2+lfCedK6g90B3YjucW+j6TvSepDctftTiS/NHZt5I9uVjK++ciy0CpdARCSnvpNQGdgTkRMSst3B7YlWfIAoCXwLNCTZMXCtwAk3QYMqqWO/YDjACKiGvhc0kbLndM/3aalx21Jgvz6JAtcfZnWce9qfVqzMuKgbln4avkVKdPAvbiwCBgfEUcvd15vilzFsAgCfhcRNyxXx+BGrMOsrDj9YqUyCdhrycqESp7+04Nk4bItJW2dnnf0St4/ATg1fW8zSRuw4oqFDwM/K8jVd0lXJ3wC+FH6pKD1SVI9ZrngoG4lkT7E4QRgdLpa4CSgZ0R8TZJu+d90oHTOSi5xJtAvXdXweWC75VewjIhHSB488mx63jhg/Yh4gWQp2unAP0lSRGa54LVfzMxyxD11M7MccVA3M8sRB3UzsxxxUDczyxEHdTOzHHFQNzPLEQd1M7MccVA3M8uR/w/FZA9SuB8J7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    cm = tf.confusion_matrix(test_labels, test_pred_labels).eval()\n",
    "\n",
    "LABELS = ['negative', 'positive']\n",
    "sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS, fmt='g')\n",
    "xl = plt.xlabel(\"Predicted\")\n",
    "yl = plt.ylabel(\"Actuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('bert_sentiment_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 366s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(x=[test_input_ids, \n",
    "                                    test_input_masks, \n",
    "                                    test_segment_ids],\n",
    "                                 batch_size=500,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.ravel()\n",
    "test_pred_labels = [1 if prob > 0.5 else 0 for prob in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      7490\n",
      "           1       0.92      0.93      0.92      7510\n",
      "\n",
      "    accuracy                           0.92     15000\n",
      "   macro avg       0.92      0.92      0.92     15000\n",
      "weighted avg       0.92      0.92      0.92     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    cm = tf.confusion_matrix(test_labels, test_pred_labels).eval()\n",
    "\n",
    "LABELS = ['negative', 'positive']\n",
    "sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS, fmt='g')\n",
    "xl = plt.xlabel(\"Predicted\")\n",
    "yl = plt.ylabel(\"Actuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
