{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2596MB\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jul  1 02:01 'BERT - TF Keras implementation - Sentiment Analysis-Copy1.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jul  1 02:00 'BERT - TF Keras implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 21 13:11 'BERT Inference - TF Implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 21 13:11 'BERT Training - TF Implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze 1320MB Jun 25 08:12  bert_sentiment_model.h5\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  442MB Jun 25 08:12  bert_sentiment_model_weights.h5\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 21 11:18  checkpoint\r\n",
      "drwxr-xr-x 2 redanalyze redanalyze    1MB Jun 21 10:02  eval\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  623MB Jun 21 11:18  events.out.tfevents.1561110216.better-eve-instance\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  193MB Jun 21 11:01  graph.pbtxt\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze   20MB Jun 21 03:12  imdb_movie_reviews.csv.bz2\r\n",
      "drwxrwxr-x 3 redanalyze redanalyze    1MB Jun 21 12:55  tf_models\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l --block-size=MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf_hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  1 02:02:31 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   63C    P0    30W /  70W |    213MiB / 15079MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     14494      C   /home/redanalyze/anaconda3/bin/python        203MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      "review       50000 non-null object\n",
      "sentiment    50000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./imdb_movie_reviews.csv.bz2', compression='bz2')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'] = [1 if sentiment == 'positive' else 0 \n",
    "                            for sentiment in dataset['sentiment'].values]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 2), (5000, 2), (15000, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = dataset.iloc[:30000]\n",
    "val_df = dataset.iloc[30000:35000]\n",
    "test_df = dataset.iloc[35000:]\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_df['review'].tolist()\n",
    "train_labels = train_df['sentiment'].tolist()\n",
    "\n",
    "val_text = val_df['review'].tolist()\n",
    "val_labels = val_df['sentiment'].tolist()\n",
    "\n",
    "test_text = test_df['review'].tolist()\n",
    "test_labels = test_df['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_doc_lens = [len(doc.split(' ')) for doc in train_text]\n",
    "o = plt.hist(train_doc_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "       When running eval/predict on the TPU, we need to pad the number of examples\n",
    "       to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "       size. The alternative is to drop the last batch, which is bad because it means\n",
    "       the entire output data won't be generated.\n",
    "       We use this class instead of `None` because treating `None` as padding\n",
    "       batches could cause silent errors.\n",
    "  \"\"\"\n",
    "    \n",
    "    \n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module(bert_path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  tf_hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=text, text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Params for bert model and tokenization\n",
    "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "MAX_SEQ_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0701 02:02:46.433641 140267069904704 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path=BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_text, train_labels)\n",
    "val_examples = convert_text_to_examples(val_text, val_labels)\n",
    "test_examples = convert_text_to_examples(test_text, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52ee17e942d4604a5f86e62d3d0dd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=30000, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14996b04ad6e4b4097caa27c28e5b0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=5000, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea419fd57e14cf7869027583310511f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=15000, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(train_input_ids, train_input_masks, \n",
    " train_segment_ids, train_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
    "                                                                  examples=train_examples, \n",
    "                                                                  max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "(val_input_ids, val_input_masks, \n",
    " val_segment_ids, val_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
    "                                                              examples=val_examples, \n",
    "                                                              max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "(test_input_ids, test_input_masks, \n",
    " test_segment_ids, test_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
    "                                                                examples=test_examples, \n",
    "                                                                max_seq_length=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 512), (5000, 512), (15000, 512))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids.shape, val_input_ids.shape, test_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_hub.module.Module at 0x7f924980c550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = tf_hub.Module(BERT_PATH, trainable=True, name=f\"bert_module\")\n",
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'bert_module/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/embeddings/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/embeddings/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>\n",
      "bert_module/bert/embeddings/position_embeddings:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>\n",
      "bert_module/bert/embeddings/token_type_embeddings:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float32>\n",
      "bert_module/bert/embeddings/word_embeddings:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_0/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_1/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_10/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_11/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_2/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_3/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_4/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_5/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_6/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_7/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_8/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/key/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/key/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/query/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/query/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/value/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/attention/self/value/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/intermediate/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/intermediate/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/output/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/output/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/output/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "bert_module/bert/encoder/layer_9/output/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/bert/pooler/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/bert/pooler/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/output_bias:0' shape=(30522,) dtype=float32>\n",
      "bert_module/cls/predictions/output_bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "bert_module/cls/predictions/transform/LayerNorm/beta:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "bert_module/cls/predictions/transform/LayerNorm/gamma:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>\n",
      "bert_module/cls/predictions/transform/dense/bias:0\n",
      "\t\t|\n",
      "\t\tV\n",
      "<tf.Variable 'bert_module/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "bert_module/cls/predictions/transform/dense/kernel:0\n",
      "\t\t|\n",
      "\t\tV\n"
     ]
    }
   ],
   "source": [
    "for var in bm.variables:\n",
    "    print(var)\n",
    "    print(var.name)\n",
    "    print('\\t\\t|')\n",
    "    print('\\t\\tV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bm.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder/layer_10\n",
      "encoder/layer_9\n",
      "encoder/layer_8\n",
      "encoder/layer_7\n",
      "encoder/layer_6\n",
      "encoder/layer_5\n",
      "encoder/layer_4\n",
      "encoder/layer_3\n",
      "encoder/layer_2\n",
      "encoder/layer_1\n",
      "encoder/layer_0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10+1):\n",
    "    print(f\"encoder/layer_{str(10 - i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.layers.Layer):\n",
    "    \n",
    "    def __init__(self, bert_path, n_fine_tune_encoders=10, **kwargs,):\n",
    "        \n",
    "        self.n_fine_tune_encoders = n_fine_tune_encoders\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.bert_path = bert_path\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.bert = tf_hub.Module(self.bert_path,\n",
    "                                  trainable=self.trainable, \n",
    "                                  name=f\"{self.name}_module\")\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        trainable_vars = [var for var in trainable_vars \n",
    "                                  if not \"/cls/\" in var.name]\n",
    "        trainable_layers = [\"embeddings\", \"pooler/dense\"]\n",
    "\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_encoders+1):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(10 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [var for var in trainable_vars\n",
    "                                  if any([l in var.name \n",
    "                                              for l in trainable_layers])]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:# and 'encoder/layer' not in var.name:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        print('Trainable layers:', len(self._trainable_weights))\n",
    "        print('Non Trainable layers:', len(self._non_trainable_weights))\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(input_ids=input_ids, \n",
    "                           input_mask=input_mask, \n",
    "                           segment_ids=segment_ids)\n",
    "        \n",
    "        pooled = self.bert(inputs=bert_inputs, \n",
    "                           signature=\"tokens\", \n",
    "                           as_dict=True)[\"pooled_output\"]\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(bert_path, max_seq_length, n_fine_tune_encoders=10): \n",
    "    \n",
    "    inp_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    inp_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    inp_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [inp_id, inp_mask, inp_segment]\n",
    "    \n",
    "    bert_output = BertLayer(bert_path=bert_path, \n",
    "                            n_fine_tune_encoders=n_fine_tune_encoders)(bert_inputs)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=tf.keras.optimizers.Adam(lr=2e-5), \n",
    "                  metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0701 02:06:06.637487 140267069904704 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers: 199\n",
      "Non Trainable layers: 5\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0701 02:06:08.384334 140267069904704 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_path=BERT_PATH, max_seq_length=MAX_SEQ_LENGTH, n_fine_tune_encoders=10)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_1 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      bert_layer_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 109,679,361\n",
      "Non-trainable params: 622,650\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "30000/30000 [==============================] - 4427s 148ms/step - loss: 0.2086 - acc: 0.9178 - val_loss: 0.1599 - val_acc: 0.9370\n",
      "Epoch 2/3\n",
      "30000/30000 [==============================] - 4413s 147ms/step - loss: 0.0809 - acc: 0.9732 - val_loss: 0.1916 - val_acc: 0.9322\n",
      "Epoch 3/3\n",
      " 3570/30000 [==>...........................] - ETA: 1:01:08 - loss: 0.0259 - acc: 0.9927"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e1f167438af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs=3,\n",
    "    batch_size=15,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 802s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(x=[test_input_ids, \n",
    "                                    test_input_masks, \n",
    "                                    test_segment_ids],\n",
    "                                 batch_size=200,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = [1 if prob > 0.5 else 0 for prob in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      7490\n",
      "           1       0.95      0.93      0.94      7510\n",
      "\n",
      "    accuracy                           0.94     15000\n",
      "   macro avg       0.94      0.94      0.94     15000\n",
      "weighted avg       0.94      0.94      0.94     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "with tf.Session() as session:\n",
    "    cm = tf.confusion_matrix(test_labels, test_pred_labels).eval()\n",
    "\n",
    "LABELS = ['negative', 'positive']\n",
    "sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS, fmt='g')\n",
    "xl = plt.xlabel(\"Predicted\")\n",
    "yl = plt.ylabel(\"Actuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('bert_sentiment_model_weights_seq512b15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bert_sentiment_model_seq512b15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4357MB\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jul  1 04:57 'BERT - TF Keras implementation - Sentiment Analysis-Copy1.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jul  1 02:00 'BERT - TF Keras implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 21 13:11 'BERT Inference - TF Implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 21 13:11 'BERT Training - TF Implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze 1320MB Jun 25 08:12  bert_sentiment_model.h5\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze 1320MB Jul  1 04:57  bert_sentiment_model_seq512b15.h5\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  442MB Jun 25 08:12  bert_sentiment_model_weights.h5\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  442MB Jul  1 04:57  bert_sentiment_model_weights_seq512b15.h5\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze    1MB Jun 21 11:18  checkpoint\r\n",
      "drwxr-xr-x 2 redanalyze redanalyze    1MB Jun 21 10:02  eval\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  623MB Jun 21 11:18  events.out.tfevents.1561110216.better-eve-instance\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  193MB Jun 21 11:01  graph.pbtxt\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze   20MB Jun 21 03:12  imdb_movie_reviews.csv.bz2\r\n",
      "drwxrwxr-x 3 redanalyze redanalyze    1MB Jun 21 12:55  tf_models\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l --block-size=MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0701 04:57:47.784232 140267069904704 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers: 199\n",
      "Non Trainable layers: 5\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0701 04:57:49.445465 140267069904704 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_2 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          196864      bert_layer_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            257         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 109,679,361\n",
      "Non-trainable params: 622,650\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = build_model(bert_path=BERT_PATH, max_seq_length=MAX_SEQ_LENGTH, n_fine_tune_encoders=10)\n",
    "initialize_vars(sess)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 811s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(x=[test_input_ids, \n",
    "                                    test_input_masks, \n",
    "                                    test_segment_ids],\n",
    "                                 batch_size=200,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.ravel()\n",
    "test_pred_labels = [1 if prob > 0.5 else 0 for prob in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      7490\n",
      "           1       0.50      0.00      0.00      7510\n",
      "\n",
      "    accuracy                           0.50     15000\n",
      "   macro avg       0.50      0.50      0.33     15000\n",
      "weighted avg       0.50      0.50      0.33     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    cm = tf.confusion_matrix(test_labels, test_pred_labels).eval()\n",
    "\n",
    "LABELS = ['negative', 'positive']\n",
    "sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS, fmt='g')\n",
    "xl = plt.xlabel(\"Predicted\")\n",
    "yl = plt.ylabel(\"Actuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('bert_sentiment_model_weights_seq512b15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 808s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(x=[test_input_ids, \n",
    "                                    test_input_masks, \n",
    "                                    test_segment_ids],\n",
    "                                 batch_size=200,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.ravel()\n",
    "test_pred_labels = [1 if prob > 0.5 else 0 for prob in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      7490\n",
      "           1       0.95      0.93      0.94      7510\n",
      "\n",
      "    accuracy                           0.94     15000\n",
      "   macro avg       0.94      0.94      0.94     15000\n",
      "weighted avg       0.94      0.94      0.94     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    cm = tf.confusion_matrix(test_labels, test_pred_labels).eval()\n",
    "\n",
    "LABELS = ['negative', 'positive']\n",
    "sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS, fmt='g')\n",
    "xl = plt.xlabel(\"Predicted\")\n",
    "yl = plt.ylabel(\"Actuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
