{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-21 03:12:02--  https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2\n",
      "Resolving github.com (github.com)... 192.30.253.112\n",
      "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/dipanjanS/nlp_workshop_dhs18/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2 [following]\n",
      "--2019-06-21 03:12:03--  https://raw.githubusercontent.com/dipanjanS/nlp_workshop_dhs18/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.192.133, 151.101.128.133, 151.101.64.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.192.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19522289 (19M) [application/octet-stream]\n",
      "Saving to: ‘imdb_movie_reviews.csv.bz2’\n",
      "\n",
      "imdb_movie_reviews. 100%[===================>]  18.62M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-06-21 03:12:03 (127 MB/s) - ‘imdb_movie_reviews.csv.bz2’ saved [19522289/19522289]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2 --output-document=imdb_movie_reviews.csv.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20MB\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze  1MB Jun 21 03:15 'BERT - Raw TensorFlow Implementation - Sentiment Analysis.ipynb'\r\n",
      "-rw-rw-r-- 1 redanalyze redanalyze 20MB Jun 21 03:12  imdb_movie_reviews.csv.bz2\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l --block-size=MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5c/6f3698513cf1cd730a5ea66aec665d213adf9de59b34f362f270e0bd126f/tensorflow_hub-0.4.0-py2.py3-none-any.whl (75kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 3.8MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /home/redanalyze/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (1.16.4)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /home/redanalyze/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/redanalyze/anaconda3/lib/python3.6/site-packages (from tensorflow_hub) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/redanalyze/anaconda3/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow_hub) (41.0.1)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf_hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six in /home/redanalyze/anaconda3/lib/python3.6/site-packages (from bert-tensorflow) (1.12.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "Successfully installed bert-tensorflow-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 21 09:08:30 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   55C    P0    28W /  70W |    213MiB / 15079MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      6656      C   /home/redanalyze/anaconda3/bin/python        203MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      "review       50000 non-null object\n",
      "sentiment    50000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./imdb_movie_reviews.csv.bz2', compression='bz2')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'] = [1 if sentiment == 'positive' else 0 \n",
    "                            for sentiment in dataset['sentiment'].values]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'review'\n",
    "LABEL_COLUMN = 'sentiment'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 2), (5000, 2), (15000, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = dataset.iloc[:30000]\n",
    "val_df = dataset.iloc[30000:35000]\n",
    "test_df = dataset.iloc[35000:]\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create  `InputExample`'s using the constructor provided in the BERT library.\n",
    "\n",
    "- `text_a` is the text we want to classify, which in this case, is the `review` field in our Dataframe. \n",
    "- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n",
    "- `label` is the label for our example, i.e. 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class InputExample in module bert.run_classifier:\n",
      "\n",
      "class InputExample(builtins.object)\n",
      " |  A single training/test example for simple sequence classification.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, guid, text_a, text_b=None, label=None)\n",
      " |      Constructs a InputExample.\n",
      " |      \n",
      " |      Args:\n",
      " |        guid: Unique id for the example.\n",
      " |        text_a: string. The untokenized text of the first sequence. For single\n",
      " |          sequence tasks, only this sequence must be specified.\n",
      " |        text_b: (Optional) string. The untokenized text of the second sequence.\n",
      " |          Only must be specified for sequence pair tasks.\n",
      " |        label: (Optional) string. The label of the example. This should be\n",
      " |          specified for train and dev examples, but not for test examples.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bert.run_classifier.InputExample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_input_examples = train_df.apply(lambda row: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                                   text_a=row[DATA_COLUMN], \n",
    "                                                                                   text_b=None, \n",
    "                                                                                   label=row[LABEL_COLUMN]), \n",
    "                                      axis=1)\n",
    "\n",
    "val_input_examples = val_df.apply(lambda row: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                               text_a=row[DATA_COLUMN], \n",
    "                                                                               text_b=None, \n",
    "                                                                               label=row[LABEL_COLUMN]), \n",
    "                                  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': None,\n",
       " 'text_a': \"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\",\n",
       " 'text_b': None,\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = train_input_examples.iloc[3]\n",
    "ex.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to preprocess our data so that it matches the data BERT was trained on. For this, we'll need to do a couple of things (but don't worry--this is also included in the Python library):\n",
    "\n",
    "\n",
    "1. Lowercase our text (if we're using a BERT lowercase model)\n",
    "2. Tokenize it (i.e. `\"sally says hi\" -> [\"sally\", \"says\", \"hi\"]`)\n",
    "3. Break words into WordPieces (i.e. `\"calling\" -> [\"call\", \"##ing\"]`)\n",
    "4. Map our words to indexes using a vocab file that BERT provides\n",
    "5. Add special `\"CLS\"` and `\"SEP\"` tokens (see the [readme](https://github.com/google-research/bert))\n",
    "6. Append \"index\" and \"segment\" tokens to each input (see the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
    "\n",
    "\n",
    "Thankfully, we don't have to worry about most of these details.\n",
    "To start, we'll need to load a vocabulary file and lowercasing information directly from the BERT tf hub module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class FullTokenizer in module bert.tokenization:\n",
      "\n",
      "class FullTokenizer(builtins.object)\n",
      " |  Runs end-to-end tokenziation.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, vocab_file, do_lower_case=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  convert_ids_to_tokens(self, ids)\n",
      " |  \n",
      " |  convert_tokens_to_ids(self, tokens)\n",
      " |  \n",
      " |  tokenize(self, text)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bert.tokenization.FullTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:13:29.074799 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization info: {'do_lower_case': True, 'vocab_file': b'/tmp/tfhub_modules/5a395eafef2a37bd9fc55d7f6ae676d2a134a838/assets/vocab.txt'}\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_TFHUB = 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1'\n",
    "\n",
    "def create_tokenizer_from_tfhub_module(tfhub_module):\n",
    "    \"\"\"Get the vocab file and casing info from the TF Hub module.\"\"\"\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        # we are not fine-tuning BERT layers here\n",
    "        bert_module = tf_hub.Module(tfhub_module, trainable=False)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", \n",
    "                                        as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            print('Tokenization info: {}'.format(sess.run(tokenization_info)))\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                                  tokenization_info[\"do_lower_case\"]])\n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_tfhub_module(tfhub_module=BERT_MODEL_TFHUB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT model we're using expects lowercase data (that's what stored in the `tokenization_info` parameter `do_lower_case`. Besides this, we also loaded BERT's vocab file. Finally, we created a tokenizer, which breaks words into word pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<',\n",
       " 'h',\n",
       " '##1',\n",
       " '>',\n",
       " 'yesterday',\n",
       " \"'\",\n",
       " 's',\n",
       " 'movie',\n",
       " 'wasn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'that',\n",
       " 'great',\n",
       " '.',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " '<',\n",
       " 'b',\n",
       " '>',\n",
       " 'token',\n",
       " '##izer',\n",
       " '<',\n",
       " '/',\n",
       " 'b',\n",
       " '>',\n",
       " 'used',\n",
       " 'for',\n",
       " 'token',\n",
       " '##izing',\n",
       " 'this',\n",
       " 'sentence',\n",
       " '.',\n",
       " '<',\n",
       " '/',\n",
       " 'h',\n",
       " '##1',\n",
       " '>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"<h1>Yesterday's movie wasn't that great. This is a <b>tokenizer</b> used for tokenizing this sentence.</h1>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our tokenizer, we'll call `run_classifier.convert_examples_to_features` on our `InputExamples` to convert them into features BERT understands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.599638 139683216717632 tf_logging.py:115] Writing example 0 of 30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.608187 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.609346 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] one of the other reviewers has mentioned that after watching just 1 oz episode you ' ll be hooked . they are right , as this is exactly what happened with me . < br / > < br / > the first thing that struck me about oz was its brutality and un ##fl ##in ##ching scenes of violence , which set in right from the word go . trust me , this is not a show for the faint hearted or tim ##id . this show pulls no punches with regards to drugs , sex or violence . its is hardcore , in the classic use of the word . < br / > < br / > it is called oz as that [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.610438 139683216717632 tf_logging.py:115] tokens: [CLS] one of the other reviewers has mentioned that after watching just 1 oz episode you ' ll be hooked . they are right , as this is exactly what happened with me . < br / > < br / > the first thing that struck me about oz was its brutality and un ##fl ##in ##ching scenes of violence , which set in right from the word go . trust me , this is not a show for the faint hearted or tim ##id . this show pulls no punches with regards to drugs , sex or violence . its is hardcore , in the classic use of the word . < br / > < br / > it is called oz as that [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2028 1997 1996 2060 15814 2038 3855 2008 2044 3666 2074 1015 11472 2792 2017 1005 2222 2022 13322 1012 2027 2024 2157 1010 2004 2023 2003 3599 2054 3047 2007 2033 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2034 2518 2008 4930 2033 2055 11472 2001 2049 24083 1998 4895 10258 2378 8450 5019 1997 4808 1010 2029 2275 1999 2157 2013 1996 2773 2175 1012 3404 2033 1010 2023 2003 2025 1037 2265 2005 1996 8143 18627 2030 5199 3593 1012 2023 2265 8005 2053 17957 2007 12362 2000 5850 1010 3348 2030 4808 1012 2049 2003 13076 1010 1999 1996 4438 2224 1997 1996 2773 1012 1026 7987 1013 1028 1026 7987 1013 1028 2009 2003 2170 11472 2004 2008 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.611481 139683216717632 tf_logging.py:115] input_ids: 101 2028 1997 1996 2060 15814 2038 3855 2008 2044 3666 2074 1015 11472 2792 2017 1005 2222 2022 13322 1012 2027 2024 2157 1010 2004 2023 2003 3599 2054 3047 2007 2033 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2034 2518 2008 4930 2033 2055 11472 2001 2049 24083 1998 4895 10258 2378 8450 5019 1997 4808 1010 2029 2275 1999 2157 2013 1996 2773 2175 1012 3404 2033 1010 2023 2003 2025 1037 2265 2005 1996 8143 18627 2030 5199 3593 1012 2023 2265 8005 2053 17957 2007 12362 2000 5850 1010 3348 2030 4808 1012 2049 2003 13076 1010 1999 1996 4438 2224 1997 1996 2773 1012 1026 7987 1013 1028 1026 7987 1013 1028 2009 2003 2170 11472 2004 2008 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.612672 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.613786 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.614878 139683216717632 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.621892 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.622922 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] a wonderful little production . < br / > < br / > the filming technique is very una ##ss ##uming - very old - time - bbc fashion and gives a comforting , and sometimes discomfort ##ing , sense of realism to the entire piece . < br / > < br / > the actors are extremely well chosen - michael sheen not only \" has got all the polar ##i \" but he has all the voices down pat too ! you can truly see the seam ##less editing guided by the references to williams ' diary entries , not only is it well worth the watching but it is a terrific ##ly written and performed piece . a master ##ful production about [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.623976 139683216717632 tf_logging.py:115] tokens: [CLS] a wonderful little production . < br / > < br / > the filming technique is very una ##ss ##uming - very old - time - bbc fashion and gives a comforting , and sometimes discomfort ##ing , sense of realism to the entire piece . < br / > < br / > the actors are extremely well chosen - michael sheen not only \" has got all the polar ##i \" but he has all the voices down pat too ! you can truly see the seam ##less editing guided by the references to williams ' diary entries , not only is it well worth the watching but it is a terrific ##ly written and performed piece . a master ##ful production about [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1037 6919 2210 2537 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 7467 6028 2003 2200 14477 4757 24270 1011 2200 2214 1011 2051 1011 4035 4827 1998 3957 1037 16334 1010 1998 2823 17964 2075 1010 3168 1997 15650 2000 1996 2972 3538 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 5889 2024 5186 2092 4217 1011 2745 20682 2025 2069 1000 2038 2288 2035 1996 11508 2072 1000 2021 2002 2038 2035 1996 5755 2091 6986 2205 999 2017 2064 5621 2156 1996 25180 3238 9260 8546 2011 1996 7604 2000 3766 1005 9708 10445 1010 2025 2069 2003 2009 2092 4276 1996 3666 2021 2009 2003 1037 27547 2135 2517 1998 2864 3538 1012 1037 3040 3993 2537 2055 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.625495 139683216717632 tf_logging.py:115] input_ids: 101 1037 6919 2210 2537 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 7467 6028 2003 2200 14477 4757 24270 1011 2200 2214 1011 2051 1011 4035 4827 1998 3957 1037 16334 1010 1998 2823 17964 2075 1010 3168 1997 15650 2000 1996 2972 3538 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 5889 2024 5186 2092 4217 1011 2745 20682 2025 2069 1000 2038 2288 2035 1996 11508 2072 1000 2021 2002 2038 2035 1996 5755 2091 6986 2205 999 2017 2064 5621 2156 1996 25180 3238 9260 8546 2011 1996 7604 2000 3766 1005 9708 10445 1010 2025 2069 2003 2009 2092 4276 1996 3666 2021 2009 2003 1037 27547 2135 2517 1998 2864 3538 1012 1037 3040 3993 2537 2055 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.626622 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.627670 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.628658 139683216717632 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.634940 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.636051 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i thought this was a wonderful way to spend time on a too hot summer weekend , sitting in the air conditioned theater and watching a light - hearted comedy . the plot is sim ##pl ##istic , but the dialogue is witty and the characters are li ##ka ##ble ( even the well bread suspected serial killer ) . while some may be disappointed when they realize this is not match point 2 : risk addiction , i thought it was proof that woody allen is still fully in control of the style many of us have grown to love . < br / > < br / > this was the most i ' d laughed at one of woody ' s comedies in [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.637146 139683216717632 tf_logging.py:115] tokens: [CLS] i thought this was a wonderful way to spend time on a too hot summer weekend , sitting in the air conditioned theater and watching a light - hearted comedy . the plot is sim ##pl ##istic , but the dialogue is witty and the characters are li ##ka ##ble ( even the well bread suspected serial killer ) . while some may be disappointed when they realize this is not match point 2 : risk addiction , i thought it was proof that woody allen is still fully in control of the style many of us have grown to love . < br / > < br / > this was the most i ' d laughed at one of woody ' s comedies in [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2245 2023 2001 1037 6919 2126 2000 5247 2051 2006 1037 2205 2980 2621 5353 1010 3564 1999 1996 2250 22442 4258 1998 3666 1037 2422 1011 18627 4038 1012 1996 5436 2003 21934 24759 6553 1010 2021 1996 7982 2003 25591 1998 1996 3494 2024 5622 2912 3468 1006 2130 1996 2092 7852 6878 7642 6359 1007 1012 2096 2070 2089 2022 9364 2043 2027 5382 2023 2003 2025 2674 2391 1016 1024 3891 13449 1010 1045 2245 2009 2001 6947 2008 13703 5297 2003 2145 3929 1999 2491 1997 1996 2806 2116 1997 2149 2031 4961 2000 2293 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2001 1996 2087 1045 1005 1040 4191 2012 2028 1997 13703 1005 1055 22092 1999 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.638229 139683216717632 tf_logging.py:115] input_ids: 101 1045 2245 2023 2001 1037 6919 2126 2000 5247 2051 2006 1037 2205 2980 2621 5353 1010 3564 1999 1996 2250 22442 4258 1998 3666 1037 2422 1011 18627 4038 1012 1996 5436 2003 21934 24759 6553 1010 2021 1996 7982 2003 25591 1998 1996 3494 2024 5622 2912 3468 1006 2130 1996 2092 7852 6878 7642 6359 1007 1012 2096 2070 2089 2022 9364 2043 2027 5382 2023 2003 2025 2674 2391 1016 1024 3891 13449 1010 1045 2245 2009 2001 6947 2008 13703 5297 2003 2145 3929 1999 2491 1997 1996 2806 2116 1997 2149 2031 4961 2000 2293 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2001 1996 2087 1045 1005 1040 4191 2012 2028 1997 13703 1005 1055 22092 1999 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.639324 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.640376 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.641658 139683216717632 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.646942 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.647948 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] basically there ' s a family where a little boy ( jake ) thinks there ' s a zombie in his closet & his parents are fighting all the time . < br / > < br / > this movie is slower than a soap opera . . . and suddenly , jake decides to become ram ##bo and kill the zombie . < br / > < br / > ok , first of all when you ' re going to make a film you must decide if its a thriller or a drama ! as a drama the movie is watch ##able . parents are di ##vor ##cing & arguing like in real life . and then we have jake with his closet [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.648981 139683216717632 tf_logging.py:115] tokens: [CLS] basically there ' s a family where a little boy ( jake ) thinks there ' s a zombie in his closet & his parents are fighting all the time . < br / > < br / > this movie is slower than a soap opera . . . and suddenly , jake decides to become ram ##bo and kill the zombie . < br / > < br / > ok , first of all when you ' re going to make a film you must decide if its a thriller or a drama ! as a drama the movie is watch ##able . parents are di ##vor ##cing & arguing like in real life . and then we have jake with his closet [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 10468 2045 1005 1055 1037 2155 2073 1037 2210 2879 1006 5180 1007 6732 2045 1005 1055 1037 11798 1999 2010 9346 1004 2010 3008 2024 3554 2035 1996 2051 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 3185 2003 12430 2084 1037 7815 3850 1012 1012 1012 1998 3402 1010 5180 7288 2000 2468 8223 5092 1998 3102 1996 11798 1012 1026 7987 1013 1028 1026 7987 1013 1028 7929 1010 2034 1997 2035 2043 2017 1005 2128 2183 2000 2191 1037 2143 2017 2442 5630 2065 2049 1037 10874 2030 1037 3689 999 2004 1037 3689 1996 3185 2003 3422 3085 1012 3008 2024 4487 14550 6129 1004 9177 2066 1999 2613 2166 1012 1998 2059 2057 2031 5180 2007 2010 9346 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.650090 139683216717632 tf_logging.py:115] input_ids: 101 10468 2045 1005 1055 1037 2155 2073 1037 2210 2879 1006 5180 1007 6732 2045 1005 1055 1037 11798 1999 2010 9346 1004 2010 3008 2024 3554 2035 1996 2051 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 3185 2003 12430 2084 1037 7815 3850 1012 1012 1012 1998 3402 1010 5180 7288 2000 2468 8223 5092 1998 3102 1996 11798 1012 1026 7987 1013 1028 1026 7987 1013 1028 7929 1010 2034 1997 2035 2043 2017 1005 2128 2183 2000 2191 1037 2143 2017 2442 5630 2065 2049 1037 10874 2030 1037 3689 999 2004 1037 3689 1996 3185 2003 3422 3085 1012 3008 2024 4487 14550 6129 1004 9177 2066 1999 2613 2166 1012 1998 2059 2057 2031 5180 2007 2010 9346 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.651163 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.652184 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.653182 139683216717632 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.668354 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.670361 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] pet ##ter matt ##ei ' s \" love in the time of money \" is a visually stunning film to watch . mr . matt ##ei offers us a vivid portrait about human relations . this is a movie that seems to be telling us what money , power and success do to people in the different situations we encounter . < br / > < br / > this being a variation on the arthur sc ##hn ##itz ##ler ' s play about the same theme , the director transfers the action to the present time new york where all these different characters meet and connect . each one is connected in one way , or another to the next person , but no one [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.671381 139683216717632 tf_logging.py:115] tokens: [CLS] pet ##ter matt ##ei ' s \" love in the time of money \" is a visually stunning film to watch . mr . matt ##ei offers us a vivid portrait about human relations . this is a movie that seems to be telling us what money , power and success do to people in the different situations we encounter . < br / > < br / > this being a variation on the arthur sc ##hn ##itz ##ler ' s play about the same theme , the director transfers the action to the present time new york where all these different characters meet and connect . each one is connected in one way , or another to the next person , but no one [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 9004 3334 4717 7416 1005 1055 1000 2293 1999 1996 2051 1997 2769 1000 2003 1037 17453 14726 2143 2000 3422 1012 2720 1012 4717 7416 4107 2149 1037 14954 6533 2055 2529 4262 1012 2023 2003 1037 3185 2008 3849 2000 2022 4129 2149 2054 2769 1010 2373 1998 3112 2079 2000 2111 1999 1996 2367 8146 2057 8087 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2108 1037 8386 2006 1996 4300 8040 7295 8838 3917 1005 1055 2377 2055 1996 2168 4323 1010 1996 2472 15210 1996 2895 2000 1996 2556 2051 2047 2259 2073 2035 2122 2367 3494 3113 1998 7532 1012 2169 2028 2003 4198 1999 2028 2126 1010 2030 2178 2000 1996 2279 2711 1010 2021 2053 2028 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.672332 139683216717632 tf_logging.py:115] input_ids: 101 9004 3334 4717 7416 1005 1055 1000 2293 1999 1996 2051 1997 2769 1000 2003 1037 17453 14726 2143 2000 3422 1012 2720 1012 4717 7416 4107 2149 1037 14954 6533 2055 2529 4262 1012 2023 2003 1037 3185 2008 3849 2000 2022 4129 2149 2054 2769 1010 2373 1998 3112 2079 2000 2111 1999 1996 2367 8146 2057 8087 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2108 1037 8386 2006 1996 4300 8040 7295 8838 3917 1005 1055 2377 2055 1996 2168 4323 1010 1996 2472 15210 1996 2895 2000 1996 2556 2051 2047 2259 2073 2035 2122 2367 3494 3113 1998 7532 1012 2169 2028 2003 4198 1999 2028 2126 1010 2030 2178 2000 1996 2279 2711 1010 2021 2053 2028 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.673313 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.674319 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:14:56.675270 139683216717632 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:15:32.470094 139683216717632 tf_logging.py:115] Writing example 10000 of 30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 20000 of 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:08.724129 139683216717632 tf_logging.py:115] Writing example 20000 of 30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.755963 139683216717632 tf_logging.py:115] Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.759778 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.760783 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] one of quite a few cartoon sc ##oo ##by doo films , \" sc ##oo ##by doo and the loch ness monster \" turns out to be entertaining , exciting , interesting , funny and also does a surprisingly good interpretation of the highlands of scotland . one annoying aspect of the film is the voices of many of the characters - american people trying to sound scottish in this film are unfortunately not succeeding all that well ( although some people do better scottish accents than others ) . < br / > < br / > daphne has come to the highlands to see her cousin shannon and the highland games at blake castle . gravely shannon tells the gang that she believes to [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.761779 139683216717632 tf_logging.py:115] tokens: [CLS] one of quite a few cartoon sc ##oo ##by doo films , \" sc ##oo ##by doo and the loch ness monster \" turns out to be entertaining , exciting , interesting , funny and also does a surprisingly good interpretation of the highlands of scotland . one annoying aspect of the film is the voices of many of the characters - american people trying to sound scottish in this film are unfortunately not succeeding all that well ( although some people do better scottish accents than others ) . < br / > < br / > daphne has come to the highlands to see her cousin shannon and the highland games at blake castle . gravely shannon tells the gang that she believes to [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2028 1997 3243 1037 2261 9476 8040 9541 3762 20160 3152 1010 1000 8040 9541 3762 20160 1998 1996 14941 23384 6071 1000 4332 2041 2000 2022 14036 1010 10990 1010 5875 1010 6057 1998 2036 2515 1037 10889 2204 7613 1997 1996 11784 1997 3885 1012 2028 15703 7814 1997 1996 2143 2003 1996 5755 1997 2116 1997 1996 3494 1011 2137 2111 2667 2000 2614 4104 1999 2023 2143 2024 6854 2025 13034 2035 2008 2092 1006 2348 2070 2111 2079 2488 4104 24947 2084 2500 1007 1012 1026 7987 1013 1028 1026 7987 1013 1028 16847 2038 2272 2000 1996 11784 2000 2156 2014 5542 10881 1998 1996 10983 2399 2012 6511 3317 1012 28070 10881 4136 1996 6080 2008 2016 7164 2000 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.762679 139683216717632 tf_logging.py:115] input_ids: 101 2028 1997 3243 1037 2261 9476 8040 9541 3762 20160 3152 1010 1000 8040 9541 3762 20160 1998 1996 14941 23384 6071 1000 4332 2041 2000 2022 14036 1010 10990 1010 5875 1010 6057 1998 2036 2515 1037 10889 2204 7613 1997 1996 11784 1997 3885 1012 2028 15703 7814 1997 1996 2143 2003 1996 5755 1997 2116 1997 1996 3494 1011 2137 2111 2667 2000 2614 4104 1999 2023 2143 2024 6854 2025 13034 2035 2008 2092 1006 2348 2070 2111 2079 2488 4104 24947 2084 2500 1007 1012 1026 7987 1013 1028 1026 7987 1013 1028 16847 2038 2272 2000 1996 11784 2000 2156 2014 5542 10881 1998 1996 10983 2399 2012 6511 3317 1012 28070 10881 4136 1996 6080 2008 2016 7164 2000 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.763568 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.764481 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.765239 139683216717632 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.773168 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.774083 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this is one of the si ##llie ##st movies i have ever had the mis ##fort ##une to watch ! i should have expected it , after seeing the first two , but i keep getting sucker ##ed into these types of movies with the idea of \" maybe they did it right this time \" . nope - not even close . < br / > < br / > where do i begin ? how about with the special effects . . . to give you an idea of what passes for sf ##x in this movie , at one point a soldier is shooting at a \" rap ##tor \" as it runs down a hallway . even with less than a second [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.775100 139683216717632 tf_logging.py:115] tokens: [CLS] this is one of the si ##llie ##st movies i have ever had the mis ##fort ##une to watch ! i should have expected it , after seeing the first two , but i keep getting sucker ##ed into these types of movies with the idea of \" maybe they did it right this time \" . nope - not even close . < br / > < br / > where do i begin ? how about with the special effects . . . to give you an idea of what passes for sf ##x in this movie , at one point a soldier is shooting at a \" rap ##tor \" as it runs down a hallway . even with less than a second [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2003 2028 1997 1996 9033 23697 3367 5691 1045 2031 2412 2018 1996 28616 13028 9816 2000 3422 999 1045 2323 2031 3517 2009 1010 2044 3773 1996 2034 2048 1010 2021 1045 2562 2893 26476 2098 2046 2122 4127 1997 5691 2007 1996 2801 1997 1000 2672 2027 2106 2009 2157 2023 2051 1000 1012 16780 1011 2025 2130 2485 1012 1026 7987 1013 1028 1026 7987 1013 1028 2073 2079 1045 4088 1029 2129 2055 2007 1996 2569 3896 1012 1012 1012 2000 2507 2017 2019 2801 1997 2054 5235 2005 16420 2595 1999 2023 3185 1010 2012 2028 2391 1037 5268 2003 5008 2012 1037 1000 9680 4263 1000 2004 2009 3216 2091 1037 6797 1012 2130 2007 2625 2084 1037 2117 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.776135 139683216717632 tf_logging.py:115] input_ids: 101 2023 2003 2028 1997 1996 9033 23697 3367 5691 1045 2031 2412 2018 1996 28616 13028 9816 2000 3422 999 1045 2323 2031 3517 2009 1010 2044 3773 1996 2034 2048 1010 2021 1045 2562 2893 26476 2098 2046 2122 4127 1997 5691 2007 1996 2801 1997 1000 2672 2027 2106 2009 2157 2023 2051 1000 1012 16780 1011 2025 2130 2485 1012 1026 7987 1013 1028 1026 7987 1013 1028 2073 2079 1045 4088 1029 2129 2055 2007 1996 2569 3896 1012 1012 1012 2000 2507 2017 2019 2801 1997 2054 5235 2005 16420 2595 1999 2023 3185 1010 2012 2028 2391 1037 5268 2003 5008 2012 1037 1000 9680 4263 1000 2004 2009 3216 2091 1037 6797 1012 2130 2007 2625 2084 1037 2117 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.777110 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.778061 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.778977 139683216717632 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.782195 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.783180 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] for some reason my father - in - law gave me a copy of this tape . i think because my great uncle , buddy bae ##r , was the giant in this movie and my father - in - law thought i ' d like to see it . i had , years before as a child , and didn ' t like it then , either . < br / > < br / > my son , then two , watched it and was hooked . every waking moment in front of the tv , this ho ##rri ##d video played . i went to work with the ina ##ne songs stuck in my head . the two \" leads \" were worse [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.784081 139683216717632 tf_logging.py:115] tokens: [CLS] for some reason my father - in - law gave me a copy of this tape . i think because my great uncle , buddy bae ##r , was the giant in this movie and my father - in - law thought i ' d like to see it . i had , years before as a child , and didn ' t like it then , either . < br / > < br / > my son , then two , watched it and was hooked . every waking moment in front of the tv , this ho ##rri ##d video played . i went to work with the ina ##ne songs stuck in my head . the two \" leads \" were worse [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2005 2070 3114 2026 2269 1011 1999 1011 2375 2435 2033 1037 6100 1997 2023 6823 1012 1045 2228 2138 2026 2307 4470 1010 8937 25818 2099 1010 2001 1996 5016 1999 2023 3185 1998 2026 2269 1011 1999 1011 2375 2245 1045 1005 1040 2066 2000 2156 2009 1012 1045 2018 1010 2086 2077 2004 1037 2775 1010 1998 2134 1005 1056 2066 2009 2059 1010 2593 1012 1026 7987 1013 1028 1026 7987 1013 1028 2026 2365 1010 2059 2048 1010 3427 2009 1998 2001 13322 1012 2296 12447 2617 1999 2392 1997 1996 2694 1010 2023 7570 18752 2094 2678 2209 1012 1045 2253 2000 2147 2007 1996 27118 2638 2774 5881 1999 2026 2132 1012 1996 2048 1000 5260 1000 2020 4788 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.785124 139683216717632 tf_logging.py:115] input_ids: 101 2005 2070 3114 2026 2269 1011 1999 1011 2375 2435 2033 1037 6100 1997 2023 6823 1012 1045 2228 2138 2026 2307 4470 1010 8937 25818 2099 1010 2001 1996 5016 1999 2023 3185 1998 2026 2269 1011 1999 1011 2375 2245 1045 1005 1040 2066 2000 2156 2009 1012 1045 2018 1010 2086 2077 2004 1037 2775 1010 1998 2134 1005 1056 2066 2009 2059 1010 2593 1012 1026 7987 1013 1028 1026 7987 1013 1028 2026 2365 1010 2059 2048 1010 3427 2009 1998 2001 13322 1012 2296 12447 2617 1999 2392 1997 1996 2694 1010 2023 7570 18752 2094 2678 2209 1012 1045 2253 2000 2147 2007 1996 27118 2638 2774 5881 1999 2026 2132 1012 1996 2048 1000 5260 1000 2020 4788 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.786122 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.787106 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.788022 139683216717632 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.790411 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.791581 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] it may be hard to explain how , but this film is a masterpiece . perhaps , because i never imagined that a plot like this or a film with so few words would convey all this poetry . the true poetry and aristocracy of human passions and obsession . bog ##ard is amazing and needles ##s to say that venice is ut ##ilised as a perfect scenery : dark , sinking and dr ##ear ##y just like bog ##ard ' s soul . and classical music is more that a simple background escort to human feelings . in my opinion , a classic masterpiece of european film - making . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.792597 139683216717632 tf_logging.py:115] tokens: [CLS] it may be hard to explain how , but this film is a masterpiece . perhaps , because i never imagined that a plot like this or a film with so few words would convey all this poetry . the true poetry and aristocracy of human passions and obsession . bog ##ard is amazing and needles ##s to say that venice is ut ##ilised as a perfect scenery : dark , sinking and dr ##ear ##y just like bog ##ard ' s soul . and classical music is more that a simple background escort to human feelings . in my opinion , a classic masterpiece of european film - making . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2009 2089 2022 2524 2000 4863 2129 1010 2021 2023 2143 2003 1037 17743 1012 3383 1010 2138 1045 2196 8078 2008 1037 5436 2066 2023 2030 1037 2143 2007 2061 2261 2616 2052 16636 2035 2023 4623 1012 1996 2995 4623 1998 22706 1997 2529 25289 1998 17418 1012 22132 4232 2003 6429 1998 17044 2015 2000 2360 2008 7914 2003 21183 21758 2004 1037 3819 17363 1024 2601 1010 10186 1998 2852 14644 2100 2074 2066 22132 4232 1005 1055 3969 1012 1998 4556 2189 2003 2062 2008 1037 3722 4281 8620 2000 2529 5346 1012 1999 2026 5448 1010 1037 4438 17743 1997 2647 2143 1011 2437 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.793569 139683216717632 tf_logging.py:115] input_ids: 101 2009 2089 2022 2524 2000 4863 2129 1010 2021 2023 2143 2003 1037 17743 1012 3383 1010 2138 1045 2196 8078 2008 1037 5436 2066 2023 2030 1037 2143 2007 2061 2261 2616 2052 16636 2035 2023 4623 1012 1996 2995 4623 1998 22706 1997 2529 25289 1998 17418 1012 22132 4232 2003 6429 1998 17044 2015 2000 2360 2008 7914 2003 21183 21758 2004 1037 3819 17363 1024 2601 1010 10186 1998 2852 14644 2100 2074 2066 22132 4232 1005 1055 3969 1012 1998 4556 2189 2003 2062 2008 1037 3722 4281 8620 2000 2529 5346 1012 1999 2026 5448 1010 1037 4438 17743 1997 2647 2143 1011 2437 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.794992 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.795963 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.802905 139683216717632 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.805488 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.806453 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this show is the worst show ever ! norris and his family write it , produce it , direct it , etc etc . the only reason i ever see it is because my goofy wife likes it . how many times can norris fly though the air from plain sight to land a kick on an obviously blind villain ? no trees , no building , just who ##osh . . . . . thin air . he always solve ##s the case or is the best at whatever skill there is . no co star ever gets the glory . its all norris . its truly apparent that norris is awful stuck on himself and will not allow anyone to one up him in [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.807449 139683216717632 tf_logging.py:115] tokens: [CLS] this show is the worst show ever ! norris and his family write it , produce it , direct it , etc etc . the only reason i ever see it is because my goofy wife likes it . how many times can norris fly though the air from plain sight to land a kick on an obviously blind villain ? no trees , no building , just who ##osh . . . . . thin air . he always solve ##s the case or is the best at whatever skill there is . no co star ever gets the glory . its all norris . its truly apparent that norris is awful stuck on himself and will not allow anyone to one up him in [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2265 2003 1996 5409 2265 2412 999 15466 1998 2010 2155 4339 2009 1010 3965 2009 1010 3622 2009 1010 4385 4385 1012 1996 2069 3114 1045 2412 2156 2009 2003 2138 2026 27243 2564 7777 2009 1012 2129 2116 2335 2064 15466 4875 2295 1996 2250 2013 5810 4356 2000 2455 1037 5926 2006 2019 5525 6397 12700 1029 2053 3628 1010 2053 2311 1010 2074 2040 17369 1012 1012 1012 1012 1012 4857 2250 1012 2002 2467 9611 2015 1996 2553 2030 2003 1996 2190 2012 3649 8066 2045 2003 1012 2053 2522 2732 2412 4152 1996 8294 1012 2049 2035 15466 1012 2049 5621 6835 2008 15466 2003 9643 5881 2006 2370 1998 2097 2025 3499 3087 2000 2028 2039 2032 1999 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.808431 139683216717632 tf_logging.py:115] input_ids: 101 2023 2265 2003 1996 5409 2265 2412 999 15466 1998 2010 2155 4339 2009 1010 3965 2009 1010 3622 2009 1010 4385 4385 1012 1996 2069 3114 1045 2412 2156 2009 2003 2138 2026 27243 2564 7777 2009 1012 2129 2116 2335 2064 15466 4875 2295 1996 2250 2013 5810 4356 2000 2455 1037 5926 2006 2019 5525 6397 12700 1029 2053 3628 1010 2053 2311 1010 2074 2040 17369 1012 1012 1012 1012 1012 4857 2250 1012 2002 2467 9611 2015 1996 2553 2030 2003 1996 2190 2012 3649 8066 2045 2003 1012 2053 2522 2732 2412 4152 1996 8294 1012 2049 2035 15466 1012 2049 5621 6835 2008 15466 2003 9643 5881 2006 2370 1998 2097 2025 3499 3087 2000 2028 2039 2032 1999 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.809454 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.810445 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:16:44.811421 139683216717632 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "# We'll set sequences to be at most 1000 tokens long.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "train_features = (bert.run_classifier\n",
    "                      .convert_examples_to_features(train_input_examples, \n",
    "                                                    label_list, \n",
    "                                                    MAX_SEQ_LENGTH, \n",
    "                                                    tokenizer))\n",
    "val_features = (bert.run_classifier\n",
    "                    .convert_examples_to_features(val_input_examples, \n",
    "                                                  label_list, \n",
    "                                                  MAX_SEQ_LENGTH, \n",
    "                                                  tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "Now that we've processed and prepared our data, let's focus on building our model. The `build_classification_model` function does this below. \n",
    "\n",
    "- First, it loads the BERT tf hub module again (this time to extract the computation graph). \n",
    "- Next, it creates a single new layer that will be trained to adapt BERT to our sentiment classification task (i.e. classifying whether a movie review is positive - 1 or negative - 0). \n",
    "\n",
    "This strategy of using a mostly trained model and tuning on top of it is called fine-tuning. Remember to set the parameter `trainable=True` when loading the model this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(tfhub_module, is_predicting, input_ids, input_mask, segment_ids, \n",
    "                 labels, num_labels, finetune_layers=True):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "    \n",
    "    bert_module = tf_hub.Module(tfhub_module, trainable=finetune_layers)\n",
    "    \n",
    "    bert_inputs = dict(input_ids=input_ids,\n",
    "                       input_mask=input_mask,\n",
    "                       segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\",\n",
    "                               as_dict=True)\n",
    "    \n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for sentiment data.\n",
    "    output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size],\n",
    "                                     initializer=tf.glorot_uniform_initializer(seed=SEED))\n",
    "    output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "    \n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "        \n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "        \n",
    "        #  get labels from probabilities\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        \n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "        \n",
    "        # If we're training / evaluating, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        \n",
    "        return (loss, predicted_labels, log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_optimizer in module bert.optimization:\n",
      "\n",
      "create_optimizer(loss, init_lr, num_train_steps, num_warmup_steps, use_tpu)\n",
      "    Creates an optimizer training op.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bert.optimization.create_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "\n",
    "def model_fn_builder(tfhub_module, num_labels, learning_rate, num_train_steps, num_warmup_steps,\n",
    "                     finetune_layers=True):\n",
    "    \"\"\"Returns `model_fn` closure for our tf Estimator.\"\"\"\n",
    "    \n",
    "    def model_fn(features, labels, mode, params):  \n",
    "        \"\"\"The `model_fn` for tf Estimator.\"\"\"\n",
    "        \n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "        # TRAINING and EVALUATION\n",
    "        if not is_predicting:\n",
    "            (loss, predicted_labels, log_probs) = create_model(tfhub_module, is_predicting, \n",
    "                                                               input_ids, input_mask, segment_ids, \n",
    "                                                               label_ids, num_labels, \n",
    "                                                               finetune_layers=finetune_layers)\n",
    "            train_op = bert.optimization.create_optimizer(loss, learning_rate, \n",
    "                                                          num_train_steps, num_warmup_steps, \n",
    "                                                          use_tpu=False)\n",
    "            \n",
    "            # Calculate evaluation metrics. \n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "                f1_score = tf.contrib.metrics.f1_score(label_ids, predicted_labels)\n",
    "                auc = tf.metrics.auc(label_ids, predicted_labels)\n",
    "                recall = tf.metrics.recall(label_ids, predicted_labels)\n",
    "                precision = tf.metrics.precision(label_ids, predicted_labels)\n",
    "                true_pos = tf.metrics.true_positives(label_ids, predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(label_ids, predicted_labels)\n",
    "                false_pos = tf.metrics.false_positives(label_ids, predicted_labels)\n",
    "                false_neg = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
    "                \n",
    "                return {\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"f1_score\": f1_score,\n",
    "                    \"auc\": auc,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg\n",
    "                }\n",
    "            \n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
    "            \n",
    "        else:\n",
    "            (predicted_labels, log_probs) = create_model(tfhub_module, is_predicting, input_ids, \n",
    "                                                         input_mask, segment_ids, \n",
    "                                                         label_ids, num_labels, finetune_layers=False)\n",
    "            \n",
    "            predictions = {\n",
    "              'probabilities': log_probs,\n",
    "              'labels': predicted_labels\n",
    "            }\n",
    "            \n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "BATCH_SIZE = 30\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 5.0\n",
    "\n",
    "# Warmup is a period of time where the learning rate \n",
    "# is small and gradually increases which usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "\n",
    "# Model configs\n",
    "OUTPUT_DIR = './'\n",
    "SAVE_CHECKPOINTS_STEPS = 1000\n",
    "SAVE_SUMMARY_STEPS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "num_train_steps, num_warmup_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './', '_tf_random_seed': 42, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f09f404f208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:40:00.010935 139683216717632 tf_logging.py:115] Using config: {'_model_dir': './', '_tf_random_seed': 42, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f09f404f208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Specify the output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(model_dir=OUTPUT_DIR,\n",
    "                                    keep_checkpoint_max=5,\n",
    "                                    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "                                    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "                                    tf_random_seed=SEED)\n",
    "\n",
    "model_fn = model_fn_builder(tfhub_module=BERT_MODEL_TFHUB, num_labels=len(label_list),\n",
    "                            learning_rate=LEARNING_RATE, num_train_steps=num_train_steps,\n",
    "                            num_warmup_steps=num_warmup_steps, finetune_layers=True)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config,\n",
    "                                   params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an input builder function that takes our training feature set (`train_features`) and produces a generator. This is a pretty standard design pattern for working with Tensorflow [Estimators](https://www.tensorflow.org/guide/estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function input_fn_builder in module bert.run_classifier:\n",
      "\n",
      "input_fn_builder(features, seq_length, is_training, drop_remainder)\n",
      "    Creates an `input_fn` closure to be passed to TPUEstimator.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bert.run_classifier.input_fn_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. \n",
    "# drop_remainder = False for using GPUs.\n",
    "\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(features=train_features,\n",
    "                                                      seq_length=MAX_SEQ_LENGTH,\n",
    "                                                      is_training=True,\n",
    "                                                      drop_remainder=False)\n",
    "\n",
    "val_input_fn = bert.run_classifier.input_fn_builder(features=val_features,\n",
    "                                                    seq_length=MAX_SEQ_LENGTH,\n",
    "                                                    is_training=False,\n",
    "                                                    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training for step = 0\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:43:12.372841 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:43:15.799862 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n",
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:43:35.745073 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:43:35.748805 139683216717632 tf_logging.py:115] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:43:39.880209 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:43:45.334978 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:43:45.510107 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:44:00.384350 139683216717632 tf_logging.py:115] Saving checkpoints for 0 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1563432, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:44:22.189821 139683216717632 tf_logging.py:115] loss = 1.1563432, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.913693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:46:11.634739 139683216717632 tf_logging.py:115] global_step/sec: 0.913693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.30663794, step = 100 (109.448 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:46:11.637811 139683216717632 tf_logging.py:115] loss = 0.30663794, step = 100 (109.448 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.992287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:47:52.411935 139683216717632 tf_logging.py:115] global_step/sec: 0.992287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48585132, step = 200 (100.776 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:47:52.413960 139683216717632 tf_logging.py:115] loss = 0.48585132, step = 200 (100.776 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.991091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:49:33.310892 139683216717632 tf_logging.py:115] global_step/sec: 0.991091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.60389733, step = 301 (100.899 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:49:33.313021 139683216717632 tf_logging.py:115] loss = 0.60389733, step = 301 (100.899 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.993696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:51:13.945258 139683216717632 tf_logging.py:115] global_step/sec: 0.993696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39748803, step = 400 (100.635 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:51:13.947708 139683216717632 tf_logging.py:115] loss = 0.39748803, step = 400 (100.635 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.951661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:52:59.024735 139683216717632 tf_logging.py:115] global_step/sec: 0.951661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2694697, step = 500 (105.079 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:52:59.026853 139683216717632 tf_logging.py:115] loss = 0.2694697, step = 500 (105.079 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.990047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:54:40.029981 139683216717632 tf_logging.py:115] global_step/sec: 0.990047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.272138, step = 601 (101.005 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:54:40.031990 139683216717632 tf_logging.py:115] loss = 0.272138, step = 601 (101.005 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.993341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:56:20.700261 139683216717632 tf_logging.py:115] global_step/sec: 0.993341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.27713433, step = 701 (100.670 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:56:20.702409 139683216717632 tf_logging.py:115] loss = 0.27713433, step = 701 (100.670 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.994682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:58:01.234913 139683216717632 tf_logging.py:115] global_step/sec: 0.994682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.17895669, step = 800 (100.535 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:58:01.237182 139683216717632 tf_logging.py:115] loss = 0.17895669, step = 800 (100.535 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.993144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:59:41.925256 139683216717632 tf_logging.py:115] global_step/sec: 0.993144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.18482037, step = 901 (100.690 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 09:59:41.927346 139683216717632 tf_logging.py:115] loss = 0.18482037, step = 901 (100.690 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:21.846439 139683216717632 tf_logging.py:115] Saving checkpoints for 1000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.13635291.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:25.095300 139683216717632 tf_logging.py:115] Loss for final step: 0.13635291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time (s): 1105.5477355820003\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:27.208039 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:30.138184 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n",
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:38.739621 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-21-10:01:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:38.760995 139683216717632 tf_logging.py:115] Starting evaluation at 2019-06-21-10:01:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:40.058771 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:40.062236 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:41.890846 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:01:42.057514 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-21-10:02:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:02:39.076423 139683216717632 tf_logging.py:115] Finished evaluation at 2019-06-21-10:02:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: auc = 0.88229823, eval_accuracy = 0.8818, f1_score = 0.88645524, false_negatives = 168.0, false_positives = 423.0, global_step = 1000, loss = 0.29552042, precision = 0.8450549, recall = 0.9321212, true_negatives = 2102.0, true_positives = 2307.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:02:39.078750 139683216717632 tf_logging.py:115] Saving dict for global step 1000: auc = 0.88229823, eval_accuracy = 0.8818, f1_score = 0.88645524, false_negatives = 168.0, false_positives = 423.0, global_step = 1000, loss = 0.29552042, precision = 0.8450549, recall = 0.9321212, true_negatives = 2102.0, true_positives = 2307.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ./model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:02:40.970923 139683216717632 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 1000: ./model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Metrics (Validation): {'auc': 0.88229823, 'eval_accuracy': 0.8818, 'f1_score': 0.88645524, 'false_negatives': 168.0, 'false_positives': 423.0, 'loss': 0.29552042, 'precision': 0.8450549, 'recall': 0.9321212, 'true_negatives': 2102.0, 'true_positives': 2307.0, 'global_step': 1000}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training for step = 1000\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:02:53.527291 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:02:57.089101 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:03:05.538080 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:03:05.541993 139683216717632 tf_logging.py:115] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:03:07.234352 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:03:07.238855 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:03:09.047710 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:03:09.216958 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:03:24.432518 139683216717632 tf_logging.py:115] Saving checkpoints for 1000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07602609, step = 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:03:43.763377 139683216717632 tf_logging.py:115] loss = 0.07602609, step = 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.917651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:05:32.736971 139683216717632 tf_logging.py:115] global_step/sec: 0.917651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.25567305, step = 1100 (108.976 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:05:32.739803 139683216717632 tf_logging.py:115] loss = 0.25567305, step = 1100 (108.976 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.996212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:07:13.117158 139683216717632 tf_logging.py:115] global_step/sec: 0.996212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2341236, step = 1200 (100.380 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:07:13.119598 139683216717632 tf_logging.py:115] loss = 0.2341236, step = 1200 (100.380 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.00142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:08:52.975339 139683216717632 tf_logging.py:115] global_step/sec: 1.00142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12094994, step = 1300 (99.858 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:08:52.978030 139683216717632 tf_logging.py:115] loss = 0.12094994, step = 1300 (99.858 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.00082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:10:32.893120 139683216717632 tf_logging.py:115] global_step/sec: 1.00082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24169251, step = 1400 (99.918 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:10:32.896367 139683216717632 tf_logging.py:115] loss = 0.24169251, step = 1400 (99.918 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.959301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:12:17.135712 139683216717632 tf_logging.py:115] global_step/sec: 0.959301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12847911, step = 1500 (104.243 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:12:17.139485 139683216717632 tf_logging.py:115] loss = 0.12847911, step = 1500 (104.243 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.00101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:13:57.034515 139683216717632 tf_logging.py:115] global_step/sec: 1.00101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.051168583, step = 1600 (99.897 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:13:57.036825 139683216717632 tf_logging.py:115] loss = 0.051168583, step = 1600 (99.897 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.00119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:15:36.915685 139683216717632 tf_logging.py:115] global_step/sec: 1.00119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.021226373, step = 1700 (99.881 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:15:36.917854 139683216717632 tf_logging.py:115] loss = 0.021226373, step = 1700 (99.881 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.999451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:17:16.970609 139683216717632 tf_logging.py:115] global_step/sec: 0.999451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.018390657, step = 1800 (100.055 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:17:16.972573 139683216717632 tf_logging.py:115] loss = 0.018390657, step = 1800 (100.055 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.999538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:18:57.016758 139683216717632 tf_logging.py:115] global_step/sec: 0.999538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04604488, step = 1900 (100.046 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:18:57.018996 139683216717632 tf_logging.py:115] loss = 0.04604488, step = 1900 (100.046 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:36.080904 139683216717632 tf_logging.py:115] Saving checkpoints for 2000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.0065474627.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:38.842007 139683216717632 tf_logging.py:115] Loss for final step: 0.0065474627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time (s): 1077.8704119649992\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:40.904001 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:44.161177 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:52.640472 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-21-10:20:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:52.660033 139683216717632 tf_logging.py:115] Starting evaluation at 2019-06-21-10:20:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:53.895852 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:53.899356 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:55.523023 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:20:55.670337 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-21-10:21:51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:21:51.756243 139683216717632 tf_logging.py:115] Finished evaluation at 2019-06-21-10:21:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2000: auc = 0.8854146, eval_accuracy = 0.885, f1_score = 0.8886306, false_negatives = 181.0, false_positives = 394.0, global_step = 2000, loss = 0.37891608, precision = 0.85342264, recall = 0.9268687, true_negatives = 2131.0, true_positives = 2294.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:21:51.758065 139683216717632 tf_logging.py:115] Saving dict for global step 2000: auc = 0.8854146, eval_accuracy = 0.885, f1_score = 0.8886306, false_negatives = 181.0, false_positives = 394.0, global_step = 2000, loss = 0.37891608, precision = 0.85342264, recall = 0.9268687, true_negatives = 2131.0, true_positives = 2294.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: ./model.ckpt-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:21:51.760136 139683216717632 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 2000: ./model.ckpt-2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Metrics (Validation): {'auc': 0.8854146, 'eval_accuracy': 0.885, 'f1_score': 0.8886306, 'false_negatives': 181.0, 'false_positives': 394.0, 'loss': 0.37891608, 'precision': 0.85342264, 'recall': 0.9268687, 'true_negatives': 2131.0, 'true_positives': 2294.0, 'global_step': 2000}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training for step = 2000\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:04.165378 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:07.787979 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:15.951213 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:15.956290 139683216717632 tf_logging.py:115] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:17.247689 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:17.251448 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:18.969302 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:19.131654 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:35.032096 139683216717632 tf_logging.py:115] Saving checkpoints for 2000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.008496029, step = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:22:54.361114 139683216717632 tf_logging.py:115] loss = 0.008496029, step = 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.907584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:24:44.542926 139683216717632 tf_logging.py:115] global_step/sec: 0.907584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1565062, step = 2100 (110.184 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:24:44.545254 139683216717632 tf_logging.py:115] loss = 0.1565062, step = 2100 (110.184 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.986189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:26:25.943384 139683216717632 tf_logging.py:115] global_step/sec: 0.986189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14769469, step = 2200 (101.400 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:26:25.945693 139683216717632 tf_logging.py:115] loss = 0.14769469, step = 2200 (101.400 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.988982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:28:07.057412 139683216717632 tf_logging.py:115] global_step/sec: 0.988982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.027861115, step = 2300 (101.114 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:28:07.059263 139683216717632 tf_logging.py:115] loss = 0.027861115, step = 2300 (101.114 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.988717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:29:48.198775 139683216717632 tf_logging.py:115] global_step/sec: 0.988717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.02586219, step = 2400 (101.141 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:29:48.200727 139683216717632 tf_logging.py:115] loss = 0.02586219, step = 2400 (101.141 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.948944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:31:33.578989 139683216717632 tf_logging.py:115] global_step/sec: 0.948944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00062784634, step = 2500 (105.381 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:31:33.581488 139683216717632 tf_logging.py:115] loss = 0.00062784634, step = 2500 (105.381 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.98944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:33:14.646322 139683216717632 tf_logging.py:115] global_step/sec: 0.98944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0006337907, step = 2600 (101.067 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:33:14.648205 139683216717632 tf_logging.py:115] loss = 0.0006337907, step = 2600 (101.067 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.992604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:34:55.391367 139683216717632 tf_logging.py:115] global_step/sec: 0.992604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0014543834, step = 2700 (100.745 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:34:55.393473 139683216717632 tf_logging.py:115] loss = 0.0014543834, step = 2700 (100.745 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.988699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:36:36.534365 139683216717632 tf_logging.py:115] global_step/sec: 0.988699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0008185753, step = 2800 (101.143 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:36:36.536118 139683216717632 tf_logging.py:115] loss = 0.0008185753, step = 2800 (101.143 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.990949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:38:17.447788 139683216717632 tf_logging.py:115] global_step/sec: 0.990949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0011993459, step = 2900 (100.914 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:38:17.450156 139683216717632 tf_logging.py:115] loss = 0.0011993459, step = 2900 (100.914 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:39:57.476696 139683216717632 tf_logging.py:115] Saving checkpoints for 3000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.00022269167.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:40:00.404667 139683216717632 tf_logging.py:115] Loss for final step: 0.00022269167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time (s): 1088.6431612939996\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:40:02.545997 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:40:05.852339 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:40:14.811772 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-21-10:40:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:40:14.833397 139683216717632 tf_logging.py:115] Starting evaluation at 2019-06-21-10:40:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:40:16.220524 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:40:16.224634 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:40:17.932560 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:40:18.086125 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-21-10:41:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:14.675338 139683216717632 tf_logging.py:115] Finished evaluation at 2019-06-21-10:41:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 3000: auc = 0.88311225, eval_accuracy = 0.8828, f1_score = 0.88536775, false_negatives = 212.0, false_positives = 374.0, global_step = 3000, loss = 0.6262498, precision = 0.8581722, recall = 0.9143434, true_negatives = 2151.0, true_positives = 2263.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:14.677197 139683216717632 tf_logging.py:115] Saving dict for global step 3000: auc = 0.88311225, eval_accuracy = 0.8828, f1_score = 0.88536775, false_negatives = 212.0, false_positives = 374.0, global_step = 3000, loss = 0.6262498, precision = 0.8581722, recall = 0.9143434, true_negatives = 2151.0, true_positives = 2263.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: ./model.ckpt-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:14.679218 139683216717632 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 3000: ./model.ckpt-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Metrics (Validation): {'auc': 0.88311225, 'eval_accuracy': 0.8828, 'f1_score': 0.88536775, 'false_negatives': 212.0, 'false_positives': 374.0, 'loss': 0.6262498, 'precision': 0.8581722, 'recall': 0.9143434, 'true_negatives': 2151.0, 'true_positives': 2263.0, 'global_step': 3000}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training for step = 3000\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:27.351634 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:30.708670 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:39.178846 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:39.182077 139683216717632 tf_logging.py:115] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:40.436379 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:40.441543 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:42.222096 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:42.432967 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:41:58.330596 139683216717632 tf_logging.py:115] Saving checkpoints for 3000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0002053967, step = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:42:18.255687 139683216717632 tf_logging.py:115] loss = 0.0002053967, step = 3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.905814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:44:08.653162 139683216717632 tf_logging.py:115] global_step/sec: 0.905814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.014883214, step = 3100 (110.400 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:44:08.655347 139683216717632 tf_logging.py:115] loss = 0.014883214, step = 3100 (110.400 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.983905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:45:50.288896 139683216717632 tf_logging.py:115] global_step/sec: 0.983905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00020419773, step = 3200 (101.636 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:45:50.291490 139683216717632 tf_logging.py:115] loss = 0.00020419773, step = 3200 (101.636 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.989016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:47:31.399501 139683216717632 tf_logging.py:115] global_step/sec: 0.989016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00035947884, step = 3300 (101.111 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:47:31.402078 139683216717632 tf_logging.py:115] loss = 0.00035947884, step = 3300 (101.111 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.987752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:49:12.639452 139683216717632 tf_logging.py:115] global_step/sec: 0.987752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0004549345, step = 3400 (101.240 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:49:12.642246 139683216717632 tf_logging.py:115] loss = 0.0004549345, step = 3400 (101.240 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.949889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:50:57.914932 139683216717632 tf_logging.py:115] global_step/sec: 0.949889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00013233945, step = 3500 (105.275 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:50:57.917559 139683216717632 tf_logging.py:115] loss = 0.00013233945, step = 3500 (105.275 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.989208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:52:39.005917 139683216717632 tf_logging.py:115] global_step/sec: 0.989208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00017646197, step = 3600 (101.090 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:52:39.007550 139683216717632 tf_logging.py:115] loss = 0.00017646197, step = 3600 (101.090 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.987266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:54:20.295742 139683216717632 tf_logging.py:115] global_step/sec: 0.987266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00041972127, step = 3700 (101.290 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:54:20.298024 139683216717632 tf_logging.py:115] loss = 0.00041972127, step = 3700 (101.290 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.986936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:56:01.619379 139683216717632 tf_logging.py:115] global_step/sec: 0.986936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00016924909, step = 3800 (101.323 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:56:01.621474 139683216717632 tf_logging.py:115] loss = 0.00016924909, step = 3800 (101.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.989346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:57:42.696370 139683216717632 tf_logging.py:115] global_step/sec: 0.989346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0001468564, step = 3900 (101.077 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:57:42.698618 139683216717632 tf_logging.py:115] loss = 0.0001468564, step = 3900 (101.077 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:22.909079 139683216717632 tf_logging.py:115] Saving checkpoints for 4000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 5.0053335e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:25.375405 139683216717632 tf_logging.py:115] Loss for final step: 5.0053335e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time (s): 1090.6949085699998\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:27.432203 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:31.005864 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:40.163416 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-21-10:59:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:40.183847 139683216717632 tf_logging.py:115] Starting evaluation at 2019-06-21-10:59:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:41.584120 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:41.587891 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:43.261599 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 10:59:43.411969 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-21-11:00:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:00:40.163148 139683216717632 tf_logging.py:115] Finished evaluation at 2019-06-21-11:00:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 4000: auc = 0.8850665, eval_accuracy = 0.885, f1_score = 0.8847463, false_negatives = 268.0, false_positives = 307.0, global_step = 4000, loss = 0.76216644, precision = 0.87788385, recall = 0.8917172, true_negatives = 2218.0, true_positives = 2207.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:00:40.165427 139683216717632 tf_logging.py:115] Saving dict for global step 4000: auc = 0.8850665, eval_accuracy = 0.885, f1_score = 0.8847463, false_negatives = 268.0, false_positives = 307.0, global_step = 4000, loss = 0.76216644, precision = 0.87788385, recall = 0.8917172, true_negatives = 2218.0, true_positives = 2207.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: ./model.ckpt-4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:00:40.167753 139683216717632 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 4000: ./model.ckpt-4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Metrics (Validation): {'auc': 0.8850665, 'eval_accuracy': 0.885, 'f1_score': 0.8847463, 'false_negatives': 268.0, 'false_positives': 307.0, 'loss': 0.76216644, 'precision': 0.87788385, 'recall': 0.8917172, 'true_negatives': 2218.0, 'true_positives': 2207.0, 'global_step': 4000}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training for step = 4000\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:00:52.780500 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:00:56.331662 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:01:05.288043 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:01:05.291510 139683216717632 tf_logging.py:115] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:01:06.565261 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:01:06.569761 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:01:08.411611 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:01:08.612033 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:01:24.658763 139683216717632 tf_logging.py:115] Saving checkpoints for 4000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.110317e-05, step = 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:01:44.559571 139683216717632 tf_logging.py:115] loss = 8.110317e-05, step = 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.912301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:03:34.171826 139683216717632 tf_logging.py:115] global_step/sec: 0.912301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00023115113, step = 4100 (109.614 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:03:34.173956 139683216717632 tf_logging.py:115] loss = 0.00023115113, step = 4100 (109.614 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.998621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:05:14.309928 139683216717632 tf_logging.py:115] global_step/sec: 0.998621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00016282272, step = 4200 (100.138 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:05:14.312071 139683216717632 tf_logging.py:115] loss = 0.00016282272, step = 4200 (100.138 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.00206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:06:54.104520 139683216717632 tf_logging.py:115] global_step/sec: 1.00206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.5813056e-05, step = 4300 (99.795 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:06:54.106741 139683216717632 tf_logging.py:115] loss = 5.5813056e-05, step = 4300 (99.795 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.00093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:08:34.011633 139683216717632 tf_logging.py:115] global_step/sec: 1.00093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.167465e-05, step = 4400 (99.907 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:08:34.013945 139683216717632 tf_logging.py:115] loss = 7.167465e-05, step = 4400 (99.907 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.964665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:10:17.674599 139683216717632 tf_logging.py:115] global_step/sec: 0.964665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.322879e-05, step = 4500 (103.662 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:10:17.676431 139683216717632 tf_logging.py:115] loss = 8.322879e-05, step = 4500 (103.662 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.00035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:11:57.639806 139683216717632 tf_logging.py:115] global_step/sec: 1.00035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.193409e-05, step = 4600 (99.965 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:11:57.641716 139683216717632 tf_logging.py:115] loss = 6.193409e-05, step = 4600 (99.965 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.00236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:13:37.404822 139683216717632 tf_logging.py:115] global_step/sec: 1.00236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00010336601, step = 4700 (99.765 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:13:37.406952 139683216717632 tf_logging.py:115] loss = 0.00010336601, step = 4700 (99.765 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.999911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:15:17.413707 139683216717632 tf_logging.py:115] global_step/sec: 0.999911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.833295e-05, step = 4800 (100.009 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:15:17.415549 139683216717632 tf_logging.py:115] loss = 4.833295e-05, step = 4800 (100.009 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.00014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:16:57.399376 139683216717632 tf_logging.py:115] global_step/sec: 1.00014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.302425e-05, step = 4900 (99.986 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:16:57.401425 139683216717632 tf_logging.py:115] loss = 8.302425e-05, step = 4900 (99.986 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:36.308480 139683216717632 tf_logging.py:115] Saving checkpoints for 5000 into ./model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 3.6639325e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:39.158623 139683216717632 tf_logging.py:115] Loss for final step: 3.6639325e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time (s): 1078.9906374540005\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:41.284880 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:44.305826 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:53.418797 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-21-11:18:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:53.440639 139683216717632 tf_logging.py:115] Starting evaluation at 2019-06-21-11:18:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:54.835994 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:54.841481 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:56.744149 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:18:56.899319 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-21-11:19:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:19:53.547437 139683216717632 tf_logging.py:115] Finished evaluation at 2019-06-21-11:19:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 5000: auc = 0.88574857, eval_accuracy = 0.8856, f1_score = 0.8862822, false_negatives = 246.0, false_positives = 326.0, global_step = 5000, loss = 0.8004833, precision = 0.872407, recall = 0.90060604, true_negatives = 2199.0, true_positives = 2229.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:19:53.549565 139683216717632 tf_logging.py:115] Saving dict for global step 5000: auc = 0.88574857, eval_accuracy = 0.8856, f1_score = 0.8862822, false_negatives = 246.0, false_positives = 326.0, global_step = 5000, loss = 0.8004833, precision = 0.872407, recall = 0.90060604, true_negatives = 2199.0, true_positives = 2229.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:19:53.551027 139683216717632 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 5000: ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Metrics (Validation): {'auc': 0.88574857, 'eval_accuracy': 0.8856, 'f1_score': 0.8862822, 'false_negatives': 246.0, 'false_positives': 326.0, 'loss': 0.8004833, 'precision': 0.872407, 'recall': 0.90060604, 'true_negatives': 2199.0, 'true_positives': 2229.0, 'global_step': 5000}\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "import time\n",
    "\n",
    "TOTAL_STEPS = num_train_steps\n",
    "STEP_SIZE = 1000\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    for step in range(0, TOTAL_STEPS, STEP_SIZE):\n",
    "        print()\n",
    "        print('-'*100)\n",
    "        print('Training for step =', step)\n",
    "        start_time = time.monotonic()\n",
    "        estimator.train(input_fn=train_input_fn, steps=STEP_SIZE)\n",
    "        elapsed_time = time.monotonic() - start_time\n",
    "        print('Train Time (s):', elapsed_time)\n",
    "        print('Eval Metrics (Validation):', estimator.evaluate(input_fn=val_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:20:05.879234 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:20:09.548363 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:20:17.969020 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-21-11:20:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:20:17.988731 139683216717632 tf_logging.py:115] Starting evaluation at 2019-06-21-11:20:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:20:19.310905 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:20:19.315236 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:20:21.202335 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:20:21.410462 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-21-11:25:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:25:44.419113 139683216717632 tf_logging.py:115] Finished evaluation at 2019-06-21-11:25:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 5000: auc = 0.99963325, eval_accuracy = 0.9996333, f1_score = 0.99963367, false_negatives = 5.0, false_positives = 6.0, global_step = 5000, loss = 0.002022977, precision = 0.9996004, recall = 0.999667, true_negatives = 14979.0, true_positives = 15010.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:25:44.421201 139683216717632 tf_logging.py:115] Saving dict for global step 5000: auc = 0.99963325, eval_accuracy = 0.9996333, f1_score = 0.99963367, false_negatives = 5.0, false_positives = 6.0, global_step = 5000, loss = 0.002022977, precision = 0.9996004, recall = 0.999667, true_negatives = 14979.0, true_positives = 15010.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:25:44.423527 139683216717632 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 5000: ./model.ckpt-5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.99963325,\n",
       " 'eval_accuracy': 0.9996333,\n",
       " 'f1_score': 0.99963367,\n",
       " 'false_negatives': 5.0,\n",
       " 'false_positives': 6.0,\n",
       " 'loss': 0.002022977,\n",
       " 'precision': 0.9996004,\n",
       " 'recall': 0.999667,\n",
       " 'true_negatives': 14979.0,\n",
       " 'true_positives': 15010.0,\n",
       " 'global_step': 5000}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eval_fn = bert.run_classifier.input_fn_builder(features=train_features,\n",
    "                                                      seq_length=MAX_SEQ_LENGTH,\n",
    "                                                      is_training=False,\n",
    "                                                      drop_remainder=False)\n",
    "\n",
    "estimator.evaluate(input_fn=train_eval_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:25:46.462184 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:25:50.282655 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:25:59.101998 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-21-11:25:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:25:59.122987 139683216717632 tf_logging.py:115] Starting evaluation at 2019-06-21-11:25:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:00.380154 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:00.384164 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:02.138422 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:02.285797 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-21-11:26:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.277312 139683216717632 tf_logging.py:115] Finished evaluation at 2019-06-21-11:26:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 5000: auc = 0.88574857, eval_accuracy = 0.8856, f1_score = 0.8862822, false_negatives = 246.0, false_positives = 326.0, global_step = 5000, loss = 0.8004833, precision = 0.872407, recall = 0.90060604, true_negatives = 2199.0, true_positives = 2229.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.279388 139683216717632 tf_logging.py:115] Saving dict for global step 5000: auc = 0.88574857, eval_accuracy = 0.8856, f1_score = 0.8862822, false_negatives = 246.0, false_positives = 326.0, global_step = 5000, loss = 0.8004833, precision = 0.872407, recall = 0.90060604, true_negatives = 2199.0, true_positives = 2229.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.281645 139683216717632 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 5000: ./model.ckpt-5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.88574857,\n",
       " 'eval_accuracy': 0.8856,\n",
       " 'f1_score': 0.8862822,\n",
       " 'false_negatives': 246.0,\n",
       " 'false_positives': 326.0,\n",
       " 'loss': 0.8004833,\n",
       " 'precision': 0.872407,\n",
       " 'recall': 0.90060604,\n",
       " 'true_negatives': 2199.0,\n",
       " 'true_positives': 2229.0,\n",
       " 'global_step': 5000}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.568448 139683216717632 tf_logging.py:115] Writing example 0 of 15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.571476 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.572467 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] just don ' t bother . i thought i would see a movie with great su ##ps ##pen ##se and action . < br / > < br / > but it grows boring and terribly predictable after the interesting start . in the middle of the film you have a little social drama and all tension is lost because it slow ##s down the speed . towards the end the it gets better but not really great . i think the director took this movie just too serious . in such a kind of a movie even if u don ' t care about the plot at least you want some nice action . i nearly do ##zed off in the middle / main part [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.574589 139683216717632 tf_logging.py:115] tokens: [CLS] just don ' t bother . i thought i would see a movie with great su ##ps ##pen ##se and action . < br / > < br / > but it grows boring and terribly predictable after the interesting start . in the middle of the film you have a little social drama and all tension is lost because it slow ##s down the speed . towards the end the it gets better but not really great . i think the director took this movie just too serious . in such a kind of a movie even if u don ' t care about the plot at least you want some nice action . i nearly do ##zed off in the middle / main part [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2074 2123 1005 1056 8572 1012 1045 2245 1045 2052 2156 1037 3185 2007 2307 10514 4523 11837 3366 1998 2895 1012 1026 7987 1013 1028 1026 7987 1013 1028 2021 2009 7502 11771 1998 16668 21425 2044 1996 5875 2707 1012 1999 1996 2690 1997 1996 2143 2017 2031 1037 2210 2591 3689 1998 2035 6980 2003 2439 2138 2009 4030 2015 2091 1996 3177 1012 2875 1996 2203 1996 2009 4152 2488 2021 2025 2428 2307 1012 1045 2228 1996 2472 2165 2023 3185 2074 2205 3809 1012 1999 2107 1037 2785 1997 1037 3185 2130 2065 1057 2123 1005 1056 2729 2055 1996 5436 2012 2560 2017 2215 2070 3835 2895 1012 1045 3053 2079 5422 2125 1999 1996 2690 1013 2364 2112 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.575619 139683216717632 tf_logging.py:115] input_ids: 101 2074 2123 1005 1056 8572 1012 1045 2245 1045 2052 2156 1037 3185 2007 2307 10514 4523 11837 3366 1998 2895 1012 1026 7987 1013 1028 1026 7987 1013 1028 2021 2009 7502 11771 1998 16668 21425 2044 1996 5875 2707 1012 1999 1996 2690 1997 1996 2143 2017 2031 1037 2210 2591 3689 1998 2035 6980 2003 2439 2138 2009 4030 2015 2091 1996 3177 1012 2875 1996 2203 1996 2009 4152 2488 2021 2025 2428 2307 1012 1045 2228 1996 2472 2165 2023 3185 2074 2205 3809 1012 1999 2107 1037 2785 1997 1037 3185 2130 2065 1057 2123 1005 1056 2729 2055 1996 5436 2012 2560 2017 2215 2070 3835 2895 1012 1045 3053 2079 5422 2125 1999 1996 2690 1013 2364 2112 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.576573 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.578663 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.579672 139683216717632 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.585052 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.585983 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] be careful with this one . once you get yer mit ##ts on it , it ' ll change the way you look at kung - fu flick ##s . you will be yearning a plot from all of the kung - fu films now , you will be wanting character depth and development , you will be craving mystery and un ##pre ##dict ##ability , you will demand dynamic camera work and incredible backdrop ##s . sadly , you won ' t find all of these aspects together in one kung - fu movie , except for five deadly venom ##s ! < br / > < br / > easily the best kung - fu movie of all - time , venom ##s blend [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.587085 139683216717632 tf_logging.py:115] tokens: [CLS] be careful with this one . once you get yer mit ##ts on it , it ' ll change the way you look at kung - fu flick ##s . you will be yearning a plot from all of the kung - fu films now , you will be wanting character depth and development , you will be craving mystery and un ##pre ##dict ##ability , you will demand dynamic camera work and incredible backdrop ##s . sadly , you won ' t find all of these aspects together in one kung - fu movie , except for five deadly venom ##s ! < br / > < br / > easily the best kung - fu movie of all - time , venom ##s blend [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2022 6176 2007 2023 2028 1012 2320 2017 2131 20416 10210 3215 2006 2009 1010 2009 1005 2222 2689 1996 2126 2017 2298 2012 18577 1011 11865 17312 2015 1012 2017 2097 2022 29479 1037 5436 2013 2035 1997 1996 18577 1011 11865 3152 2085 1010 2017 2097 2022 5782 2839 5995 1998 2458 1010 2017 2097 2022 26369 6547 1998 4895 28139 29201 8010 1010 2017 2097 5157 8790 4950 2147 1998 9788 18876 2015 1012 13718 1010 2017 2180 1005 1056 2424 2035 1997 2122 5919 2362 1999 2028 18577 1011 11865 3185 1010 3272 2005 2274 9252 15779 2015 999 1026 7987 1013 1028 1026 7987 1013 1028 4089 1996 2190 18577 1011 11865 3185 1997 2035 1011 2051 1010 15779 2015 12586 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.587970 139683216717632 tf_logging.py:115] input_ids: 101 2022 6176 2007 2023 2028 1012 2320 2017 2131 20416 10210 3215 2006 2009 1010 2009 1005 2222 2689 1996 2126 2017 2298 2012 18577 1011 11865 17312 2015 1012 2017 2097 2022 29479 1037 5436 2013 2035 1997 1996 18577 1011 11865 3152 2085 1010 2017 2097 2022 5782 2839 5995 1998 2458 1010 2017 2097 2022 26369 6547 1998 4895 28139 29201 8010 1010 2017 2097 5157 8790 4950 2147 1998 9788 18876 2015 1012 13718 1010 2017 2180 1005 1056 2424 2035 1997 2122 5919 2362 1999 2028 18577 1011 11865 3185 1010 3272 2005 2274 9252 15779 2015 999 1026 7987 1013 1028 1026 7987 1013 1028 4089 1996 2190 18577 1011 11865 3185 1997 2035 1011 2051 1010 15779 2015 12586 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.588782 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.589577 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.590430 139683216717632 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.594294 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.597595 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] chili palmer is tired of doing movies and know wants to do some success in music . being half ma ##fi ##oso half expert ne ##go ##tia ##tor , he wants to rise in the music market . however , know everyone is like him and making the good singer linda moon to record a hit will be harder as expected . the first part is funny and filled with irony , this one falls into the easy jokes and has many less good moments . only the two women ( um ##a and mil ##ian ) are decent in their part . most of the film is done with his ##tri ##onic character , excessive ##ly exaggerated ( a little is ok , too much [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.598495 139683216717632 tf_logging.py:115] tokens: [CLS] chili palmer is tired of doing movies and know wants to do some success in music . being half ma ##fi ##oso half expert ne ##go ##tia ##tor , he wants to rise in the music market . however , know everyone is like him and making the good singer linda moon to record a hit will be harder as expected . the first part is funny and filled with irony , this one falls into the easy jokes and has many less good moments . only the two women ( um ##a and mil ##ian ) are decent in their part . most of the film is done with his ##tri ##onic character , excessive ##ly exaggerated ( a little is ok , too much [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 20238 8809 2003 5458 1997 2725 5691 1998 2113 4122 2000 2079 2070 3112 1999 2189 1012 2108 2431 5003 8873 19137 2431 6739 11265 3995 10711 4263 1010 2002 4122 2000 4125 1999 1996 2189 3006 1012 2174 1010 2113 3071 2003 2066 2032 1998 2437 1996 2204 3220 8507 4231 2000 2501 1037 2718 2097 2022 6211 2004 3517 1012 1996 2034 2112 2003 6057 1998 3561 2007 19728 1010 2023 2028 4212 2046 1996 3733 13198 1998 2038 2116 2625 2204 5312 1012 2069 1996 2048 2308 1006 8529 2050 1998 23689 2937 1007 2024 11519 1999 2037 2112 1012 2087 1997 1996 2143 2003 2589 2007 2010 18886 12356 2839 1010 11664 2135 16903 1006 1037 2210 2003 7929 1010 2205 2172 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.599321 139683216717632 tf_logging.py:115] input_ids: 101 20238 8809 2003 5458 1997 2725 5691 1998 2113 4122 2000 2079 2070 3112 1999 2189 1012 2108 2431 5003 8873 19137 2431 6739 11265 3995 10711 4263 1010 2002 4122 2000 4125 1999 1996 2189 3006 1012 2174 1010 2113 3071 2003 2066 2032 1998 2437 1996 2204 3220 8507 4231 2000 2501 1037 2718 2097 2022 6211 2004 3517 1012 1996 2034 2112 2003 6057 1998 3561 2007 19728 1010 2023 2028 4212 2046 1996 3733 13198 1998 2038 2116 2625 2204 5312 1012 2069 1996 2048 2308 1006 8529 2050 1998 23689 2937 1007 2024 11519 1999 2037 2112 1012 2087 1997 1996 2143 2003 2589 2007 2010 18886 12356 2839 1010 11664 2135 16903 1006 1037 2210 2003 7929 1010 2205 2172 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.600050 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.600768 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.602732 139683216717632 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.616149 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.617443 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] following is a little - known 1998 british film , which was made with a budget of £ ##80 ##00 and has a running time of 70 minutes . when watching it , you ' d never expect its director to go on to make it in hollywood and become one of the most acclaimed and celebrated directors of the 21st century well , everybody has to start somewhere i suppose . < br / > < br / > the director of following , as you probably already know is englishman christopher nolan , who directly after following would go on to direct the critically - acclaimed independent film me ##mento ; a few years later he would be hired by warner bros . to [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.618662 139683216717632 tf_logging.py:115] tokens: [CLS] following is a little - known 1998 british film , which was made with a budget of £ ##80 ##00 and has a running time of 70 minutes . when watching it , you ' d never expect its director to go on to make it in hollywood and become one of the most acclaimed and celebrated directors of the 21st century well , everybody has to start somewhere i suppose . < br / > < br / > the director of following , as you probably already know is englishman christopher nolan , who directly after following would go on to direct the critically - acclaimed independent film me ##mento ; a few years later he would be hired by warner bros . to [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2206 2003 1037 2210 1011 2124 2687 2329 2143 1010 2029 2001 2081 2007 1037 5166 1997 1069 17914 8889 1998 2038 1037 2770 2051 1997 3963 2781 1012 2043 3666 2009 1010 2017 1005 1040 2196 5987 2049 2472 2000 2175 2006 2000 2191 2009 1999 5365 1998 2468 2028 1997 1996 2087 10251 1998 6334 5501 1997 1996 7398 2301 2092 1010 7955 2038 2000 2707 4873 1045 6814 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2472 1997 2206 1010 2004 2017 2763 2525 2113 2003 25244 5696 13401 1010 2040 3495 2044 2206 2052 2175 2006 2000 3622 1996 11321 1011 10251 2981 2143 2033 23065 1025 1037 2261 2086 2101 2002 2052 2022 5086 2011 6654 10243 1012 2000 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.619599 139683216717632 tf_logging.py:115] input_ids: 101 2206 2003 1037 2210 1011 2124 2687 2329 2143 1010 2029 2001 2081 2007 1037 5166 1997 1069 17914 8889 1998 2038 1037 2770 2051 1997 3963 2781 1012 2043 3666 2009 1010 2017 1005 1040 2196 5987 2049 2472 2000 2175 2006 2000 2191 2009 1999 5365 1998 2468 2028 1997 1996 2087 10251 1998 6334 5501 1997 1996 7398 2301 2092 1010 7955 2038 2000 2707 4873 1045 6814 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2472 1997 2206 1010 2004 2017 2763 2525 2113 2003 25244 5696 13401 1010 2040 3495 2044 2206 2052 2175 2006 2000 3622 1996 11321 1011 10251 2981 2143 2033 23065 1025 1037 2261 2086 2101 2002 2052 2022 5086 2011 6654 10243 1012 2000 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.621229 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.622125 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.623018 139683216717632 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.626083 139683216717632 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.628141 139683216717632 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] dark angel is a cross between hu ##xley ' s brave new world and percy ' s love in the ruins - - portraying the not too distant future as a disturbing mixture of chaos and order , both in the worst sense of the word . once one swallows the premise that all modern technology can be brought to a stands ##till by \" the pulse , \" it provides an entertaining landscape for exploring the personalities of and relationships between the two primary characters - - max ( the dark angel / bike messenger ) and logan ( the rich rebel ) . it seems uneven , perhaps a result of a variety of authors , but is held together by the energetic , [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.629061 139683216717632 tf_logging.py:115] tokens: [CLS] dark angel is a cross between hu ##xley ' s brave new world and percy ' s love in the ruins - - portraying the not too distant future as a disturbing mixture of chaos and order , both in the worst sense of the word . once one swallows the premise that all modern technology can be brought to a stands ##till by \" the pulse , \" it provides an entertaining landscape for exploring the personalities of and relationships between the two primary characters - - max ( the dark angel / bike messenger ) and logan ( the rich rebel ) . it seems uneven , perhaps a result of a variety of authors , but is held together by the energetic , [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2601 4850 2003 1037 2892 2090 15876 20959 1005 1055 9191 2047 2088 1998 11312 1005 1055 2293 1999 1996 8435 1011 1011 17274 1996 2025 2205 6802 2925 2004 1037 14888 8150 1997 8488 1998 2344 1010 2119 1999 1996 5409 3168 1997 1996 2773 1012 2320 2028 26436 1996 18458 2008 2035 2715 2974 2064 2022 2716 2000 1037 4832 28345 2011 1000 1996 8187 1010 1000 2009 3640 2019 14036 5957 2005 11131 1996 12857 1997 1998 6550 2090 1996 2048 3078 3494 1011 1011 4098 1006 1996 2601 4850 1013 7997 11981 1007 1998 6307 1006 1996 4138 8443 1007 1012 2009 3849 17837 1010 3383 1037 2765 1997 1037 3528 1997 6048 1010 2021 2003 2218 2362 2011 1996 18114 1010 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.629928 139683216717632 tf_logging.py:115] input_ids: 101 2601 4850 2003 1037 2892 2090 15876 20959 1005 1055 9191 2047 2088 1998 11312 1005 1055 2293 1999 1996 8435 1011 1011 17274 1996 2025 2205 6802 2925 2004 1037 14888 8150 1997 8488 1998 2344 1010 2119 1999 1996 5409 3168 1997 1996 2773 1012 2320 2028 26436 1996 18458 2008 2035 2715 2974 2064 2022 2716 2000 1037 4832 28345 2011 1000 1996 8187 1010 1000 2009 3640 2019 14036 5957 2005 11131 1996 12857 1997 1998 6550 2090 1996 2048 3078 3494 1011 1011 4098 1006 1996 2601 4850 1013 7997 11981 1007 1998 6307 1006 1996 4138 8443 1007 1012 2009 3849 17837 1010 3383 1037 2765 1997 1037 3528 1997 6048 1010 2021 2003 2218 2362 2011 1996 18114 1010 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.630823 139683216717632 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.631687 139683216717632 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:26:58.632506 139683216717632 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:27:33.905021 139683216717632 tf_logging.py:115] Writing example 10000 of 15000\n"
     ]
    }
   ],
   "source": [
    "test_input_examples = test_df.apply(lambda row: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                                 text_a=row[DATA_COLUMN], \n",
    "                                                                                 text_b=None, \n",
    "                                                                                 label=row[LABEL_COLUMN]), \n",
    "                                    axis=1)\n",
    "\n",
    "test_features = (bert.run_classifier\n",
    "                     .convert_examples_to_features(test_input_examples, \n",
    "                                                   label_list, \n",
    "                                                   MAX_SEQ_LENGTH, \n",
    "                                                   tokenizer))\n",
    "\n",
    "test_input_fn = bert.run_classifier.input_fn_builder(features=test_features,\n",
    "                                                     seq_length=MAX_SEQ_LENGTH,\n",
    "                                                     is_training=False,\n",
    "                                                     drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:27:57.695512 139683216717632 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:28:01.289114 139683216717632 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:28:10.089350 139683216717632 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-21-11:28:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:28:10.113395 139683216717632 tf_logging.py:115] Starting evaluation at 2019-06-21-11:28:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:28:11.429640 139683216717632 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:28:11.433333 139683216717632 tf_logging.py:115] Restoring parameters from ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:28:13.180720 139683216717632 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:28:13.420335 139683216717632 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-21-11:30:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:30:56.030908 139683216717632 tf_logging.py:115] Finished evaluation at 2019-06-21-11:30:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 5000: auc = 0.8883222, eval_accuracy = 0.8883333, f1_score = 0.88938785, false_negatives = 776.0, false_positives = 899.0, global_step = 5000, loss = 0.8116456, precision = 0.88222194, recall = 0.8966711, true_negatives = 6591.0, true_positives = 6734.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:30:56.032912 139683216717632 tf_logging.py:115] Saving dict for global step 5000: auc = 0.8883222, eval_accuracy = 0.8883333, f1_score = 0.88938785, false_negatives = 776.0, false_positives = 899.0, global_step = 5000, loss = 0.8116456, precision = 0.88222194, recall = 0.8966711, true_negatives = 6591.0, true_positives = 6734.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: ./model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0621 11:30:56.035010 139683216717632 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 5000: ./model.ckpt-5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8883222,\n",
       " 'eval_accuracy': 0.8883333,\n",
       " 'f1_score': 0.88938785,\n",
       " 'false_negatives': 776.0,\n",
       " 'false_positives': 899.0,\n",
       " 'loss': 0.8116456,\n",
       " 'precision': 0.88222194,\n",
       " 'recall': 0.8966711,\n",
       " 'true_negatives': 6591.0,\n",
       " 'true_positives': 6734.0,\n",
       " 'global_step': 5000}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
