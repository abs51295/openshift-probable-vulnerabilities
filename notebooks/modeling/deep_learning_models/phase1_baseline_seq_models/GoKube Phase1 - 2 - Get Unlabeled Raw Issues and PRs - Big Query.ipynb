{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get GoKube Repos which had past CVEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1881 entries, 0 to 1880\n",
      "Data columns (total 12 columns):\n",
      "CVE ID               1328 non-null object\n",
      "Package name         1804 non-null object\n",
      "Ecosystem            1874 non-null object\n",
      "GH issue             715 non-null object\n",
      "GH PR                373 non-null object\n",
      "GH Commit            948 non-null object\n",
      "Bugzilla             259 non-null object\n",
      "ML                   482 non-null object\n",
      "Other sources        65 non-null object\n",
      "Issue Reported on    51 non-null object\n",
      "CVE reported on      58 non-null object\n",
      "Fixed on             76 non-null object\n",
      "dtypes: object(12)\n",
      "memory usage: 176.4+ KB\n"
     ]
    }
   ],
   "source": [
    "cve_df = pd.read_csv('./data/positive_github_links/go_cves_positive_links-may2019.csv')\n",
    "cve_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_df = cve_df[cve_df.Ecosystem == 'go']\n",
    "go_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues Before: (36,)\n",
      "Issues After: (39,)\n",
      "PRs Before: (40,)\n",
      "PRs After: (45,)\n",
      "Commits Before: (73,)\n",
      "Commits After: (78,)\n"
     ]
    }
   ],
   "source": [
    "gh_issues = go_df['GH issue'].dropna().values\n",
    "print('Issues Before:', gh_issues.shape)\n",
    "gh_issues = [item.strip().split('\\n') for item in gh_issues]\n",
    "gh_issues = np.array([str(item.strip()) for sublist in gh_issues for item in sublist])\n",
    "print('Issues After:', gh_issues.shape)\n",
    "\n",
    "gh_prs = go_df['GH PR'].dropna().values\n",
    "print('PRs Before:', gh_prs.shape)\n",
    "gh_prs = [item.strip().split('\\n') for item in gh_prs]\n",
    "gh_prs = np.array([str(item.strip()) for sublist in gh_prs for item in sublist])\n",
    "print('PRs After:', gh_prs.shape)\n",
    "\n",
    "gh_commits = go_df['GH Commit'].dropna().values\n",
    "print('Commits Before:', gh_commits.shape)\n",
    "gh_commits = [item.strip().split('\\n') for item in gh_commits]\n",
    "gh_commits = np.array([str(item.strip()) for sublist in gh_commits for item in sublist])\n",
    "print('Commits After:', gh_commits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_links = np.concatenate((gh_issues, gh_commits, gh_prs))\n",
    "gh_links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_links = np.unique(gh_links)\n",
    "gh_links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_links = np.array([item for item in gh_links if 'github' in item])\n",
    "gh_links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://github.com/apache/thrift/commit/2007783e874d524a46b818598a45078448ecc53e',\n",
       "       'https://github.com/apache/thrift/pull/1061',\n",
       "       'https://github.com/astaxie/beego/commit/9865779f149669777ee33aae71cd29c8db8ffd66',\n",
       "       'https://github.com/astaxie/beego/pull/3383',\n",
       "       'https://github.com/brancz/kube-rbac-proxy/commit/c41c4dee92abc0859d952559e37cf9ad8a442789',\n",
       "       'https://github.com/brancz/kube-rbac-proxy/pull/27',\n",
       "       'https://github.com/cisco/node-jose/pull/88',\n",
       "       'https://github.com/cloudflare/cfssl/commit/f74c74db7f22df0051d7f872b5161dfa2a797ace',\n",
       "       'https://github.com/cloudflare/cfssl/pull/776',\n",
       "       'https://github.com/cloudfoundry-incubator/bits-service/commit/9e4010e42a4b462fef69889a453b5c32d56e3100'],\n",
       "      dtype='<U130')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r'.*?github.com/(.*?/.*?)/', re.I)\n",
    "repo_names = np.array(list(filter(None,[pattern.search(item).group(1) \n",
    "                                            if pattern.search(item) else None \n",
    "                                               for item in gh_links])))\n",
    "repo_names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_names = np.unique(repo_names)\n",
    "repo_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Unlabeled GitHub Data for Repos having past CVEs \n",
    "## (Go-Kube ecosystem only) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bq_utils as bqu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bq_utils.BigQueryHelper at 0x7fb07e91f390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'bq_key.json'\n",
    "gh_archive = bqu.BigQueryHelper(active_project= \"githubarchive\", \n",
    "                                dataset_name = \"year\")\n",
    "gh_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_archive.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.9256986239925"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT  type, count(*)\n",
    "        FROM `githubarchive.year.20*`\n",
    "        WHERE _TABLE_SUFFIX IN ('16', '17', '18')\n",
    "        AND repo.name in {repos}\n",
    "        GROUP BY type\n",
    "\"\"\".format(repos=tuple(repo_names))\n",
    "gh_archive.estimate_query_size(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PullRequestEvent</td>\n",
       "      <td>168759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IssueCommentEvent</td>\n",
       "      <td>1623715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PullRequestReviewCommentEvent</td>\n",
       "      <td>236683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>117640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IssuesEvent</td>\n",
       "      <td>195866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             type      f0_\n",
       "2                PullRequestEvent   168759\n",
       "3               IssueCommentEvent  1623715\n",
       "6   PullRequestReviewCommentEvent   236683\n",
       "10                      PushEvent   117640\n",
       "12                    IssuesEvent   195866"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gh_archive.query_to_pandas(query)\n",
    "df[df.type.isin(['PushEvent', 'PullRequestEvent', 'IssuesEvent', \n",
    "                'PullRequestReviewCommentEvent', 'IssueCommentEvent'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2583.8375390227884"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    repo.name as repo_name, \n",
    "    type as event_type, \n",
    "    actor.id as actor_id,\n",
    "    actor.login as actor_name,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.action') as issue_status,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.url') as issue_api_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.html_url') as issue_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.user.login') as issue_creator_name,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.user.url') as issue_creator_api_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.user.html_url') as issue_creator_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.comments') as comment_count,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.id') as issue_id,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.number') as issue_number,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.created_at') as issue_created_at,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.updated_at') as issue_updated_at,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.issue.closed_at') as issue_closed_at,\n",
    "    TRIM(REGEXP_REPLACE(\n",
    "             REGEXP_REPLACE(\n",
    "                 JSON_EXTRACT_SCALAR(payload, '$.issue.title'), \n",
    "                 r'\\\\r\\\\n|\\\\r|\\\\n', \n",
    "                 ' '),\n",
    "             r'\\s{2,}', \n",
    "             ' ')) as issue_title,\n",
    "    TRIM(REGEXP_REPLACE(\n",
    "             REGEXP_REPLACE(\n",
    "                 JSON_EXTRACT_SCALAR(payload, '$.issue.body'), \n",
    "                 r'\\\\r\\\\n|\\\\r|\\\\n', \n",
    "                 ' '),\n",
    "             r'\\s{2,}', \n",
    "             ' ')) as issue_body\n",
    "        \n",
    "FROM `githubarchive.year.20*`\n",
    "    WHERE _TABLE_SUFFIX IN ('16', '17', '18')\n",
    "    AND repo.name in {repos}\n",
    "    AND type = 'IssuesEvent'\n",
    "    \"\"\".replace('{repos}', str(tuple(repo_names)))\n",
    "gh_archive.estimate_query_size(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = gh_archive.query_to_pandas(query)\n",
    "issues_df.to_csv('./data/gokube_phase1_jun19/GH_unlabeled_issues.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2583.8375390227884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    repo.name as repo_name, \n",
    "    type as event_type, \n",
    "    actor.id as actor_id,\n",
    "    actor.login as actor_name,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.action') as pr_status,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.id') as pr_id,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.number') as pr_number,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.url') as pr_api_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.html_url') as pr_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.diff_url') as pr_diff_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.patch_url') as pr_patch_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.user.login') as pr_creator_name,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.user.url') as pr_creator_api_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.user.html_url') as pr_creator_url,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.created_at') as pr_created_at,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.updated_at') as pr_updated_at,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.closed_at') as pr_closed_at,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.merged_at') as pr_merged_at,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.merged') as pr_merged_status,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.comments') as pr_comments_count,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.review_comments') as pr_review_comments_count,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.commits') as pr_commits_count,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.additions') as pr_additions_count,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.deletions') as pr_deletions_count,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.changed_files') as pr_changed_files_count,    \n",
    "    TRIM(REGEXP_REPLACE(\n",
    "             REGEXP_REPLACE(\n",
    "                 JSON_EXTRACT_SCALAR(payload, '$.pull_request.title'), \n",
    "                 r'\\\\r\\\\n|\\\\r|\\\\n', \n",
    "                 ' '),\n",
    "             r'\\s{2,}', \n",
    "             ' ')) as pr_title,\n",
    "    TRIM(REGEXP_REPLACE(\n",
    "             REGEXP_REPLACE(\n",
    "                 JSON_EXTRACT_SCALAR(payload, '$.pull_request.body'), \n",
    "                 r'\\\\r\\\\n|\\\\r|\\\\n', \n",
    "                 ' '),\n",
    "             r'\\s{2,}', \n",
    "             ' ')) as pr_body\n",
    "        \n",
    "FROM `githubarchive.year.20*`\n",
    "    WHERE _TABLE_SUFFIX IN ('16', '17', '18')\n",
    "    AND repo.name in {repos}\n",
    "    AND type = 'PullRequestEvent'\n",
    "\"\"\".replace('{repos}', str(tuple(repo_names)))\n",
    "gh_archive.estimate_query_size(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs_df = gh_archive.query_to_pandas(query)\n",
    "prs_df.to_csv('./data/gokube_phase1_jun19/GH_unlabeled_prs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = pd.DataFrame(repo_names, columns=['repo_names'])\n",
    "repos.to_csv('./data/gokube_phase1_jun19/Go_GH_repo_names.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
