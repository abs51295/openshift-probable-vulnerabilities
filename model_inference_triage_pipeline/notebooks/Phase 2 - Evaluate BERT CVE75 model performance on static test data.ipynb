{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/redanalyze/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import bert_text_processor as btp\n",
    "from models import bert_cve_classifier as bcvec\n",
    "from sklearn.utils import class_weight\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Counter({1: 22572, 2: 671})\n",
      "After: Counter({0: 22572, 1: 671})\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('../../data/GH_complete_labeled_issues_prs - preprocessed.csv', encoding='utf-8', \n",
    "                      na_filter=False)\n",
    "dataset = dataset[dataset.label != 0]\n",
    "texts = dataset['description'].tolist()\n",
    "labels = dataset['label'].tolist()\n",
    "\n",
    "print('Before:', Counter(labels))\n",
    "labels = [0 if item == 1 else 1 for item in labels]\n",
    "print('After:', Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17432, 5811)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(texts, labels, \n",
    "                                                                    test_size=0.25, random_state=SEED)\n",
    "len(train_text), len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Params for bert model and tokenization\n",
    "BERT_PATH = \"models/model_assets/gokube-phase2/base_bert_tfhub_models/bert_uncased_L12_H768_A12\"\n",
    "MAX_SEQ_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Base BERT Model\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0811 05:51:18.691654 140712378369856 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n",
      "Converting text to examples: 5811it [00:00, 579994.30it/s]\n",
      "Converting examples to features:   0%|          | 0/5811 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT WordPiece Tokenizer\n",
      "Creating Input Examples from data\n",
      "Creating BERT Input Features from Input Examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting examples to features: 100%|██████████| 5811/5811 [01:28<00:00, 65.66it/s] \n"
     ]
    }
   ],
   "source": [
    "# process text data\n",
    "btp_test = btp.BertTextProcessor(tf_session=sess, \n",
    "                                  bert_model_path=BERT_PATH, \n",
    "                                  max_seq_length=MAX_SEQ_LENGTH)\n",
    "btp_test.create_bert_tokenizer()\n",
    "btp_test.convert_text_to_input_examples(test_text, test_labels)\n",
    "btp_test.convert_examples_to_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build BERT Classifier CVE Model Architecture\n",
      "Loading Base BERT Model\n",
      "Trainable layers: 199\n",
      "Non Trainable layers: 5\n",
      "Constructing Base BERT architecture\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 05:56:37.218409 140712378369856 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "bc = bcvec.BERTClassifier(bert_model_path=BERT_PATH, \n",
    "                          max_seq_length=MAX_SEQ_LENGTH)\n",
    "bc.build_model_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 304s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL1 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:01-trn_loss:0.379-trn_acc:0.904-val_loss:0.229-val_acc:0.918.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL1)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96      5646\n",
      "           1       0.26      0.86      0.39       165\n",
      "\n",
      "    accuracy                           0.92      5811\n",
      "   macro avg       0.63      0.89      0.68      5811\n",
      "weighted avg       0.97      0.92      0.94      5811\n",
      "\n",
      "[[5232  414]\n",
      " [  23  142]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 300s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL2 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:02-trn_loss:0.176-trn_acc:0.959-val_loss:0.153-val_acc:0.941.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL2)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96      5646\n",
      "           1       0.27      0.88      0.41       165\n",
      "\n",
      "    accuracy                           0.93      5811\n",
      "   macro avg       0.63      0.91      0.69      5811\n",
      "weighted avg       0.98      0.93      0.95      5811\n",
      "\n",
      "[[5243  403]\n",
      " [  19  146]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 304s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL3 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:03-trn_loss:0.096-trn_acc:0.981-val_loss:0.284-val_acc:0.976.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL3)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      5646\n",
      "           1       0.59      0.77      0.67       165\n",
      "\n",
      "    accuracy                           0.98      5811\n",
      "   macro avg       0.79      0.88      0.83      5811\n",
      "weighted avg       0.98      0.98      0.98      5811\n",
      "\n",
      "[[5558   88]\n",
      " [  38  127]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 300s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL4 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:04-trn_loss:0.053-trn_acc:0.987-val_loss:0.265-val_acc:0.976.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL4)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      5646\n",
      "           1       0.56      0.78      0.65       165\n",
      "\n",
      "    accuracy                           0.98      5811\n",
      "   macro avg       0.78      0.88      0.82      5811\n",
      "weighted avg       0.98      0.98      0.98      5811\n",
      "\n",
      "[[5544  102]\n",
      " [  36  129]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 303s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL5 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:05-trn_loss:0.055-trn_acc:0.991-val_loss:0.233-val_acc:0.956.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL5)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      5646\n",
      "           1       0.38      0.82      0.52       165\n",
      "\n",
      "    accuracy                           0.96      5811\n",
      "   macro avg       0.69      0.89      0.75      5811\n",
      "weighted avg       0.98      0.96      0.96      5811\n",
      "\n",
      "[[5423  223]\n",
      " [  29  136]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 300s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL6 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:06-trn_loss:0.044-trn_acc:0.994-val_loss:0.239-val_acc:0.931.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL6)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96      5646\n",
      "           1       0.28      0.90      0.43       165\n",
      "\n",
      "    accuracy                           0.93      5811\n",
      "   macro avg       0.64      0.92      0.70      5811\n",
      "weighted avg       0.98      0.93      0.95      5811\n",
      "\n",
      "[[5271  375]\n",
      " [  17  148]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 303s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL7 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:07-trn_loss:0.062-trn_acc:0.990-val_loss:0.303-val_acc:0.985.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL7)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5646\n",
      "           1       0.71      0.70      0.70       165\n",
      "\n",
      "    accuracy                           0.98      5811\n",
      "   macro avg       0.85      0.84      0.85      5811\n",
      "weighted avg       0.98      0.98      0.98      5811\n",
      "\n",
      "[[5598   48]\n",
      " [  50  115]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 299s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL8 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:08-trn_loss:0.021-trn_acc:0.998-val_loss:0.377-val_acc:0.986.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL8)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5646\n",
      "           1       0.81      0.65      0.72       165\n",
      "\n",
      "    accuracy                           0.99      5811\n",
      "   macro avg       0.90      0.82      0.86      5811\n",
      "weighted avg       0.98      0.99      0.98      5811\n",
      "\n",
      "[[5620   26]\n",
      " [  57  108]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 304s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL9 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:09-trn_loss:0.024-trn_acc:0.998-val_loss:0.330-val_acc:0.971.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL9)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      5646\n",
      "           1       0.59      0.77      0.67       165\n",
      "\n",
      "    accuracy                           0.98      5811\n",
      "   macro avg       0.79      0.88      0.83      5811\n",
      "weighted avg       0.98      0.98      0.98      5811\n",
      "\n",
      "[[5559   87]\n",
      " [  38  127]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Classifier CVE Model Weights\n",
      "5811/5811 [==============================] - 299s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "MODEL10 = '../../../dsarkar/saved_models/bert_vuln_models/bert_cve75iter2_weights-ep:10-trn_loss:0.039-trn_acc:0.994-val_loss:0.239-val_acc:0.972.h5'\n",
    "bc.load_model_weights(model_weights_path=MODEL10)\n",
    "test_predictions = bc.model_estimator.predict(x=[btp_test.input_ids, \n",
    "                                                 btp_test.input_masks, \n",
    "                                                 btp_test.segment_ids],\n",
    "                                                 batch_size=256,\n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      5646\n",
      "           1       0.51      0.81      0.63       165\n",
      "\n",
      "    accuracy                           0.97      5811\n",
      "   macro avg       0.75      0.89      0.81      5811\n",
      "weighted avg       0.98      0.97      0.98      5811\n",
      "\n",
      "[[5519  127]\n",
      " [  31  134]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = test_predictions.ravel()\n",
    "test_preds = [1 if pred > 0.5 else 0 for pred in test_preds]\n",
    "print('Performance Report:')\n",
    "print(classification_report(y_true=test_labels, y_pred=test_preds))\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
